{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script performs a complete workflow for evaluating speech recognition performance\n",
    "on text files from control and Parkinsonian subjects.\n",
    "\n",
    "It includes:\n",
    "1. Reading text files containing transcriptions.\n",
    "2. Extracting patient IDs from filenames.\n",
    "3. Loading metadata (group labels, tasks, UPDRS scores) from a JSON file.\n",
    "4. Calculating Word Error Rate (WER) and Character Error Rate (CER) using reference texts.\n",
    "5. Removing outliers using Tukey's IQR method.\n",
    "6. Visualizing WER and CER distributions using boxplots and bar plots with significance indicators.\n",
    "7. Computing summary statistics (mean, median, std) and saving to Excel.\n",
    "8. Performing statistical tests (Shapiro-Wilk, t-test, Mann-Whitney U, Kruskal-Wallis, Dunn post hoc).\n",
    "\"\"\"\n",
    "\n",
    "import os  \n",
    "import json  \n",
    "from jiwer import wer, cer  \n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro  \n",
    "import numpy as np   \n",
    "import pandas as pd \n",
    "import seaborn as sns  \n",
    "\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"Reads the content of a text file and returns it as a string.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "def extract_id_from_filename(filename: str) -> str:\n",
    "    \"\"\"Extracts the patient ID from the filename using specific naming conventions.\"\"\"\n",
    "    if filename.startswith(('B1', 'B2')):\n",
    "        patient_id = filename[2:].split('.')[0]\n",
    "    elif filename.startswith(('FB1', 'PR1')):\n",
    "        patient_id = filename[3:].split('.')[0]\n",
    "    \n",
    "    # Logic to extract ID based on the presence of two digits followed by 'F' or 'M'\n",
    "    age_found = False\n",
    "    for i in range(len(patient_id)):\n",
    "        if patient_id[i].isdigit() and not age_found:\n",
    "            if i + 1 < len(patient_id) and patient_id[i+1].isdigit():\n",
    "                age_found = True\n",
    "        elif age_found and patient_id[i] in ['F', 'M']:\n",
    "            patient_id = patient_id[:i+1]\n",
    "            break\n",
    "    return patient_id\n",
    "\n",
    "def load_json_data(json_filepath: str):\n",
    "    \"\"\"Loads data from a JSON file and returns it as a dictionary.\"\"\"\n",
    "    with open(json_filepath, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def determine_group_and_task(file_id: str, json_data) -> tuple:\n",
    "    \"\"\"Determines the group (control or Parkinsonian) and task associated with a file.\"\"\"\n",
    "    for entry in json_data:\n",
    "        if entry['id'] == file_id:\n",
    "            group = 'control' if entry['label'] == 0 else 'parkinson'\n",
    "            task = entry['task'].replace(' ', '').lower()\n",
    "            updrs = entry.get('UPDRS', None)\n",
    "            return group, task, updrs\n",
    "    return 'unknown', 'unknown', None\n",
    "\n",
    "def calculate_wer_cer_for_groups(directory: str, json_filepath: str, reference_texts) -> dict:\n",
    "    \"\"\"Calculates WER and CER for control and Parkinsonian groups.\"\"\"\n",
    "    try:\n",
    "        json_data = load_json_data(json_filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    control_wer, parkinsonian_wer = [], []\n",
    "    control_cer, parkinsonian_cer = [], []\n",
    "    parkinsonian_wer_by_updrs = {i: [] for i in range(5)}\n",
    "    parkinsonian_cer_by_updrs = {i: [] for i in range(5)}\n",
    "    control_files_count, parkinsonian_files_count = 0, 0\n",
    "    updrs_files_count = {i: 0 for i in range(5)}\n",
    "    \n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    \n",
    "    for file in files:\n",
    "        file_id = extract_id_from_filename(file)\n",
    "        if file_id is None:\n",
    "            print(f\"ID not recognized for file '{file}'\")\n",
    "            continue\n",
    "        \n",
    "        group, task, updrs = determine_group_and_task(file_id, json_data)\n",
    "        if group == 'unknown' or task == 'unknown':\n",
    "            print(f\"ID or task not recognized for file '{file}'\")\n",
    "            continue\n",
    "        \n",
    "        if task not in reference_texts:\n",
    "            print(f\"Task '{task}' not recognized in file '{file}'\")\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(directory, file)\n",
    "        reference = reference_texts[task]\n",
    "        hypothesis = read_file(file_path)\n",
    "        \n",
    "        # Calculate WER and CER using the jiwer library\n",
    "        wer_value = wer(reference, hypothesis)\n",
    "        cer_value = cer(reference, hypothesis)\n",
    "        \n",
    "        # Add WER and CER to the appropriate lists and increment counters\n",
    "        if group == 'control':\n",
    "            control_wer.append(wer_value)\n",
    "            control_cer.append(cer_value)\n",
    "            control_files_count += 1\n",
    "        elif group == 'parkinson':\n",
    "            parkinsonian_wer.append(wer_value)\n",
    "            parkinsonian_cer.append(cer_value)\n",
    "            parkinsonian_files_count += 1\n",
    "            if updrs is not None:\n",
    "                parkinsonian_wer_by_updrs[updrs].append(wer_value)\n",
    "                parkinsonian_cer_by_updrs[updrs].append(cer_value)\n",
    "                updrs_files_count[updrs] += 1\n",
    "    \n",
    "    print(f\"Number of control files processed: {control_files_count}\")\n",
    "    print(f\"Number of Parkinsonian files processed: {parkinsonian_files_count}\")\n",
    "    \n",
    "    return {\n",
    "        'control_wer': control_wer,\n",
    "        'parkinsonian_wer': parkinsonian_wer,\n",
    "        'control_cer': control_cer,\n",
    "        'parkinsonian_cer': parkinsonian_cer,\n",
    "        'control_files_count': control_files_count,\n",
    "        'parkinsonian_files_count': parkinsonian_files_count,\n",
    "        'updrs_files_count': updrs_files_count,\n",
    "        'parkinsonian_wer_by_updrs': parkinsonian_wer_by_updrs,\n",
    "        'parkinsonian_cer_by_updrs': parkinsonian_cer_by_updrs\n",
    "    }\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(data):\n",
    "    \"\"\"Removes outliers using Tukey's IQR method and returns the clean data along with the outliers.\"\"\"\n",
    "    q1 = np.percentile(data, 25)  # First quartile (Q1)\n",
    "    q3 = np.percentile(data, 75)  # Third quartile (Q3)\n",
    "    iqr = q3 - q1  # Interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower bound\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper bound\n",
    "    \n",
    "    # Print bounds for debugging\n",
    "    print(f\"Lower bound: {lower_bound}, Upper bound: {upper_bound}\")\n",
    "    \n",
    "    # Separate data into clean data and outliers\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "    \n",
    "    # Print number and values of outliers for debugging\n",
    "    print(f\"Number of outliers detected: {len(outliers)}\")\n",
    "    print(f\"Outliers: {outliers}\")\n",
    "    \n",
    "    return filtered_data, outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Section 6: Plotting the Boxplots (WER and CER) Separately with Larger Text and Legend, Including Numerosity and Outliers\n",
    "def plot_boxplots_wer_cer(control_wer, parkinsonian_wer, control_cer, parkinsonian_cer):\n",
    "    \"\"\"Plots separate boxplots for WER and CER with Tukey's outlier removal, showing numerosity and outliers with larger text.\"\"\"\n",
    "    \n",
    "    # Print numerosity before outlier removal\n",
    "    print(f\"\\n### Numerosity Before Outlier Removal ###\")\n",
    "    print(f\"WER - Control group: {len(control_wer)}, Parkinsonian group: {len(parkinsonian_wer)}\")\n",
    "    print(f\"CER - Control group: {len(control_cer)}, Parkinsonian group: {len(parkinsonian_cer)}\")\n",
    "    \n",
    "    # Calculate and print medians and means before outlier removal\n",
    "    median_control_wer = np.median(control_wer)\n",
    "    median_parkinsonian_wer = np.median(parkinsonian_wer)\n",
    "    median_control_cer = np.median(control_cer)\n",
    "    median_parkinsonian_cer = np.median(parkinsonian_cer)\n",
    "    \n",
    "    mean_control_wer = np.mean(control_wer)\n",
    "    mean_parkinsonian_wer = np.mean(parkinsonian_wer)\n",
    "    mean_control_cer = np.mean(control_cer)\n",
    "    mean_parkinsonian_cer = np.mean(parkinsonian_cer)\n",
    "    \n",
    "    print(f\"\\n### Medians and Means ###\")\n",
    "    print(f\"WER - Control group median: {median_control_wer:.4f}, mean: {mean_control_wer:.4f}\")\n",
    "    print(f\"WER - Parkinsonian group median: {median_parkinsonian_wer:.4f}, mean: {mean_parkinsonian_wer:.4f}\")\n",
    "    print(f\"CER - Control group median: {median_control_cer:.4f}, mean: {mean_control_cer:.4f}\")\n",
    "    print(f\"CER - Parkinsonian group median: {median_parkinsonian_cer:.4f}, mean: {mean_parkinsonian_cer:.4f}\")\n",
    "    \n",
    "    # Remove outliers using Tukey's method\n",
    "    control_wer_clean, control_wer_outliers = remove_outliers_iqr(control_wer)\n",
    "    parkinsonian_wer_clean, parkinsonian_wer_outliers = remove_outliers_iqr(parkinsonian_wer)\n",
    "    control_cer_clean, control_cer_outliers = remove_outliers_iqr(control_cer)\n",
    "    parkinsonian_cer_clean, parkinsonian_cer_outliers = remove_outliers_iqr(parkinsonian_cer)\n",
    "    \n",
    "    # Print numerosity after outlier removal\n",
    "    print(f\"\\n### Numerosity After Outlier Removal ###\")\n",
    "    print(f\"WER - Control group: {len(control_wer_clean)}, Parkinsonian group: {len(parkinsonian_wer_clean)}\")\n",
    "    print(f\"CER - Control group: {len(control_cer_clean)}, Parkinsonian group: {len(parkinsonian_cer_clean)}\")\n",
    "    \n",
    "    # Calculate and print medians for debugging\n",
    "    median_control_wer_clean = np.median(control_wer_clean)\n",
    "    median_parkinsonian_wer_clean = np.median(parkinsonian_wer_clean)\n",
    "    median_control_cer_clean = np.median(control_cer_clean)\n",
    "    median_parkinsonian_cer_clean = np.median(parkinsonian_cer_clean)\n",
    "    \n",
    "    # Boxplot for WER (separate figure)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot([control_wer_clean, parkinsonian_wer_clean], patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Controls', 'Parkinsonians'], \n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'))\n",
    "    \n",
    "    # Manually plot outliers as black dots\n",
    "    for i, outliers in enumerate([control_wer_outliers, parkinsonian_wer_outliers], start=1):\n",
    "        plt.scatter([i] * len(outliers), outliers, color='black', zorder=3)\n",
    "    \n",
    "    # Add title and labels for WER\n",
    "    plt.title('WER Distribution for Controls and Parkinsonians (Bari)', fontsize=16)\n",
    "    plt.ylabel('WER', fontsize=14)\n",
    "    plt.xticks(fontsize=12)  # X-axis label size\n",
    "    plt.yticks(fontsize=12)  # Y-axis label size\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    handles = [plt.Line2D([0], [0], color='green', label='Mean', linestyle='-'),\n",
    "               plt.Line2D([0], [0], color='red', label='Median', linestyle='-')]\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    \n",
    "    # Show the WER plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Boxplot for CER (separate figure)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot([control_cer_clean, parkinsonian_cer_clean], patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Controls', 'Parkinsonians'], \n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'))\n",
    "    \n",
    "    # Manually plot outliers as black dots\n",
    "    for i, outliers in enumerate([control_cer_outliers, parkinsonian_cer_outliers], start=1):\n",
    "        plt.scatter([i] * len(outliers), outliers, color='black', zorder=3)\n",
    "    \n",
    "    # Add title and labels for CER\n",
    "    plt.title('CER Distribution for Controls and Parkinsonians (Bari)', fontsize=16)\n",
    "    plt.ylabel('CER', fontsize=14)\n",
    "    plt.xticks(fontsize=12)  # X-axis label size\n",
    "    plt.yticks(fontsize=12)  # Y-axis label size\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    \n",
    "    # Show the CER plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "\n",
    "def summary_statistics(control_wer_raw, parkinsonian_wer_raw, control_wer_clean, parkinsonian_wer_clean,\n",
    "                       control_cer_raw, parkinsonian_cer_raw, control_cer_clean, parkinsonian_cer_clean,\n",
    "                       output_filename=\"cumulative_results_Bari.csv\"):\n",
    "    \"\"\"\n",
    "    Calculates and saves the summary statistics (mean, median, standard deviation) for WER and CER \n",
    "    for controls and Parkinsonians using raw data. Uses cleaned data for normality and significance tests.\n",
    "    \n",
    "    Parameters:\n",
    "    - control_wer_raw: List of raw WER values for the control group\n",
    "    - parkinsonian_wer_raw: List of raw WER values for the Parkinsonians group\n",
    "    - control_wer_clean: Cleaned list of WER values for the control group\n",
    "    - parkinsonian_wer_clean: Cleaned list of WER values for the Parkinsonians group\n",
    "    - control_cer_raw: List of raw CER values for the control group\n",
    "    - parkinsonian_cer_raw: List of raw CER values for the Parkinsonians group\n",
    "    - control_cer_clean: Cleaned list of CER values for the control group\n",
    "    - parkinsonian_cer_clean: Cleaned list of CER values for the Parkinsonians group\n",
    "    - output_filename: Name of the output CSV file to save the summary table\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate number of outliers\n",
    "    wer_outliers_control = len(control_wer_raw) - len(control_wer_clean)\n",
    "    wer_outliers_parkinsonian = len(parkinsonian_wer_raw) - len(parkinsonian_wer_clean)\n",
    "    cer_outliers_control = len(control_cer_raw) - len(control_cer_clean)\n",
    "    cer_outliers_parkinsonian = len(parkinsonian_cer_raw) - len(parkinsonian_cer_clean)\n",
    "    \n",
    "    # Display number of outliers for each group\n",
    "    print(\"\\n### Number of Outliers ###\")\n",
    "    print(f\"WER - Control group: {wer_outliers_control}, Parkinsonian group: {wer_outliers_parkinsonian}\")\n",
    "    print(f\"CER - Control group: {cer_outliers_control}, Parkinsonian group: {cer_outliers_parkinsonian}\")\n",
    "    \n",
    "    # Summary statistics for WER using raw data\n",
    "    wer_stats = {\n",
    "        'Group': ['Control', 'Parkinsonians'],\n",
    "        'WER Mean': [np.mean(control_wer_raw), np.mean(parkinsonian_wer_raw)],\n",
    "        'WER Median': [np.median(control_wer_raw), np.median(parkinsonian_wer_raw)],\n",
    "        'WER Std Dev': [np.std(control_wer_raw, ddof=1), np.std(parkinsonian_wer_raw, ddof=1)]\n",
    "    }\n",
    "    \n",
    "    # Summary statistics for CER using raw data\n",
    "    cer_stats = {\n",
    "        'Group': ['Control', 'Parkinsonians'],\n",
    "        'CER Mean': [np.mean(control_cer_raw), np.mean(parkinsonian_cer_raw)],\n",
    "        'CER Median': [np.median(control_cer_raw), np.median(parkinsonian_cer_raw)],\n",
    "        'CER Std Dev': [np.std(control_cer_raw, ddof=1), np.std(parkinsonian_cer_raw, ddof=1)]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrames for WER and CER statistics\n",
    "    wer_df = pd.DataFrame(wer_stats)\n",
    "    cer_df = pd.DataFrame(cer_stats)\n",
    "    \n",
    "    # Combine WER and CER statistics into a single DataFrame\n",
    "    summary_df = pd.concat([wer_df, cer_df.drop(columns='Group')], axis=1)\n",
    "    \n",
    "    # Save the summary statistics to a CSV file\n",
    "    summary_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n### Summary Statistics for WER and CER saved to {output_filename} ###\")\n",
    "    print(summary_df)\n",
    "    \n",
    "    # Statistical tests between control and Parkinsonians for WER and CER using cleaned data\n",
    "    print(\"\\n### Statistical Tests ###\")\n",
    "    \n",
    "    # Shapiro-Wilk test for normality on cleaned data\n",
    "    wer_normality_control = shapiro(control_wer_clean)[1]\n",
    "    wer_normality_parkinsonian = shapiro(parkinsonian_wer_clean)[1]\n",
    "    cer_normality_control = shapiro(control_cer_clean)[1]\n",
    "    cer_normality_parkinsonian = shapiro(parkinsonian_cer_clean)[1]\n",
    "    \n",
    "    print(\"\\nShapiro-Wilk p-values (Normality Test on Cleaned Data):\")\n",
    "    print(f\"Control WER: {wer_normality_control}\")\n",
    "    print(f\"Parkinsonians WER: {wer_normality_parkinsonian}\")\n",
    "    print(f\"Control CER: {cer_normality_control}\")\n",
    "    print(f\"Parkinsonians CER: {cer_normality_parkinsonian}\")\n",
    "    \n",
    "    # Decide on parametric (t-test) or non-parametric test (Mann-Whitney U) based on normality\n",
    "    if wer_normality_control > 0.05 and wer_normality_parkinsonian > 0.05:\n",
    "        # Parametric t-test for WER\n",
    "        wer_test_stat, wer_p_value = ttest_ind(control_wer_clean, parkinsonian_wer_clean)\n",
    "        wer_test_name = \"t-test\"\n",
    "    else:\n",
    "        # Non-parametric Mann-Whitney U test for WER\n",
    "        wer_test_stat, wer_p_value = mannwhitneyu(control_wer_clean, parkinsonian_wer_clean, alternative='two-sided')\n",
    "        wer_test_name = \"Mann-Whitney U\"\n",
    "        \n",
    "    if cer_normality_control > 0.05 and cer_normality_parkinsonian > 0.05:\n",
    "        # Parametric t-test for CER\n",
    "        cer_test_stat, cer_p_value = ttest_ind(control_cer_clean, parkinsonian_cer_clean)\n",
    "        cer_test_name = \"t-test\"\n",
    "    else:\n",
    "        # Non-parametric Mann-Whitney U test for CER\n",
    "        cer_test_stat, cer_p_value = mannwhitneyu(control_cer_clean, parkinsonian_cer_clean, alternative='two-sided')\n",
    "        cer_test_name = \"Mann-Whitney U\"\n",
    "    \n",
    "    # Display results of the tests\n",
    "    print(f\"\\nWER Statistical Test ({wer_test_name}): Statistic = {wer_test_stat}, p-value = {wer_p_value}\")\n",
    "    print(f\"CER Statistical Test ({cer_test_name}): Statistic = {cer_test_stat}, p-value = {cer_p_value}\")\n",
    "    \n",
    "    # Adding test results to summary DataFrame\n",
    "    test_results = {\n",
    "        'Metric': ['WER', 'CER'],\n",
    "        'Test': [wer_test_name, cer_test_name],\n",
    "        'Test Statistic': [wer_test_stat, cer_test_stat],\n",
    "        'p-value': [wer_p_value, cer_p_value]\n",
    "    }\n",
    "    test_df = pd.DataFrame(test_results)\n",
    "    \n",
    "    # Save test results to CSV file\n",
    "    with open(output_filename, 'a') as f:\n",
    "        f.write(\"\\n\\n### Statistical Test Results ###\\n\")\n",
    "        test_df.to_csv(f, index=False)\n",
    "    \n",
    "    print(\"\\n### Statistical Test Results saved to CSV ###\")\n",
    "    print(test_df)\n",
    "    \n",
    "    return summary_df, test_df\n",
    "\n",
    "\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "\n",
    "# Section 4: Perform Statistical Tests (Shapiro-Wilk, Mann-Whitney U, or t-test)\n",
    "def perform_statistical_tests(control_values, parkinsonian_values, metric_name):\n",
    "    \"\"\"Performs Shapiro-Wilk test for normality and applies the appropriate statistical test.\"\"\"\n",
    "\n",
    "    # Shapiro-Wilk test for normality\n",
    "    control_normality_p = shapiro(control_values).pvalue\n",
    "    parkinsonian_normality_p = shapiro(parkinsonian_values).pvalue\n",
    "    \n",
    "    # Debug information about normality\n",
    "    print(f\"\\n### Debug for {metric_name} ###\")\n",
    "    print(f\"{metric_name} - Control group normality p-value: {control_normality_p:.3e}\")\n",
    "    print(f\"{metric_name} - Parkinsonian group normality p-value: {parkinsonian_normality_p:.3e}\")\n",
    "    \n",
    "    alpha = 0.05  # Significance level\n",
    "    \n",
    "    # Determine if both groups are normally distributed\n",
    "    if control_normality_p > alpha and parkinsonian_normality_p > alpha:\n",
    "        print(f\"The p-value for normality is greater than {alpha}, so both groups are normally distributed for {metric_name}. Performing unpaired t-test.\")\n",
    "        stat, p_value = ttest_ind(control_values, parkinsonian_values)\n",
    "        print(f\"The p-value for the unpaired t-test is {p_value:.3e}.\")\n",
    "    else:\n",
    "        print(f\"At least one group is not normally distributed for {metric_name} (p-value <= {alpha}). Performing Mann-Whitney U test.\")\n",
    "        stat, p_value = mannwhitneyu(control_values, parkinsonian_values)\n",
    "        print(f\"The p-value for the Mann-Whitney U test is {p_value:.3e}.\")\n",
    "    \n",
    "    # Debugging result interpretation\n",
    "    if p_value < alpha:\n",
    "        print(f\"Since the p-value is less than {alpha}, we reject the null hypothesis. There is a statistically significant difference between the two groups for {metric_name}.\")\n",
    "    else:\n",
    "        print(f\"Since the p-value is greater than {alpha}, we fail to reject the null hypothesis. There is no statistically significant difference between the two groups for {metric_name}.\")\n",
    "    \n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "\n",
    "# General directory and JSON filepath\n",
    "directory = 'data_files'  # Directory where the text files are located\n",
    "json_filepath = 'metadata.json'  # JSON file containing patient metadata\n",
    "\n",
    "\n",
    "# Reference texts associated with tasks\n",
    "reference_texts = {\n",
    "    'readtext': 'Il ramarro della zia. Il papà (o il babbo come dice il piccolo Dado) era sul letto. Sotto di lui, accanto al lago, sedeva Gigi, detto Ciccio, cocco della mamma e della nonna. Vicino ad un sasso c’era una rosa rosso vivo e lo sciocco, vedendola, la volle per la zia. La zia Lulù cercava zanzare per il suo ramarro, ma dato che era giugno (o luglio non so bene) non ne trovava. Trovò invece una rana che saltando dalla strada finì nel lago con un grande spruzzo. Sai che fifa, la zia! Lo schizzo bagnò il suo completo rosa che divenne giallo come un taxi. Passava di lì un signore cosmopolita di nome Sardanapalo Nabucodonosor che si innamorò della zia e la portò con sé in Afghanistan.',\n",
    "    'words': 'pipa, buco, topo, dado, casa, gatto, filo, vaso, muro, neve, luna, rete, zero, scia, ciao, giro, sole, uomo, iuta, gnomo, glielo, pozzo, brodo, plagio, treno, classe, grigio, flotta, creta, drago, frate, spesa, stufa, scala, slitta, splende, strada, scrive, spruzzo, sgrido, sfregio, sdraio, sbrigo, prova, calendario, autobiografia, monotono, pericoloso, montagnoso, prestigioso.',\n",
    "    'phrases': 'Oggi è una bella giornata per sciare. Voglio una maglia di lana color ocra. Il motociclista attraversò una strada stretta di montagna. Patrizia ha pranzato a casa di Fabio. Questo è il tuo cappello? Dopo vieni a casa? La televisione funziona? Non posso aiutarti? Marco non è partito. Il medico non è impegnato.'\n",
    "}\n",
    "\n",
    "# Step 1: Calculate WER and CER for all files\n",
    "results = calculate_wer_cer_for_groups(directory, json_filepath, reference_texts)\n",
    "\n",
    "# Extract raw WER and CER data for control and Parkinsonian groups\n",
    "control_wer = results['control_wer']\n",
    "parkinsonian_wer = results['parkinsonian_wer']\n",
    "control_cer = results['control_cer']\n",
    "parkinsonian_cer = results['parkinsonian_cer']\n",
    "parkinsonian_wer_by_updrs = results['parkinsonian_wer_by_updrs']\n",
    "parkinsonian_cer_by_updrs = results['parkinsonian_cer_by_updrs']\n",
    "\n",
    "# Apply outlier removal function to raw data\n",
    "control_wer_clean, control_wer_outliers = remove_outliers_iqr(control_wer)\n",
    "parkinsonian_wer_clean, parkinsonian_wer_outliers = remove_outliers_iqr(parkinsonian_wer)\n",
    "control_cer_clean, control_cer_outliers = remove_outliers_iqr(control_cer)\n",
    "parkinsonian_cer_clean, parkinsonian_cer_outliers = remove_outliers_iqr(parkinsonian_cer)\n",
    "parkinsonian_wer_by_updrs_clean = {i: remove_outliers_iqr(parkinsonian_wer_by_updrs[i])[0] for i in range(5)}\n",
    "parkinsonian_cer_by_updrs_clean = {i: remove_outliers_iqr(parkinsonian_cer_by_updrs[i])[0] for i in range(5)}\n",
    "\n",
    "# Print information about outliers for each group\n",
    "print(\"\\n### Outlier Information for Each Group ###\")\n",
    "print(f\"Control WER - Outliers ({len(control_wer_outliers)}): {control_wer_outliers}\")\n",
    "print(f\"Control CER - Outliers ({len(control_cer_outliers)}): {control_cer_outliers}\")\n",
    "print(f\"Parkinsonian WER - Outliers ({len(parkinsonian_wer_outliers)}): {parkinsonian_wer_outliers}\")\n",
    "print(f\"Parkinsonian CER - Outliers ({len(parkinsonian_cer_outliers)}): {parkinsonian_cer_outliers}\")\n",
    "\n",
    "# Outliers for each UPDRS level\n",
    "for updrs_level in range(5):\n",
    "    wer_clean, wer_outliers = remove_outliers_iqr(parkinsonian_wer_by_updrs[updrs_level])\n",
    "    cer_clean, cer_outliers = remove_outliers_iqr(parkinsonian_cer_by_updrs[updrs_level])\n",
    "    print(f\"UPDRS {updrs_level} WER - Outliers ({len(wer_outliers)}): {wer_outliers}\")\n",
    "    print(f\"UPDRS {updrs_level} CER - Outliers ({len(cer_outliers)}): {cer_outliers}\")\n",
    "\n",
    "# Step 2: Plot boxplots for WER and CER using raw data\n",
    "plot_boxplots_wer_cer(control_wer, parkinsonian_wer, control_cer, parkinsonian_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the `summary_statistics` function on raw (raw) and cleaned (clean) data\n",
    "summary_stats_df, test_results_df = summary_statistics(\n",
    "    control_wer_raw=control_wer,                  # Raw WER values for controls\n",
    "    parkinsonian_wer_raw=parkinsonian_wer,        # Raw WER values for Parkinsonians\n",
    "    control_wer_clean=control_wer_clean,          # Cleaned WER values for controls\n",
    "    parkinsonian_wer_clean=parkinsonian_wer_clean,# Cleaned WER values for Parkinsonians\n",
    "    control_cer_raw=control_cer,                  # Raw CER values for controls\n",
    "    parkinsonian_cer_raw=parkinsonian_cer,        # Raw CER values for Parkinsonians\n",
    "    control_cer_clean=control_cer_clean,          # Cleaned CER values for controls\n",
    "    parkinsonian_cer_clean=parkinsonian_cer_clean # Cleaned CER values for Parkinsonians\n",
    ")\n",
    "\n",
    "# Perform separate statistical tests for WER and CER using cleaned data\n",
    "wer_test_summary = perform_statistical_tests(control_wer_clean, parkinsonian_wer_clean, \"WER\")\n",
    "cer_test_summary = perform_statistical_tests(control_cer_clean, parkinsonian_cer_clean, \"CER\")\n",
    "\n",
    "# Combine test results into a DataFrame to save to file\n",
    "test_summary_df = pd.DataFrame([wer_test_summary, cer_test_summary])\n",
    "\n",
    "# Save cumulative summary statistics and test results to a single CSV file\n",
    "output_filename = \"cumulative_results_Bari.csv\"\n",
    "summary_stats_df.to_csv(output_filename, index=False)\n",
    "with open(output_filename, 'a') as f:\n",
    "    f.write(\"\\n\\n### Test Summary Results ###\\n\")\n",
    "    test_summary_df.to_csv(f, index=False)\n",
    "\n",
    "print(\"\\n### Summary Statistics ###\")\n",
    "print(summary_stats_df)\n",
    "print(\"\\n### Test Results ###\")\n",
    "print(test_summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, kruskal\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "def summary_statistics_and_tests_bari(control_wer_clean, parkinsonian_wer_by_updrs_clean,\n",
    "                                         control_cer_clean, parkinsonian_cer_by_updrs_clean,\n",
    "                                         output_filename=\"summary_statistics_and_tests_bari.csv\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculates summary statistics for WER and CER across Control and all UPDRS groups (0-4), performs normality tests, \n",
    "    applies Kruskal-Wallis across all groups, and if significant, performs Dunn's post hoc test without Bonferroni correction.\n",
    "    Results are saved to a CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define group labels for display purposes\n",
    "    updrs_levels = ['Control'] + [f'UPDRS {i}' for i in range(5)]\n",
    "    \n",
    "    # Convert UPDRS group data from dictionaries to lists for analysis\n",
    "    parkinsonian_wer_by_updrs_list = [parkinsonian_wer_by_updrs_clean[i] for i in range(5)]\n",
    "    parkinsonian_cer_by_updrs_list = [parkinsonian_cer_by_updrs_clean[i] for i in range(5)]\n",
    "    \n",
    "    # Step 1: Display sample sizes with additional detail\n",
    "    print(\"\\n### Group Sizes (Sample Counts) ###\")\n",
    "    sample_sizes = {'Group': updrs_levels, 'Sample Size': [len(control_wer_clean)] + [len(parkinsonian_wer_by_updrs_list[i]) for i in range(5)]}\n",
    "    sample_df = pd.DataFrame(sample_sizes)\n",
    "    print(sample_df.to_string(index=False))\n",
    "    \n",
    "    # Step 2: Calculate and display summary statistics for WER and CER\n",
    "    wer_stats = {\n",
    "        'Group': updrs_levels,\n",
    "        'WER Mean': [np.mean(control_wer_clean)] + [np.mean(parkinsonian_wer_by_updrs_list[i]) for i in range(5)],\n",
    "        'WER Median': [np.median(control_wer_clean)] + [np.median(parkinsonian_wer_by_updrs_list[i]) for i in range(5)],\n",
    "        'WER Std Dev': [np.std(control_wer_clean, ddof=1)] + [np.std(parkinsonian_wer_by_updrs_list[i], ddof=1) for i in range(5)]\n",
    "    }\n",
    "    cer_stats = {\n",
    "        'Group': updrs_levels,\n",
    "        'CER Mean': [np.mean(control_cer_clean)] + [np.mean(parkinsonian_cer_by_updrs_list[i]) for i in range(5)],\n",
    "        'CER Median': [np.median(control_cer_clean)] + [np.median(parkinsonian_cer_by_updrs_list[i]) for i in range(5)],\n",
    "        'CER Std Dev': [np.std(control_cer_clean, ddof=1)] + [np.std(parkinsonian_cer_by_updrs_list[i], ddof=1) for i in range(5)]\n",
    "    }\n",
    "\n",
    "    wer_df = pd.DataFrame(wer_stats)\n",
    "    cer_df = pd.DataFrame(cer_stats)\n",
    "    \n",
    "    print(\"\\n### WER Summary Statistics ###\")\n",
    "    print(wer_df.to_string(index=False))\n",
    "    print(\"\\n### CER Summary Statistics ###\")\n",
    "    print(cer_df.to_string(index=False))\n",
    "    \n",
    "    with open(output_filename, 'w') as f:\n",
    "        wer_df.to_csv(f, index=False)\n",
    "        f.write(\"\\n\\n\")\n",
    "        cer_df.to_csv(f, index=False)\n",
    "    \n",
    "    # Step 3: Perform Shapiro-Wilk normality test and display results in a clean format\n",
    "    print(\"\\n### Shapiro-Wilk Normality Test Results ###\")\n",
    "    normality_results = {'Group': [], 'WER p-value': [], 'CER p-value': []}\n",
    "    \n",
    "    groups = [control_wer_clean] + parkinsonian_wer_by_updrs_list\n",
    "    cer_groups = [control_cer_clean] + parkinsonian_cer_by_updrs_list\n",
    "\n",
    "    for i, (wer_group, cer_group) in enumerate(zip(groups, cer_groups)):\n",
    "        group_name = updrs_levels[i]\n",
    "        wer_p_value = shapiro(wer_group).pvalue if len(wer_group) > 2 else np.nan\n",
    "        cer_p_value = shapiro(cer_group).pvalue if len(cer_group) > 2 else np.nan\n",
    "        normality_results['Group'].append(group_name)\n",
    "        normality_results['WER p-value'].append(wer_p_value)\n",
    "        normality_results['CER p-value'].append(cer_p_value)\n",
    "        # Additional print for normality test interpretation\n",
    "        print(f\"For WER, {group_name} {'has' if wer_p_value > alpha else 'does not have'} a normal distribution (p-value = {wer_p_value:.4f})\")\n",
    "        print(f\"For CER, {group_name} {'has' if cer_p_value > alpha else 'does not have'} a normal distribution (p-value = {cer_p_value:.4f})\")\n",
    "    \n",
    "    normality_df = pd.DataFrame(normality_results)\n",
    "    print(\"\\n### Shapiro-Wilk Normality Test Results Summary ###\")\n",
    "    print(normality_df.to_string(index=False))\n",
    "    \n",
    "    with open(output_filename, 'a') as f:\n",
    "        f.write(\"\\n\\n### Shapiro-Wilk Normality Test Results ###\\n\")\n",
    "        normality_df.to_csv(f, index=False)\n",
    "    \n",
    "    # Step 4: Kruskal-Wallis test and, if necessary, Dunn's test with detailed interpretation\n",
    "    significant_tests = {'Metric': [], 'Test': [], 'p-value': [], 'Conclusion': []}\n",
    "    dunn_results = []\n",
    "\n",
    "    # WER Kruskal-Wallis test\n",
    "    print(\"\\n### Kruskal-Wallis Test for WER ###\")\n",
    "    wer_stat, wer_p_value = kruskal(*groups)\n",
    "    wer_conclusion = f\"The difference is {'statistically significant' if wer_p_value < alpha else 'not statistically significant'} at alpha = {alpha}.\"\n",
    "    significant_tests['Metric'].append('WER')\n",
    "    significant_tests['Test'].append(\"Kruskal-Wallis\")\n",
    "    significant_tests['p-value'].append(wer_p_value)\n",
    "    significant_tests['Conclusion'].append(wer_conclusion)\n",
    "    print(f\"Kruskal-Wallis WER p-value: {wer_p_value:.5f} - {wer_conclusion}\")\n",
    "\n",
    "    # CER Kruskal-Wallis test\n",
    "    print(\"\\n### Kruskal-Wallis Test for CER ###\")\n",
    "    cer_stat, cer_p_value = kruskal(*cer_groups)\n",
    "    cer_conclusion = f\"The difference is {'statistically significant' if cer_p_value < alpha else 'not statistically significant'} at alpha = {alpha}.\"\n",
    "    significant_tests['Metric'].append('CER')\n",
    "    significant_tests['Test'].append(\"Kruskal-Wallis\")\n",
    "    significant_tests['p-value'].append(cer_p_value)\n",
    "    significant_tests['Conclusion'].append(cer_conclusion)\n",
    "    print(f\"Kruskal-Wallis CER p-value: {cer_p_value:.5f} - {cer_conclusion}\")\n",
    "\n",
    "    # Dunn's post hoc test for CER only if Kruskal-Wallis was significant\n",
    "    if cer_p_value < alpha:\n",
    "        print(\"\\n### Dunn's Post Hoc Test for CER ###\")\n",
    "        dunn_test_results = posthoc_dunn(cer_groups)\n",
    "        dunn_results.append(('CER', dunn_test_results))\n",
    "        print(\"Dunn's post hoc test results for CER:\\n\", dunn_test_results)\n",
    "        \n",
    "        # Interpret Dunn's test results in detail\n",
    "        print(\"\\nInterpreting Dunn's Test Results for each UPDRS pair for CER:\")\n",
    "        for i, group_1 in enumerate(updrs_levels, 1):\n",
    "            for j, group_2 in enumerate(updrs_levels, 1):\n",
    "                if i < j:  # Print only unique pairs\n",
    "                    p_value = dunn_test_results.iloc[i-1, j-1]\n",
    "                    significance = \"significantly different\" if p_value < alpha else \"not significantly different\"\n",
    "                    print(f\"{group_1} vs. {group_2}: {significance} (p-value = {p_value:.4f})\")\n",
    "    \n",
    "    # Convert significance test results to DataFrame and save\n",
    "    tests_df = pd.DataFrame(significant_tests)\n",
    "    with open(output_filename, 'a') as f:\n",
    "        f.write(\"\\n\\n### Significance Test Results ###\\n\")\n",
    "        tests_df.to_csv(f, index=False)\n",
    "        \n",
    "        # Save Dunn's test results for CER, if available\n",
    "        if dunn_results:\n",
    "            for metric, result in dunn_results:\n",
    "                f.write(f\"\\n\\n### Dunn's Post Hoc Test Results for {metric} ###\\n\")\n",
    "                result.to_csv(f)\n",
    "                print(f\"Dunn's post hoc test results for {metric} saved to CSV.\")\n",
    "\n",
    "    # Display summaries in console\n",
    "    print(\"\\n### Summary Statistics and Test Results Saved to CSV ###\")\n",
    "    print(\"\\n### Significance Test Summary ###\")\n",
    "    print(tests_df)\n",
    "\n",
    "    if dunn_results:\n",
    "        for metric, result in dunn_results:\n",
    "            print(f\"\\n### Dunn's Post Hoc Test Results for {metric} ###\")\n",
    "            print(result.to_string(index=False))\n",
    "    \n",
    "    return wer_df, cer_df, normality_df, tests_df, dunn_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the statistical analysis and store the results\n",
    "wer_df, cer_df, normality_df, tests_df, dunn_results = summary_statistics_and_tests_bari(\n",
    "    control_wer_clean,               # Cleaned WER values for Control group\n",
    "    parkinsonian_wer_by_updrs_clean,  # Cleaned WER values for Parkinsonian UPDRS groups\n",
    "    control_cer_clean,                # Cleaned CER values for Control group\n",
    "    parkinsonian_cer_by_updrs_clean,  # Cleaned CER values for Parkinsonian UPDRS groups\n",
    "    output_filename=\"bari_analysis_results.csv\",  # Output filename for CSV\n",
    "    alpha=0.05  # Significance level\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_significance_adjusted(wer_df, cer_df, dunn_results, updrs_levels):\n",
    "    \"\"\"\n",
    "    Generates bar plots for WER and CER across UPDRS groups,\n",
    "    showing only statistically significant differences based on Dunn's post hoc test.\n",
    "    The figure is saved as a high-quality PDF and also displayed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract WER and CER means and standard deviations\n",
    "    wer_means = wer_df['WER Mean'].values\n",
    "    wer_stds = wer_df['WER Std Dev'].values\n",
    "    cer_means = cer_df['CER Mean'].values\n",
    "    cer_stds = cer_df['CER Std Dev'].values\n",
    "\n",
    "    x_positions = np.arange(len(updrs_levels))\n",
    "\n",
    "    def add_significance(ax, x1, x2, y, p_value, line_offset=0):\n",
    "        \"\"\"Adds a significance bar with asterisk annotation between x1 and x2 if p-value is significant.\"\"\"\n",
    "        if p_value < 0.05:\n",
    "            if p_value < 0.0001:\n",
    "                symbol = '****'\n",
    "            elif p_value < 0.001:\n",
    "                symbol = '***'\n",
    "            elif p_value < 0.01:\n",
    "                symbol = '**'\n",
    "            else:\n",
    "                symbol = '*'\n",
    "            ax.plot([x1, x1, x2, x2], [y, y + line_offset, y + line_offset, y],\n",
    "                    color='black', linewidth=1.5)\n",
    "            ax.text((x1 + x2) * 0.5, y + line_offset, symbol,\n",
    "                    ha='center', va='bottom', color='black', fontsize=18)  # back to original size\n",
    "\n",
    "    # Create a figure with two vertical subplots (WER and CER)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 16))\n",
    "\n",
    "    # Plot WER\n",
    "    axes[0].bar(x_positions, wer_means, yerr=wer_stds, capsize=5,\n",
    "                color='lightgray', alpha=0.8)\n",
    "    axes[0].set_title('WER by UPDRS Group (Bari)', fontsize=24)\n",
    "    axes[0].set_xticks(x_positions)\n",
    "    axes[0].set_xticklabels(updrs_levels, fontsize=18)\n",
    "    axes[0].tick_params(axis='y', labelsize=18)\n",
    "    axes[0].set_ylabel('WER (Mean ± SD)', fontsize=22)\n",
    "\n",
    "    # Plot CER\n",
    "    axes[1].bar(x_positions, cer_means, yerr=cer_stds, capsize=5,\n",
    "                color='darkgray', alpha=0.8)\n",
    "    axes[1].set_title('CER by UPDRS Group (Bari)', fontsize=24)\n",
    "    axes[1].set_xticks(x_positions)\n",
    "    axes[1].set_xticklabels(updrs_levels, fontsize=18)\n",
    "    axes[1].tick_params(axis='y', labelsize=18)\n",
    "    axes[1].set_ylabel('CER (Mean ± SD)', fontsize=22)\n",
    "\n",
    "    # Add significance bars to CER plot\n",
    "    if dunn_results:\n",
    "        cer_significance = dunn_results[0][1]\n",
    "        pairs = [(i, j) for i in range(len(updrs_levels)) for j in range(i + 1, len(updrs_levels))]\n",
    "        line_offset = 0.05\n",
    "        for (i, j) in pairs:\n",
    "            p_value = cer_significance.iloc[i, j]\n",
    "            if p_value < 0.05:\n",
    "                y = max(cer_means[i] + cer_stds[i], cer_means[j] + cer_stds[j]) + line_offset\n",
    "                add_significance(axes[1], i, j, y, p_value, line_offset)\n",
    "                line_offset += 0.08  # Increment height for next bar\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    \n",
    "plot_with_significance_adjusted(\n",
    "    wer_df,\n",
    "    cer_df,\n",
    "    dunn_results,\n",
    "    updrs_levels=['Control', 'UPDRS 0', 'UPDRS 1', 'UPDRS 2', 'UPDRS 3', 'UPDRS 4']\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
