{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script performs a complete workflow for evaluating speech recognition performance\n",
    "on text files from control and Parkinsonian subjects in the Molinette dataset.\n",
    "\n",
    "It includes:\n",
    "1. Reading text files containing transcriptions.\n",
    "2. Extracting patient IDs from filenames.\n",
    "3. Loading metadata (group labels, tasks, UPDRS scores) from a JSON file.\n",
    "4. Calculating Word Error Rate (WER) and Character Error Rate (CER) using reference texts.\n",
    "5. Removing outliers using Tukey's IQR method.\n",
    "6. Visualizing WER and CER distributions using boxplots and bar plots with significance indicators.\n",
    "7. Computing summary statistics (mean, median, std) and saving to Excel.\n",
    "8. Performing statistical tests (Shapiro-Wilk, t-test, Mann-Whitney U, Kruskal-Wallis, Dunn post hoc).\n",
    "\"\"\"\n",
    "\n",
    "from jiwer import wer, cer\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "from scikit_posthocs import posthoc_dunn  \n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_json_data(json_filepath: str):\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file and returns it as a Python dictionary.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed JSON data.\n",
    "    \"\"\"\n",
    "    with open(json_filepath, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Path to the JSON file for MOLINETTE dataset\n",
    "molinette_json_filepath = 'metadata.json'  # JSON file containing patient metadata\n",
    "\n",
    "# Load JSON data\n",
    "molinette_data = load_json_data(molinette_json_filepath)\n",
    "\n",
    "# Function to extract the patient ID and on_off status from the MOLINETTE filename\n",
    "def extract_id_from_molinette_filename(filename: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extracts the patient ID and on_off status from the MOLINETTE filename based on the pattern after the first 'P'.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The filename to extract the ID and on_off status from \n",
    "    Returns:\n",
    "        tuple: (patient_id (str), on_off (str or None))\n",
    "    \"\"\"\n",
    "    patient_id = ''\n",
    "    on_off = None\n",
    "    \n",
    "    if filename.startswith('P'):\n",
    "        # Extract ID for filenames that start with 'P'\n",
    "        p_index = filename.find('P') + 1  # Get the index just after 'P'\n",
    "        while p_index < len(filename) and filename[p_index].isdigit():\n",
    "            patient_id += filename[p_index]\n",
    "            p_index += 1\n",
    "        if 'ON' in filename:\n",
    "            on_off = 'on'\n",
    "        elif 'OFF' in filename:\n",
    "            on_off = 'off'\n",
    "    elif filename.startswith('OP'):\n",
    "        # Extract ID for filenames that start with 'OP'\n",
    "        patient_id = filename[:5]  # Take 'OP' + first 3 digits as ID\n",
    "        on_off = 'on'  # Files with 'OP' are assumed to be 'on'\n",
    "        \n",
    "    return patient_id, on_off\n",
    "\n",
    "# Function to determine the reference text for MOLINETTE based on the filename\n",
    "def get_reference_text_molinette(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Determines the correct reference text for a MOLINETTE file based on its name.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The filename to determine the reference text for.\n",
    "s\n",
    "    Returns:\n",
    "        str or None: The reference text or None if not applicable.\n",
    "    \"\"\"\n",
    "    # Example mapping of file identifiers to reference texts\n",
    "    if 'PR1a' in filename or 'PR1b' in filename:\n",
    "        return 'A caval donato non si guarda in bocca'\n",
    "    elif 'PR2a' in filename or 'PR2b' in filename:\n",
    "        return 'Meglio soli che mal accompagnati'\n",
    "    # Add more mappings as needed based on filename patterns\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to determine group, task, and UPDRS based on file ID and dataset\n",
    "def determine_group_and_task(file_id: str, json_data, file_onoff: str = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Determines the group (parkinson), task, and UPDRS associated with a file.\n",
    "\n",
    "    Args:\n",
    "        file_id (str): The extracted file ID.\n",
    "        json_data (dict): The loaded JSON data for the MOLINETTE dataset.\n",
    "        file_onoff (str, optional): The on_off status for MOLINETTE dataset. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (group (str), task (str), updrs (int or None))\n",
    "    \"\"\"\n",
    "    for entry in json_data:\n",
    "        # Ensure both ID and on_off status are matched\n",
    "        if entry['id'] == file_id and entry.get('on_off') == file_onoff:\n",
    "            task = entry['task'].replace(' ', '').lower()\n",
    "            if task == 'proverb':\n",
    "                group = 'parkinson'  # MOLINETTE dataset has only Parkinson patients\n",
    "                updrs = entry.get('updrs', None)\n",
    "                return group, task, updrs\n",
    "    return 'unknown', 'unknown', None\n",
    "\n",
    "# Function to read the content of a text file\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        str: Content of the file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "\n",
    "# Function to calculate WER and CER for the MOLINETTE dataset by UPDRS levels (0, 1, and 2)\n",
    "def calculate_wer_cer_for_molinette(directory: str, json_data) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates WER and CER for parkinson group based on reference texts, limited to UPDRS 0, 1, and 2.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing text files.\n",
    "        json_data (dict): Loaded JSON data for the MOLINETTE dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Calculated WER and CER statistics, including lists of WER/CER values by UPDRS level.\n",
    "    \"\"\"\n",
    "    # Lists to store WER and CER values for all Parkinsonian files\n",
    "    parkinsonian_wer = []\n",
    "    parkinsonian_cer = []\n",
    "\n",
    "    # Dictionaries to store raw WER and CER values by UPDRS level (only for UPDRS levels 0, 1, and 2)\n",
    "    parkinsonian_wer_by_updrs = {i: [] for i in range(3)}\n",
    "    parkinsonian_cer_by_updrs = {i: [] for i in range(3)}\n",
    "\n",
    "    # List of all .txt files in the directory\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "    # Counters for the number of files in each UPDRS level\n",
    "    parkinsonian_files_count = 0\n",
    "    updrs_files_count = {i: 0 for i in range(3)}\n",
    "\n",
    "    for file in files:\n",
    "        # Extract file_id and on_off status (if applicable)\n",
    "        file_id, file_onoff = extract_id_from_molinette_filename(file)\n",
    "\n",
    "        if file_id is None:\n",
    "            print(f\"File ID not recognized for '{file}'\")\n",
    "            continue\n",
    "\n",
    "        # Determine group, task, and UPDRS level\n",
    "        group, task, updrs = determine_group_and_task(file_id, json_data, file_onoff)\n",
    "        if group == 'unknown' or task == 'unknown' or updrs not in parkinsonian_wer_by_updrs:\n",
    "            print(f\"Skipping unrecognized group or task for '{file}'\")\n",
    "            continue\n",
    "\n",
    "        # Get the reference text based on the task\n",
    "        reference = get_reference_text_molinette(file)\n",
    "        if reference is None:\n",
    "            print(f\"No reference text found for task '{task}' in file '{file}'\")\n",
    "            continue\n",
    "\n",
    "        # Read the hypothesis text from the file\n",
    "        file_path = os.path.join(directory, file)\n",
    "        hypothesis = read_file(file_path)\n",
    "\n",
    "        # Calculate WER and CER\n",
    "        wer_value = wer(reference, hypothesis)\n",
    "        cer_value = cer(reference, hypothesis)\n",
    "\n",
    "        # Append WER and CER values to the overall lists and to the appropriate UPDRS level\n",
    "        parkinsonian_wer.append(wer_value)\n",
    "        parkinsonian_cer.append(cer_value)\n",
    "        parkinsonian_files_count += 1\n",
    "        parkinsonian_wer_by_updrs[updrs].append(wer_value)\n",
    "        parkinsonian_cer_by_updrs[updrs].append(cer_value)\n",
    "        updrs_files_count[updrs] += 1\n",
    "\n",
    "    # Calculate average WER and CER for the overall Parkinsonian group\n",
    "    avg_parkinsonian_wer = sum(parkinsonian_wer) / len(parkinsonian_wer) if parkinsonian_wer else float('inf')\n",
    "    avg_parkinsonian_cer = sum(parkinsonian_cer) / len(parkinsonian_cer) if parkinsonian_cer else float('inf')\n",
    "\n",
    "    # Calculate average WER and CER by UPDRS level (using the full list of values per level)\n",
    "    avg_parkinsonian_wer_by_updrs = {\n",
    "        i: (sum(parkinsonian_wer_by_updrs[i]) / len(parkinsonian_wer_by_updrs[i])) if parkinsonian_wer_by_updrs[i] else float('inf')\n",
    "        for i in range(3)\n",
    "    }\n",
    "    avg_parkinsonian_cer_by_updrs = {\n",
    "        i: (sum(parkinsonian_cer_by_updrs[i]) / len(parkinsonian_cer_by_updrs[i])) if parkinsonian_cer_by_updrs[i] else float('inf')\n",
    "        for i in range(3)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'parkinsonian_wer': parkinsonian_wer,  # Full list of WER values\n",
    "        'parkinsonian_cer': parkinsonian_cer,  # Full list of CER values\n",
    "        'avg_parkinsonian_wer': avg_parkinsonian_wer,\n",
    "        'avg_parkinsonian_cer': avg_parkinsonian_cer,\n",
    "        'parkinsonian_files_count': parkinsonian_files_count,\n",
    "        'updrs_files_count': updrs_files_count,\n",
    "        'parkinsonian_wer_by_updrs': parkinsonian_wer_by_updrs,  # Raw WER values by UPDRS\n",
    "        'parkinsonian_cer_by_updrs': parkinsonian_cer_by_updrs,  # Raw CER values by UPDRS\n",
    "        'avg_parkinsonian_wer_by_updrs': avg_parkinsonian_wer_by_updrs,  # Average WER by UPDRS\n",
    "        'avg_parkinsonian_cer_by_updrs': avg_parkinsonian_cer_by_updrs  # Average CER by UPDRS\n",
    "    }\n",
    "\n",
    "# Define the directory for the MOLINETTE dataset\n",
    "molinette_directory = 'data_files'  # Directory where the text files are located\n",
    "\n",
    "\n",
    "# Calculate results for the MOLINETTE dataset\n",
    "molinette_results = calculate_wer_cer_for_molinette(molinette_directory, molinette_data)\n",
    "\n",
    "# Print final results for MOLINETTE\n",
    "print(\"MOLINETTE Results by UPDRS:\")\n",
    "for updrs_level in range(3):  # Only UPDRS 0-2 are present in MOLINETTE\n",
    "    print(f\"UPDRS {updrs_level} - WER: {molinette_results['avg_parkinsonian_wer_by_updrs'][updrs_level]:.4f}, \"\n",
    "          f\"CER: {molinette_results['avg_parkinsonian_cer_by_updrs'][updrs_level]:.4f}, \"\n",
    "          f\"Files: {molinette_results['updrs_files_count'][updrs_level]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data):\n",
    "    \"\"\"Removes outliers using Tukey's IQR method and returns the clean data along with the list of outliers.\"\"\"\n",
    "    q1 = np.percentile(data, 25)  # First quartile (Q1)\n",
    "    q3 = np.percentile(data, 75)  # Third quartile (Q3)\n",
    "    iqr = q3 - q1  # Interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower bound\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper bound\n",
    "    \n",
    "    # Print bounds for debugging\n",
    "    print(f\"Lower bound: {lower_bound}, Upper bound: {upper_bound}\")\n",
    "    \n",
    "    # Separate data into clean data and outliers\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "    \n",
    "    # Print outliers for debugging\n",
    "    print(f\"Outliers detected: {outliers}\")\n",
    "    \n",
    "    return filtered_data, outliers\n",
    "\n",
    "\n",
    "def boxplots_by_updrs(parkinsonian_values_by_updrs, metric_name=\"WER\", dataset_label=\"Molinette dataset\"):\n",
    "    \"\"\"\n",
    "    Creates boxplots for a given metric_name (WER or CER) divided by UPDRS levels, including the control group.\n",
    "    Outliers are displayed in the plot without appearing in the legend, with larger text for better readability.\n",
    "    Additionally, it prints the numerosity for each group before and after outlier removal.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print numerosity before plotting\n",
    "    print(f\"\\n### Numerosity Before Outlier Removal ###\")\n",
    "    for i in range(3):\n",
    "        print(f\"UPDRS {i}: {len(parkinsonian_values_by_updrs[i])}\")\n",
    "    \n",
    "    parkinsonian_values_by_updrs_clean = []\n",
    "    updrs_outliers = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        clean_data, outliers = remove_outliers_iqr(parkinsonian_values_by_updrs[i])\n",
    "        parkinsonian_values_by_updrs_clean.append(clean_data)\n",
    "        updrs_outliers.append(outliers)\n",
    "    \n",
    "    # Print outlier detection results\n",
    "    for i in range(3):\n",
    "        print(f\"UPDRS {i} outliers: {updrs_outliers[i]}\")\n",
    "    \n",
    "    # Prepare the data for the plot: control + UPDRS levels\n",
    "    data =  parkinsonian_values_by_updrs_clean  # Add UPDRS 0 to 2\n",
    "    \n",
    "    # Create a figure for the boxplot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create the boxplot with outliers shown\n",
    "    boxplot = ax.boxplot(data, patch_artist=True, showmeans=True, meanline=True,\n",
    "                         labels=[f'UPDRS {i}' for i in range(3)],  # Labels for each UPDRS level\n",
    "                         boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                         medianprops=dict(color='red'),  # Red line for the median\n",
    "                         meanprops=dict(color='green', linewidth=2),  # Green line for the mean\n",
    "                         whiskerprops=dict(color='black'),  # Black whiskers\n",
    "                         capprops=dict(color='black'),  # Black caps on the whiskers\n",
    "                         flierprops=dict(markerfacecolor='black', marker='o', markersize=5))  # Black dots for outliers\n",
    "    \n",
    "    # Add title and axis labels\n",
    "    ax.set_title(f'{metric_name} Distribution by UPDRS Levels ({dataset_label})', fontsize=16)  # Larger title\n",
    "    ax.set_ylabel(metric_name, fontsize=14)  # Y-axis label with larger text\n",
    "    \n",
    "    # Adjust tick parameters instead of directly setting tick labels\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add a custom legend for Mean and Median (without outliers)\n",
    "    handles = [plt.Line2D([0], [0], color='green', label='Mean', linestyle='-'),\n",
    "               plt.Line2D([0], [0], color='red', label='Median', linestyle='-')]\n",
    "    \n",
    "    # Add the legend\n",
    "    ax.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)  # Larger legend text\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_boxplots_wer_cer(parkinsonian_wer, parkinsonian_cer, dataset_label=\"Dataset\"):\n",
    "    \"\"\"Plots separate boxplots for WER and CER with Tukey's outlier removal, showing numerosity and outliers with larger text.\"\"\"\n",
    "    \n",
    "    # Print numerosity before outlier removal\n",
    "    print(f\"\\n### Numerosity Before Outlier Removal ###\")\n",
    "    print(f\"WER - Parkinsonian group: {len(parkinsonian_wer)}\")\n",
    "    print(f\"CER - Parkinsonian group: {len(parkinsonian_cer)}\")\n",
    "    \n",
    "    # Calculate mean, median, and standard deviation before outlier removal and print them\n",
    "    wer_mean, wer_median, wer_std = np.mean(parkinsonian_wer), np.median(parkinsonian_wer), np.std(parkinsonian_wer, ddof=1)\n",
    "    cer_mean, cer_median, cer_std = np.mean(parkinsonian_cer), np.median(parkinsonian_cer), np.std(parkinsonian_cer, ddof=1)\n",
    "    print(f\"\\n### WER Statistics (Before Outlier Removal) ###\")\n",
    "    print(f\"WER Mean: {wer_mean:.3f}\")\n",
    "    print(f\"WER Median: {wer_median:.3f}\")\n",
    "    print(f\"WER Std Dev: {wer_std:.3f}\")\n",
    "    \n",
    "    print(f\"\\n### CER Statistics (Before Outlier Removal) ###\")\n",
    "    print(f\"CER Mean: {cer_mean:.3f}\")\n",
    "    print(f\"CER Median: {cer_median:.3f}\")\n",
    "    print(f\"CER Std Dev: {cer_std:.3f}\")\n",
    "    # Remove outliers using Tukey's method\n",
    "    parkinsonian_wer_clean, wer_outliers = remove_outliers_iqr(parkinsonian_wer)\n",
    "    parkinsonian_cer_clean, cer_outliers = remove_outliers_iqr(parkinsonian_cer)\n",
    "    \n",
    "    # Print numerosity after outlier removal\n",
    "    print(f\"\\n### Numerosity After Outlier Removal ###\")\n",
    "    print(f\"WER - Parkinsonian group: {len(parkinsonian_wer_clean)} (outliers: {len(wer_outliers)})\")\n",
    "    print(\"WER Outliers:\", wer_outliers)  # Debugging print for WER outliers\n",
    "    print(f\"CER - Parkinsonian group: {len(parkinsonian_cer_clean)} (outliers: {len(cer_outliers)})\")\n",
    "    print(\"CER Outliers:\", cer_outliers)  # Debugging print for CER outliers\n",
    "    \n",
    "    # Create a figure for WER\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(parkinsonian_wer_clean, patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Parkinsonians'], \n",
    "                widths=0.1,\n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'),\n",
    "                flierprops=dict(marker='', markersize=0))  # Disables default outliers\n",
    "\n",
    "    # Add outliers manually for WER\n",
    "    plt.scatter([1] * len(wer_outliers), wer_outliers, color='black', marker='o')\n",
    "    plt.title(f'WER Distribution for Parkinsonians ({dataset_label})', fontsize=16)\n",
    "    plt.ylabel('WER', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    handles = [plt.Line2D([0], [0], color='green', label='Mean', linestyle='-'),\n",
    "               plt.Line2D([0], [0], color='red', label='Median', linestyle='-')]\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a separate figure for CER\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(parkinsonian_cer_clean, patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Parkinsonians'], \n",
    "                widths=0.1,\n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'),\n",
    "                flierprops=dict(marker='', markersize=0))  # Disables default outliers\n",
    "\n",
    "    # Add outliers manually for CER\n",
    "    plt.scatter([1] * len(cer_outliers), cer_outliers, color='black', marker='o')\n",
    "    plt.title(f'CER Distribution for Parkinsonians ({dataset_label})', fontsize=16)\n",
    "    plt.ylabel('CER', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers_iqr(data):\n",
    "    \"\"\"Removes outliers using Tukey's IQR method and returns the clean data along with the list of outliers.\"\"\"\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Filter data into clean data and outliers\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "    \n",
    "    return filtered_data, outliers\n",
    "\n",
    "def prepare_data_and_outliers(data_by_updrs, metric_name):\n",
    "    \"\"\"\n",
    "    Prepares clean data and outliers for each UPDRS level by applying remove_outliers_iqr,\n",
    "    and prints information about the outliers.\n",
    "    \n",
    "    Args:\n",
    "        data_by_updrs (dict): Dictionary with UPDRS levels as keys and lists of data as values.\n",
    "        metric_name (str): Name of the metric (WER or CER).\n",
    "    \n",
    "    Returns:\n",
    "        clean_data_by_updrs (dict): Dictionary with UPDRS levels as keys and cleaned data as values.\n",
    "        outliers_by_updrs (dict): Dictionary with UPDRS levels as keys and outliers as values.\n",
    "    \"\"\"\n",
    "    clean_data_by_updrs = {}\n",
    "    outliers_by_updrs = {}\n",
    "    \n",
    "    for updrs_level, data in data_by_updrs.items():\n",
    "        clean_data, outliers = remove_outliers_iqr(data)\n",
    "        clean_data_by_updrs[updrs_level] = clean_data\n",
    "        outliers_by_updrs[updrs_level] = outliers\n",
    "        \n",
    "        # Print information about outliers\n",
    "        print(f\"\\n### {metric_name} - UPDRS {updrs_level} ###\")\n",
    "        print(f\"Total Outliers: {len(outliers)}\")\n",
    "        print(\"Outlier Values:\", outliers)\n",
    "    \n",
    "    return clean_data_by_updrs, outliers_by_updrs\n",
    "\n",
    "def plot_boxplots_with_outliers(data_by_updrs, outliers_by_updrs, metric_name=\"WER\", dataset_label=\"Molinette\"):\n",
    "    \"\"\"\n",
    "    Plots separate boxplots for each UPDRS level, and manually adds outliers using scatter to ensure visibility.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Prepare data for box plot using clean data\n",
    "    data = [data_by_updrs[updrs] for updrs in range(len(data_by_updrs))]\n",
    "    labels = [f'UPDRS {updrs}' for updrs in range(len(data_by_updrs))]\n",
    "    \n",
    "    box = ax.boxplot(data, patch_artist=True, showmeans=True, meanline=True,\n",
    "                     labels=labels,\n",
    "                     widths=0.3,  # Reduced width for narrower boxes\n",
    "                     boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                     medianprops=dict(color='red'),\n",
    "                     meanprops=dict(color='green', linewidth=2, marker=''),\n",
    "                     whiskerprops=dict(color='black'),\n",
    "                     capprops=dict(color='black'),\n",
    "                     flierprops=dict(marker='', markersize=0))  # Disable automatic outlier markers\n",
    "\n",
    "    # Add custom legend for Mean and Median\n",
    "    handles = [plt.Line2D([0], [0], color='green', label='Mean', linestyle='-'),\n",
    "               plt.Line2D([0], [0], color='red', label='Median', linestyle='-')]\n",
    "    ax.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    \n",
    "    # Plot outliers manually using scatter\n",
    "    for updrs_level, outliers in outliers_by_updrs.items():\n",
    "        x_positions = np.full(len(outliers), updrs_level + 1)\n",
    "        ax.scatter(x_positions, outliers, color='black', marker='o', s=30)\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.set_title(f'{metric_name} Distribution by UPDRS Levels ({dataset_label})', fontsize=18)\n",
    "    ax.set_ylabel(metric_name, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WER and CER and print results\n",
    "results = calculate_wer_cer_for_molinette(molinette_directory, molinette_data)\n",
    "\n",
    "parkinsonian_wer = results['parkinsonian_wer']\n",
    "parkinsonian_cer = results['parkinsonian_cer']\n",
    "parkinsonian_wer_by_updrs = results['parkinsonian_wer_by_updrs']\n",
    "parkinsonian_cer_by_updrs = results['parkinsonian_cer_by_updrs']\n",
    "\n",
    "# Plotting boxplots for WER and CER with outliers\n",
    "plot_boxplots_wer_cer(parkinsonian_wer, parkinsonian_cer, dataset_label=\"Molinette\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `parkinsonian_wer_by_updrs` and `parkinsonian_cer_by_updrs` are dictionaries with data by UPDRS level\n",
    "clean_wer_by_updrs, wer_outliers_by_updrs = prepare_data_and_outliers(parkinsonian_wer_by_updrs, \"WER\")\n",
    "clean_cer_by_updrs, cer_outliers_by_updrs = prepare_data_and_outliers(parkinsonian_cer_by_updrs, \"CER\")\n",
    "\n",
    "# Plot WER and CER with outliers for each UPDRS level\n",
    "plot_boxplots_with_outliers(clean_wer_by_updrs, wer_outliers_by_updrs, metric_name=\"WER\", dataset_label=\"Molinette\")\n",
    "plot_boxplots_with_outliers(clean_cer_by_updrs, cer_outliers_by_updrs, metric_name=\"CER\", dataset_label=\"Molinette\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics_and_tests(parkinsonian_wer, parkinsonian_wer_by_updrs,\n",
    "                                 parkinsonian_cer, parkinsonian_cer_by_updrs,\n",
    "                                 parkinsonian_wer_by_updrs_clean, parkinsonian_cer_by_updrs_clean,\n",
    "                                 output_filename=\"summary_statistics_and_tests_Molinette_combined.csv\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculates summary statistics, performs normality and significance tests on WER and CER,\n",
    "    performs Dunn's post hoc test if Kruskal-Wallis test is significant, displays results, \n",
    "    and saves them to a CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define UPDRS levels (0 to 2)\n",
    "    updrs_levels = [f'UPDRS {i}' for i in range(3)]\n",
    "    \n",
    "    # Step 1: Display sample sizes for each UPDRS level\n",
    "    updrs_counts = {f'UPDRS {i}': len(parkinsonian_wer_by_updrs[i]) for i in range(3)}\n",
    "    print(\"\\n### Group Sizes (Numerosity) ###\")\n",
    "    for level, count in updrs_counts.items():\n",
    "        print(f\"{level}: {count} samples\")\n",
    "\n",
    "    # Step 2: Calculate Summary Statistics for WER and CER, including mean, median, and standard deviation\n",
    "    wer_stats = {\n",
    "        'Group': ['Parkinsonians'] + updrs_levels,\n",
    "        'WER Mean': [np.mean(parkinsonian_wer)] + [np.mean(parkinsonian_wer_by_updrs[i]) for i in range(3)],\n",
    "        'WER Median': [np.median(parkinsonian_wer)] + [np.median(parkinsonian_wer_by_updrs[i]) for i in range(3)],\n",
    "        'WER Std Dev': [np.std(parkinsonian_wer, ddof=1)] + [np.std(parkinsonian_wer_by_updrs[i], ddof=1) for i in range(3)],\n",
    "        'Sample Size': [len(parkinsonian_wer)] + [len(parkinsonian_wer_by_updrs[i]) for i in range(3)]\n",
    "    }\n",
    "    cer_stats = {\n",
    "        'Group': ['Parkinsonians'] + updrs_levels,\n",
    "        'CER Mean': [np.mean(parkinsonian_cer)] + [np.mean(parkinsonian_cer_by_updrs[i]) for i in range(3)],\n",
    "        'CER Median': [np.median(parkinsonian_cer)] + [np.median(parkinsonian_cer_by_updrs[i]) for i in range(3)],\n",
    "        'CER Std Dev': [np.std(parkinsonian_cer, ddof=1)] + [np.std(parkinsonian_cer_by_updrs[i], ddof=1) for i in range(3)],\n",
    "        'Sample Size': [len(parkinsonian_cer)] + [len(parkinsonian_cer_by_updrs[i]) for i in range(3)]\n",
    "    }\n",
    "    \n",
    "    # Step 3: Convert to DataFrames for easier display and saving\n",
    "    wer_df = pd.DataFrame(wer_stats)\n",
    "    cer_df = pd.DataFrame(cer_stats)\n",
    "    \n",
    "    # Display WER and CER statistics\n",
    "    print(\"\\n### WER Summary Statistics ###\")\n",
    "    print(wer_df.to_string(index=False))\n",
    "    print(\"\\n### CER Summary Statistics ###\")\n",
    "    print(cer_df.to_string(index=False))\n",
    "    \n",
    "    # Save summary statistics to CSV file\n",
    "    with open(output_filename, 'w') as f:\n",
    "        wer_df.to_csv(f, index=False)\n",
    "        f.write(\"\\n\\n\")\n",
    "        cer_df.to_csv(f, index=False)\n",
    "    \n",
    "    # Step 4: Perform Shapiro-Wilk normality test on WER and CER for each UPDRS level\n",
    "    normality_results = {'Group': [], 'WER p-value': [], 'CER p-value': []}\n",
    "    for i in range(3):\n",
    "        normality_results['Group'].append(f'UPDRS {i}')\n",
    "        \n",
    "        # Shapiro-Wilk test for WER values in UPDRS i\n",
    "        if len(parkinsonian_wer_by_updrs_clean[i]) > 2:  # Shapiro-Wilk requires at least 3 values\n",
    "            wer_stat, wer_p_value = shapiro(parkinsonian_wer_by_updrs_clean[i])\n",
    "            normality_results['WER p-value'].append(wer_p_value)\n",
    "            print(f\"For WER, UPDRS {i} {'does not have' if wer_p_value < alpha else 'has'} a normal distribution (p-value = {wer_p_value:.4f})\")\n",
    "        else:\n",
    "            normality_results['WER p-value'].append(np.nan)\n",
    "        \n",
    "        # Shapiro-Wilk test for CER values in UPDRS i\n",
    "        if len(parkinsonian_cer_by_updrs_clean[i]) > 2:\n",
    "            cer_stat, cer_p_value = shapiro(parkinsonian_cer_by_updrs_clean[i])\n",
    "            normality_results['CER p-value'].append(cer_p_value)\n",
    "            print(f\"For CER, UPDRS {i} {'does not have' if cer_p_value < alpha else 'has'} a normal distribution (p-value = {cer_p_value:.4f})\")\n",
    "        else:\n",
    "            normality_results['CER p-value'].append(np.nan)\n",
    "\n",
    "    # Convert normality results to DataFrame\n",
    "    normality_df = pd.DataFrame(normality_results)\n",
    "    print(\"\\n### Shapiro-Wilk Normality Test Results ###\")\n",
    "    print(normality_df.to_string(index=False))\n",
    "    \n",
    "    # Save normality test results to CSV file\n",
    "    with open(output_filename, 'a') as f:\n",
    "        f.write(\"\\n\\n### Shapiro-Wilk Normality Test Results ###\\n\")\n",
    "        normality_df.to_csv(f, index=False)\n",
    "    \n",
    "    # Step 5: Determine whether to use ANOVA or Kruskal-Wallis based on normality results\n",
    "    significant_tests = {'Metric': [], 'Test': [], 'p-value': [], 'Conclusion': []}\n",
    "    dunn_results = []\n",
    "\n",
    "    # Test for WER\n",
    "    valid_wer_data = [parkinsonian_wer_by_updrs_clean[i] for i in range(3) if len(parkinsonian_wer_by_updrs_clean[i]) > 2]\n",
    "    if all(p_value > alpha for p_value in normality_df['WER p-value'] if not np.isnan(p_value)):\n",
    "        if len(valid_wer_data) > 1:\n",
    "            test_stat, p_value = f_oneway(*valid_wer_data)\n",
    "            test_name = \"ANOVA\"\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "            test_name = \"ANOVA (Insufficient data)\"\n",
    "    else:\n",
    "        if len(valid_wer_data) > 1:\n",
    "            test_stat, p_value = kruskal(*valid_wer_data)\n",
    "            test_name = \"Kruskal-Wallis\"\n",
    "            if p_value < alpha:\n",
    "                #dunn_test_results = posthoc_dunn(valid_wer_data, p_adjust='bonferroni')\n",
    "                dunn_test_results = posthoc_dunn(valid_wer_data)\n",
    "                dunn_results.append(('WER', dunn_test_results))\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "            test_name = \"Kruskal-Wallis (Insufficient data)\"\n",
    "    \n",
    "    # Log WER significance test\n",
    "    significant_tests['Metric'].append('WER')\n",
    "    significant_tests['Test'].append(test_name)\n",
    "    significant_tests['p-value'].append(p_value)\n",
    "    conclusion = f\"The difference is {'statistically significant' if p_value < alpha else 'not statistically significant'} at alpha = {alpha}.\" if not np.isnan(p_value) else \"Insufficient data for valid test.\"\n",
    "    significant_tests['Conclusion'].append(conclusion)\n",
    "    \n",
    "    # Test for CER\n",
    "    valid_cer_data = [parkinsonian_cer_by_updrs_clean[i] for i in range(3) if len(parkinsonian_cer_by_updrs_clean[i]) > 2]\n",
    "    if all(p_value > alpha for p_value in normality_df['CER p-value'] if not np.isnan(p_value)):\n",
    "        if len(valid_cer_data) > 1:\n",
    "            test_stat, p_value = f_oneway(*valid_cer_data)\n",
    "            test_name = \"ANOVA\"\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "            test_name = \"ANOVA (Insufficient data)\"\n",
    "    else:\n",
    "        if len(valid_cer_data) > 1:\n",
    "            test_stat, p_value = kruskal(*valid_cer_data)\n",
    "            test_name = \"Kruskal-Wallis\"\n",
    "            if p_value < alpha:\n",
    "                #dunn_test_results = posthoc_dunn(valid_cer_data, p_adjust='bonferroni')\n",
    "                dunn_test_results = posthoc_dunn(valid_cer_data)\n",
    "                dunn_results.append(('CER', dunn_test_results))\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "            test_name = \"Kruskal-Wallis (Insufficient data)\"\n",
    "    \n",
    "    # Log CER significance test\n",
    "    significant_tests['Metric'].append('CER')\n",
    "    significant_tests['Test'].append(test_name)\n",
    "    significant_tests['p-value'].append(p_value)\n",
    "    conclusion = f\"The difference is {'statistically significant' if p_value < alpha else 'not statistically significant'} at alpha = {alpha}.\" if not np.isnan(p_value) else \"Insufficient data for valid test.\"\n",
    "    significant_tests['Conclusion'].append(conclusion)\n",
    "    \n",
    "    # Convert to DataFrame for significance test results\n",
    "    tests_df = pd.DataFrame(significant_tests)\n",
    "    print(\"\\n### Significance Test Results ###\")\n",
    "    print(tests_df.to_string(index=False))\n",
    "    \n",
    "    # Save significance test and Dunn's test results to CSV\n",
    "    with open(output_filename, 'a') as f:\n",
    "        f.write(\"\\n\\n### Significance Test Results ###\\n\")\n",
    "        tests_df.to_csv(f, index=False)\n",
    "        \n",
    "        # Save Dunn's post hoc test results if Kruskal-Wallis was significant\n",
    "        for metric, result in dunn_results:\n",
    "            f.write(f\"\\n\\n### Dunn's Post Hoc Test Results for {metric} ###\\n\")\n",
    "            result.to_csv(f)\n",
    "    \n",
    "    # Display Dunn’s test results in a clear format for each UPDRS pair comparison\n",
    "    for metric, result in dunn_results:\n",
    "        print(f\"\\n### Dunn's Post Hoc Test Results for {metric} ###\")\n",
    "        print(result)\n",
    "        \n",
    "        # Interpreting Dunn's test results for each pair\n",
    "        print(\"\\nInterpreting Dunn's Test Results for each UPDRS pair:\")\n",
    "        for (index, p_value) in result.stack().items():\n",
    "            level1, level2 = index\n",
    "            interpretation = (\"significantly different\" if p_value < alpha else \"not significantly different\")\n",
    "            print(f\"UPDRS {level1} vs. UPDRS {level2}: {interpretation} (p-value = {p_value:.4f})\")\n",
    "\n",
    "    print(\"\\n### Summary Statistics and Test Results Saved to CSV ###\")\n",
    "    \n",
    "    return wer_df, cer_df, normality_df, tests_df, dunn_results\n",
    "\n",
    "# Example usage\n",
    "wer_df, cer_df, normality_df, tests_df, dunn_results = summary_statistics_and_tests(\n",
    "    parkinsonian_wer=molinette_results['parkinsonian_wer'],\n",
    "    parkinsonian_wer_by_updrs=molinette_results['parkinsonian_wer_by_updrs'],\n",
    "    parkinsonian_cer=molinette_results['parkinsonian_cer'],\n",
    "    parkinsonian_cer_by_updrs=molinette_results['parkinsonian_cer_by_updrs'],\n",
    "    parkinsonian_wer_by_updrs_clean=clean_wer_by_updrs,\n",
    "    parkinsonian_cer_by_updrs_clean=clean_cer_by_updrs,\n",
    "    output_filename=\"summary_statistics_and_tests_Molinette_combined.csv\",\n",
    "    alpha=0.05\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract means and standard deviations from the DataFrames\n",
    "wer_means = wer_df['WER Mean'][1:4].values  # Only UPDRS 0, 1, 2\n",
    "wer_stds = wer_df['WER Std Dev'][1:4].values\n",
    "cer_means = cer_df['CER Mean'][1:4].values\n",
    "cer_stds = cer_df['CER Std Dev'][1:4].values\n",
    "\n",
    "# Define UPDRS groups and x positions\n",
    "updrs_groups = ['UPDRS 0', 'UPDRS 1', 'UPDRS 2']\n",
    "x_positions = np.arange(len(updrs_groups))\n",
    "\n",
    "# Function to add significance annotations\n",
    "def add_significance(ax, x1, x2, y, p_value, offset=0.02):\n",
    "    if p_value < 0.0001:\n",
    "        symbol = '****'\n",
    "    elif p_value < 0.001:\n",
    "        symbol = '***'\n",
    "    elif p_value < 0.01:\n",
    "        symbol = '**'\n",
    "    elif p_value < 0.05:\n",
    "        symbol = '*'\n",
    "    else:\n",
    "        return\n",
    "    ax.plot([x1, x1, x2, x2], [y, y + offset, y + offset, y], color='black', linewidth=1.5)\n",
    "    ax.text((x1 + x2) * 0.5, y + offset + 0.01, symbol, ha='center', va='bottom', color='black', fontsize=18)\n",
    "\n",
    "# Colors for bars\n",
    "bar_colors = ['lightgray', 'silver', 'darkgray']\n",
    "height_offsets = {(0, 1): 0.08, (0, 2): 0.20, (1, 2): 0.32}\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 16))  # Larger figure for vertical layout\n",
    "\n",
    "# WER Plot\n",
    "ax = axes[0]\n",
    "ax.bar(x_positions, wer_means, yerr=wer_stds, capsize=5, color=bar_colors, alpha=0.8)\n",
    "ax.set_title('WER by UPDRS Group (Molinette)', fontsize=24)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(updrs_groups, fontsize=18)\n",
    "ax.set_ylabel('WER (Mean ± SD)', fontsize=22)\n",
    "ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "wer_significance = dunn_results[0][1]\n",
    "for (i, j) in height_offsets:\n",
    "    p_value = wer_significance.iloc[i, j]\n",
    "    y = max(wer_means[i] + wer_stds[i], wer_means[j] + wer_stds[j]) + height_offsets[(i, j)]\n",
    "    add_significance(ax, i, j, y, p_value, offset=0.02)\n",
    "\n",
    "# CER Plot\n",
    "ax = axes[1]\n",
    "ax.bar(x_positions, cer_means, yerr=cer_stds, capsize=5, color=bar_colors, alpha=0.8)\n",
    "ax.set_title('CER by UPDRS Group (Molinette)', fontsize=24)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(updrs_groups, fontsize=18)\n",
    "ax.set_ylabel('CER (Mean ± SD)', fontsize=22)\n",
    "ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "cer_significance = dunn_results[1][1]\n",
    "for (i, j) in height_offsets:\n",
    "    p_value = cer_significance.iloc[i, j]\n",
    "    y = max(cer_means[i] + cer_stds[i], cer_means[j] + cer_stds[j]) + height_offsets[(i, j)]\n",
    "    add_significance(ax, i, j, y, p_value, offset=0.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dunn_results)\n",
    "for metric, result in dunn_results:\n",
    "    print(f\"{metric} Dunn's test result dimensions: {result.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
