{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script performs a complete workflow for evaluating speech recognition performance\n",
    "on text files from control and Parkinsonian subjects in the PC-GITA dataset.\n",
    "\n",
    "It includes:\n",
    "1. Reading text files containing transcriptions.\n",
    "2. Extracting patient IDs from filenames.\n",
    "3. Loading metadata (group labels, tasks, UPDRS scores) from a JSON file.\n",
    "4. Calculating Word Error Rate (WER) and Character Error Rate (CER) using reference texts.\n",
    "5. Removing outliers using Tukey's IQR method.\n",
    "6. Visualizing WER and CER distributions using boxplots and bar plots with significance indicators.\n",
    "7. Computing summary statistics (mean, median, std) and saving to Excel.\n",
    "8. Performing statistical tests (Shapiro-Wilk, t-test, Mann-Whitney U, Kruskal-Wallis, Dunn post hoc).\n",
    "\"\"\"\n",
    "\n",
    "import os  \n",
    "from typing import List, Dict  \n",
    "from jiwer import wer, cer  \n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro  \n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"Reads the content of a text file and returns it as a string.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "def extract_id_and_keyword(filename: str) -> (str, str):\n",
    "    \"\"\"Extracts the patient ID and keyword from the filename.\"\"\"\n",
    "    for separator in ['_', '-']:\n",
    "        if separator in filename:\n",
    "            return filename.split(separator, 1)[0], filename.split(separator, 1)[1].replace('.txt', '')\n",
    "    return None, None\n",
    "\n",
    "# Reference sentences associated with each keyword\n",
    "keyword_phrases = {\n",
    "    'juan': 'Juan se rompió una pierna cuando iba en la moto',\n",
    "    'loslibros': 'Los libros nuevos no caben en la mesa de la oficina',\n",
    "    'laura': 'Laura sube al tren que pasa',\n",
    "    'luisa': 'Luisa Rey compra el colchón duro que tanto le gusta',\n",
    "    'micasa': 'Mi casa tiene tres cuartos',\n",
    "    'omar': 'Omar, que vive cerca, trajo miel',\n",
    "    'preocupado': 'Estoy muy preocupado, cada vez me es más difícil hablar',\n",
    "    'rosita': 'Rosita Niño, que pinta bien, donó sus cuadros ayer',\n",
    "    'triste': 'Estoy muy triste, ayer vi morir a un amigo',\n",
    "    'viste': '¿Viste las noticias? Yo vi ganar la medalla di plata en pesas. Ese muchacho tiene molta forza!',\n",
    "    'readtext': 'Ayer fui al médico. ¿Qué le pasa? Me preguntó. Yo le dije: ¡Ay doctor! Donde pongo el dedo me duele. ¿Tiene la una rota? Sí. Pues ya sabemos qué es. Deje su cheque a la salida.'\n",
    "}\n",
    "\n",
    "def calculate_wer_cer_for_files(directory: str, control_ids: List[str], parkinsonian_ids: List[str]) -> Dict[str, List[float]]:\n",
    "    \"\"\"Calculates WER and CER for files and returns values for controls and Parkinsonians.\"\"\"\n",
    "    control_wer = [] \n",
    "    parkinsonian_wer = []  \n",
    "    control_cer = []  \n",
    "    parkinsonian_cer = []  \n",
    "    \n",
    "    # List of files in the directory\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    \n",
    "    # Iterate over the files\n",
    "    for file in files:\n",
    "        file_id, keyword = extract_id_and_keyword(file)\n",
    "        \n",
    "        if not file_id or not keyword:\n",
    "            print(f\"File '{file}' does not follow the expected format 'ID_keyword.txt' or 'ID-keyword.txt'\")\n",
    "            continue\n",
    "        \n",
    "        # Verify if the keyword is valid\n",
    "        if keyword not in keyword_phrases:\n",
    "            print(f\"Keyword '{keyword}' not recognized in the file '{file}'\")\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(directory, file)\n",
    "        reference = keyword_phrases[keyword]\n",
    "        hypothesis = read_file(file_path)\n",
    "        \n",
    "        # Calculate WER and CER and append to the appropriate list\n",
    "        if file_id in control_ids:\n",
    "            control_wer.append(wer(reference, hypothesis))\n",
    "            control_cer.append(cer(reference, hypothesis))\n",
    "        elif file_id in parkinsonian_ids:\n",
    "            parkinsonian_wer.append(wer(reference, hypothesis))\n",
    "            parkinsonian_cer.append(cer(reference, hypothesis))\n",
    "    \n",
    "    return {\n",
    "        'control_wer': control_wer,\n",
    "        'parkinsonian_wer': parkinsonian_wer,\n",
    "        'control_cer': control_cer,\n",
    "        'parkinsonian_cer': parkinsonian_cer\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers_iqr(data):\n",
    "    \"\"\"Removes outliers using Tukey's IQR method and returns the clean data along with the count of removed outliers.\"\"\"\n",
    "    q1 = np.percentile(data, 25)  # First quartile (Q1)\n",
    "    q3 = np.percentile(data, 75)  # Third quartile (Q3)\n",
    "    iqr = q3 - q1  # Interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower bound\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper bound\n",
    "    \n",
    "    # Filter data to remove outliers\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    num_outliers = len(data) - len(filtered_data)  # Count of removed outliers\n",
    "    \n",
    "    return filtered_data, num_outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_boxplots_wer_cer(control_wer, parkinsonian_wer, control_cer, parkinsonian_cer):\n",
    "    \"\"\"Plots separate boxplots for WER and CER with Tukey's outlier removal, showing numerosity and outliers with larger text.\"\"\"\n",
    "    \n",
    "    # Print numerosity before outlier removal\n",
    "    print(f\"\\n### Numerosity Before Outlier Removal ###\")\n",
    "    print(f\"WER - Control group: {len(control_wer)}, Parkinsonian group: {len(parkinsonian_wer)}\")\n",
    "    print(f\"CER - Control group: {len(control_cer)}, Parkinsonian group: {len(parkinsonian_cer)}\")\n",
    "    \n",
    "    # Calculate and print medians and means before outlier removal\n",
    "    median_control_wer = np.median(control_wer)\n",
    "    median_parkinsonian_wer = np.median(parkinsonian_wer)\n",
    "    median_control_cer = np.median(control_cer)\n",
    "    median_parkinsonian_cer = np.median(parkinsonian_cer)\n",
    "    \n",
    "    mean_control_wer = np.mean(control_wer)\n",
    "    mean_parkinsonian_wer = np.mean(parkinsonian_wer)\n",
    "    mean_control_cer = np.mean(control_cer)\n",
    "    mean_parkinsonian_cer = np.mean(parkinsonian_cer)\n",
    "    \n",
    "    print(f\"\\n### Medians and Means ###\")\n",
    "    print(f\"WER - Control group median: {median_control_wer:.4f}, mean: {mean_control_wer:.4f}\")\n",
    "    print(f\"WER - Parkinsonian group median: {median_parkinsonian_wer:.4f}, mean: {mean_parkinsonian_wer:.4f}\")\n",
    "    print(f\"CER - Control group median: {median_control_cer:.4f}, mean: {mean_control_cer:.4f}\")\n",
    "    print(f\"CER - Parkinsonian group median: {median_parkinsonian_cer:.4f}, mean: {mean_parkinsonian_cer:.4f}\")\n",
    "    \n",
    "    # Remove outliers using Tukey's method\n",
    "    control_wer_clean, control_wer_outliers = remove_outliers_iqr(control_wer)\n",
    "    parkinsonian_wer_clean, parkinsonian_wer_outliers = remove_outliers_iqr(parkinsonian_wer)\n",
    "    control_cer_clean, control_cer_outliers = remove_outliers_iqr(control_cer)\n",
    "    parkinsonian_cer_clean, parkinsonian_cer_outliers = remove_outliers_iqr(parkinsonian_cer)\n",
    "    \n",
    "    # Print numerosity after outlier removal\n",
    "    print(f\"\\n### Numerosity After Outlier Removal ###\")\n",
    "    print(f\"WER - Control group: {len(control_wer_clean)}, Parkinsonian group: {len(parkinsonian_wer_clean)}\")\n",
    "    print(f\"CER - Control group: {len(control_cer_clean)}, Parkinsonian group: {len(parkinsonian_cer_clean)}\")\n",
    "    \n",
    "    # Calculate and print medians for debugging\n",
    "    median_control_wer_clean = np.median(control_wer_clean)\n",
    "    median_parkinsonian_wer_clean = np.median(parkinsonian_wer_clean)\n",
    "    median_control_cer_clean = np.median(control_cer_clean)\n",
    "    median_parkinsonian_cer_clean = np.median(parkinsonian_cer_clean)\n",
    "    \n",
    "    # Boxplot for WER (separate figure)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot([control_wer, parkinsonian_wer], patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Controls', 'Parkinsonians'], \n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'),\n",
    "                flierprops=dict(markerfacecolor='black', marker='o', markersize=5))  # Ensure outliers are displayed\n",
    "    \n",
    "    # Add title and labels for WER\n",
    "    plt.title('WER Distribution for Controls and Parkinsonians (PC-GITA)', fontsize=16)\n",
    "    plt.ylabel('WER', fontsize=14)\n",
    "    plt.xticks(fontsize=12)  # X-axis label size\n",
    "    plt.yticks(fontsize=12)  # Y-axis label size\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    handles = [plt.Line2D([0], [0], color='green', label='Mean', linestyle='-'),\n",
    "               plt.Line2D([0], [0], color='red', label='Median', linestyle='-')]\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    \n",
    "    # Show the WER plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Boxplot for CER (separate figure)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot([control_cer, parkinsonian_cer], patch_artist=True, showmeans=True, meanline=True, \n",
    "                labels=['Controls', 'Parkinsonians'], \n",
    "                boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                medianprops=dict(color='red'),\n",
    "                meanprops=dict(color='green', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'),\n",
    "                flierprops=dict(markerfacecolor='black', marker='o', markersize=5))  # Ensure outliers are displayed\n",
    "    \n",
    "    # Add title and labels for CER\n",
    "    plt.title('CER Distribution for Controls and Parkinsonians (PC-GITA)', fontsize=16)\n",
    "    plt.ylabel('CER', fontsize=14)\n",
    "    plt.xticks(fontsize=12)  # X-axis label size\n",
    "    plt.yticks(fontsize=12)  # Y-axis label size\n",
    "    \n",
    "    # Add custom legend for Mean and Median\n",
    "    plt.legend(handles=handles, loc='upper right', frameon=True, shadow=True, fontsize=12)\n",
    "    \n",
    "    # Show the CER plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_cumulative_averages(control_values, parkinsonian_values, metric_name):\n",
    "    \"\"\"Calculates the cumulative averages for controls and Parkinsonians after removing outliers.\"\"\"\n",
    "    \n",
    "    # Remove outliers using Tukey's method for both control and Parkinsonian values\n",
    "    control_values_clean, control_outliers = remove_outliers_iqr(control_values)\n",
    "    parkinsonian_values_clean, parkinsonian_outliers = remove_outliers_iqr(parkinsonian_values)\n",
    "    \n",
    "    # Calculate cumulative averages for control and Parkinsonians\n",
    "    cumulative_control = np.mean(control_values_clean)\n",
    "    cumulative_parkinsonian = np.mean(parkinsonian_values_clean)\n",
    "    \n",
    "    # Calculate standard deviations\n",
    "    std_control = np.std(control_values_clean)\n",
    "    std_parkinsonian = np.std(parkinsonian_values_clean)\n",
    "    \n",
    "    # Print results for debugging\n",
    "    print(f\"\\n### {metric_name} Analysis ###\")\n",
    "    print(f\"Cumulative {metric_name} for Controls (without outliers): {cumulative_control:.4f}\")\n",
    "    print(f\"Cumulative {metric_name} for Parkinsonians (without outliers): {cumulative_parkinsonian:.4f}\")\n",
    "    print(f\"Standard deviation for Controls ({metric_name}): {std_control:.4f}\")\n",
    "    print(f\"Standard deviation for Parkinsonians ({metric_name}): {std_parkinsonian:.4f}\")\n",
    "    print(f\"Outliers removed for {metric_name} - Controls: {control_outliers}, Parkinsonians: {parkinsonian_outliers}\")\n",
    "    \n",
    "    return cumulative_control, cumulative_parkinsonian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_tests(control_values, parkinsonian_values, metric_name):\n",
    "    \"\"\"Performs Shapiro-Wilk test for normality and applies the appropriate statistical test.\"\"\"\n",
    "\n",
    "    # Shapiro-Wilk test for normality\n",
    "    control_normality_p = shapiro(control_values).pvalue\n",
    "    parkinsonian_normality_p = shapiro(parkinsonian_values).pvalue\n",
    "    \n",
    "    # Debug information about normality\n",
    "    print(f\"\\n### Debug for {metric_name} ###\")\n",
    "    print(f\"{metric_name} - Control group normality p-value: {control_normality_p:.3e}\")\n",
    "    print(f\"{metric_name} - Parkinsonian group normality p-value: {parkinsonian_normality_p:.3e}\")\n",
    "    \n",
    "    alpha = 0.05  # Significance level\n",
    "    \n",
    "    # Determine if both groups are normally distributed\n",
    "    if control_normality_p > alpha and parkinsonian_normality_p > alpha:\n",
    "        print(f\"The p-value for normality is greater than {alpha}, so both groups are normally distributed for {metric_name}. Performing unpaired t-test.\")\n",
    "        stat, p_value = ttest_ind(control_values, parkinsonian_values)\n",
    "        print(f\"The p-value for the unpaired t-test is {p_value:.3e}.\")\n",
    "    else:\n",
    "        print(f\"At least one group is not normally distributed for {metric_name} (p-value <= {alpha}). Performing Mann-Whitney U test.\")\n",
    "        stat, p_value = mannwhitneyu(control_values, parkinsonian_values)\n",
    "        print(f\"The p-value for the Mann-Whitney U test is {p_value:.3e}.\")\n",
    "    \n",
    "    # Debugging result interpretation\n",
    "    if p_value < alpha:\n",
    "        print(f\"Since the p-value is less than {alpha}, we reject the null hypothesis. There is a statistically significant difference between the two groups for {metric_name}.\")\n",
    "    else:\n",
    "        print(f\"Since the p-value is greater than {alpha}, we fail to reject the null hypothesis. There is no statistically significant difference between the two groups for {metric_name}.\")\n",
    "    \n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'directory'  # Directory where the data files are located\n",
    "\n",
    "# Define lists of control and Parkinsonian IDs\n",
    "control_ids = [\n",
    "...\n",
    "]\n",
    "parkinsonian_ids = [\n",
    "...\n",
    "]\n",
    "\n",
    "# Calculate WER and CER for each file\n",
    "wer_cer_results = calculate_wer_cer_for_files(directory, control_ids, parkinsonian_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values\n",
    "control_wer = wer_cer_results['control_wer']\n",
    "parkinsonian_wer = wer_cer_results['parkinsonian_wer']\n",
    "control_cer = wer_cer_results['control_cer']\n",
    "parkinsonian_cer = wer_cer_results['parkinsonian_cer']\n",
    "\n",
    "# Perform statistical tests for WER\n",
    "print(\"\\nPerforming statistical tests for WER...\")\n",
    "wer_p_value = perform_statistical_tests(control_values=control_wer,\n",
    "                                        parkinsonian_values=parkinsonian_wer, \n",
    "                                        metric_name=\"WER\")\n",
    "\n",
    "# Perform statistical tests for CER\n",
    "print(\"\\nPerforming statistical tests for CER...\")\n",
    "cer_p_value = perform_statistical_tests(control_values=control_cer,\n",
    "                                        parkinsonian_values=parkinsonian_cer, \n",
    "                                        metric_name=\"CER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print cumulative averages (after removing outliers)\n",
    "cumulative_wer_control, cumulative_wer_parkinsonian = calculate_cumulative_averages(control_wer, parkinsonian_wer, 'WER')\n",
    "cumulative_cer_control, cumulative_cer_parkinsonian = calculate_cumulative_averages(control_cer, parkinsonian_cer, 'CER')\n",
    "\n",
    "# Plot vertical boxplots for WER and CER\n",
    "plot_boxplots_wer_cer(control_wer, parkinsonian_wer, control_cer, parkinsonian_cer)\n",
    "\n",
    "# Print final p-values with 15 significant digits\n",
    "print(f\"\\nFinal WER p-value: {wer_p_value:.3e}\")\n",
    "print(f\"Final CER p-value: {cer_p_value:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviations for WER before outlier removal\n",
    "std_wer_control = np.std(control_wer)  # Calculate standard deviation for controls WER\n",
    "std_wer_parkinsonian = np.std(parkinsonian_wer)  # Calculate standard deviation for Parkinsonians WER\n",
    "\n",
    "# Calculate standard deviations for CER\n",
    "std_cer_control = np.std(control_cer)  # Calculate standard deviation for controls CER\n",
    "std_cer_parkinsonian = np.std(parkinsonian_cer)  # Calculate standard deviation for Parkinsonians CER\n",
    "\n",
    "# Calculate means and medians before outlier removal\n",
    "mean_wer_control = np.mean(control_wer)\n",
    "mean_wer_parkinsonian = np.mean(parkinsonian_wer)\n",
    "median_wer_control = np.median(control_wer)\n",
    "median_wer_parkinsonian = np.median(parkinsonian_wer)\n",
    "\n",
    "mean_cer_control = np.mean(control_cer)\n",
    "mean_cer_parkinsonian = np.mean(parkinsonian_cer)\n",
    "median_cer_control = np.median(control_cer)\n",
    "median_cer_parkinsonian = np.median(parkinsonian_cer)\n",
    "\n",
    "# Create a dictionary with cumulative results, standard deviations, means, and medians\n",
    "data = {\n",
    "    \"Metric\": [\"WER\", \"WER\", \"CER\", \"CER\"],  # Metrics being analyzed\n",
    "    \"Group\": [\"Controls\", \"Parkinsonians\", \"Controls\", \"Parkinsonians\"],  # Group classifications\n",
    "    \"Mean\": [mean_wer_control, mean_wer_parkinsonian, mean_cer_control, mean_cer_parkinsonian],  # Means for each group\n",
    "    \"Standard Deviation\": [std_wer_control, std_wer_parkinsonian, std_cer_control, std_cer_parkinsonian],  # Standard deviations for each group\n",
    "    \"Median\": [median_wer_control, median_wer_parkinsonian, median_cer_control, median_cer_parkinsonian]  # Medians for each group\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "results_df = pd.DataFrame(data)  # Create a DataFrame from the data dictionary\n",
    "\n",
    "# Print final table in the console\n",
    "print(\"\\nWER and CER Results with Outliers:\")\n",
    "print(results_df)  # Output the DataFrame to the console\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('cumulative_results_PCGITA.csv', index=False)\n",
    "print(\"Results with outliers saved to 'cumulative_results_PCGITA.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
