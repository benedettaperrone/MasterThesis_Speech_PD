{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DHjPrk2lW7Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "import os\n",
    "from google.colab import drive\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import login  \n",
    "import pickle  \n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "referenced_widgets": [
      "6e7822e5de834110ad02abbf50d270a4",
      "a6007a0a4f2d4fe18e82a5e86336f86f",
      "cbb2e75fe60347f8a9eec0b1ed499648",
      "3fca2fd823fd4633a212bd5ff35bae41",
      "f90a98419dbd4aa8900bec1c35887c30",
      "6b89a1e004d049ecb56977799598e9d9",
      "d05346a3b7eb4bc5b4155268b8ba553f",
      "e0deb85faa9a4d1495428d602c3edc72",
      "d679ebeafd784554907bae9ba0558711",
      "e0a85f128e8f4192ba8a16e68a714089",
      "a4f54d574afd4ac19f384222705c5917",
      "eb871e0a2cf246eb93f6489ed290db4d",
      "877f55be688144bda1c702fdc7b66c14",
      "9b7a38656bbb44ae911e16bf2d880946",
      "a8c299f851fc44acb5b5975a1190eb85",
      "da857d2ca0694f68aa05da1dc7f37784",
      "7f09db369eb54075ab1d7b1cdf7c7cdf",
      "65e7482b4426451d99a65176fd3ea7bd",
      "df10da2e305d4eeda5a15249ebb7d866",
      "6114f3834a384a17a9d61ceab7d892c2"
     ]
    },
    "executionInfo": {
     "elapsed": 18062,
     "status": "ok",
     "timestamp": 1732529925165,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "KfONe5SSmSbU",
    "outputId": "ca9819a0-6e00-4223-8bb6-c3f3e3c68eaa"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", palette=None)\n",
    "\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(color_pal)\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "tesi_path = #path to your directory\n",
    "os.chdir(tesi_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDcQ4FAX9lw1"
   },
   "outputs": [],
   "source": [
    "def print_updrs_distribution(data, label_key='label', updrs_keys=['updrs', 'UPDRS']):\n",
    "    \"\"\"\n",
    "    Prints the distribution of data based on UPDRS levels and labels.\n",
    "\n",
    "    Args:\n",
    "        data (list): Dataset containing 'label' and 'updrs' or 'UPDRS' information.\n",
    "        label_key (str): Key for the label (0 = control, 1 = Parkinsonian).\n",
    "        updrs_keys (list): Possible keys for the UPDRS value in the data.\n",
    "    \"\"\"\n",
    "    updrs_counts = defaultdict(int)\n",
    "    control_count, parkinsonian_count = 0, 0\n",
    "\n",
    "    for item in data:\n",
    "        print(f\"Item: {item}\")  \n",
    "        if label_key in item:\n",
    "            label = item[label_key]\n",
    "            print(f\"Label: {label}\")  \n",
    "            if label == 0:\n",
    "                control_count += 1\n",
    "            elif label == 1:\n",
    "                parkinsonian_count += 1\n",
    "\n",
    "        updrs_value = None\n",
    "        for key in updrs_keys:\n",
    "            if key in item:\n",
    "                updrs_value = item[key]\n",
    "                print(f\"UPDRS: {updrs_value}\") \n",
    "                break\n",
    "\n",
    "        if updrs_value is not None:\n",
    "            updrs_counts[updrs_value] += 1\n",
    "\n",
    "    print(f\"Number of controls: {control_count}\")\n",
    "    print(f\"Number of Parkinsonians: {parkinsonian_count}\")\n",
    "    print(\"UPDRS Distribution:\")\n",
    "    for updrs_value, count in sorted(updrs_counts.items()):\n",
    "        print(f\"  UPDRS {updrs_value}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 56327,
     "status": "ok",
     "timestamp": 1732529989022,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "daIYmRi2ntCh",
    "outputId": "49def369-f934-43c4-c8c9-c828b0f12d1f"
   },
   "outputs": [],
   "source": [
    "file_path = #path to your pickle file\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    newdata = pickle.load(f)\n",
    "\n",
    "print(\"Pickle file loaded successfully.\")\n",
    "\n",
    "sampling_rate = 44100\n",
    "\n",
    "audio_lengths = [len(item['audio']) for item in newdata]\n",
    "audio_lengths_sec = [length / sampling_rate for length in audio_lengths]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(audio_lengths_sec, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (Before Processing)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of audios: {len(audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length: {min(audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length: {max(audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "q1 = np.percentile(audio_lengths, 25)\n",
    "q3 = np.percentile(audio_lengths, 75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "filtered_data = [item for item in newdata if lower_bound <= len(item['audio']) <= upper_bound]\n",
    "\n",
    "filtered_audio_lengths = [len(item['audio']) for item in filtered_data]\n",
    "filtered_audio_lengths_sec = [length / sampling_rate for length in filtered_audio_lengths]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_audio_lengths_sec, bins=50, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (After Removing Outliers)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of audios after removing outliers: {len(filtered_audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length after filtering: {min(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length after filtering: {max(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "min_length = min(filtered_audio_lengths)\n",
    "print(f\"The shortest audio length is: {min_length / sampling_rate:.2f} seconds ({min_length} samples)\")\n",
    "\n",
    "newdata = filtered_data\n",
    "\n",
    "def extract_first_last_halves(audio, min_length):\n",
    "    n_half = min_length // 2\n",
    "    if len(audio) >= min_length:\n",
    "        first_half = audio[:n_half]\n",
    "        last_half = audio[-n_half:]\n",
    "    else:\n",
    "        padding = min_length - len(audio)\n",
    "        audio_padded = np.pad(audio, (0, padding), 'constant')\n",
    "        first_half = audio_padded[:n_half]\n",
    "        last_half = audio_padded[-n_half:]\n",
    "    return first_half, last_half\n",
    "\n",
    "print(\"Processing audios and creating Mel-Spectrograms for the first and last halves...\")\n",
    "for item in newdata:\n",
    "    audio = np.array(item['audio'])\n",
    "    first_half, last_half = extract_first_last_halves(audio, min_length)\n",
    "\n",
    "    mel_spec_first = librosa.feature.melspectrogram(y=first_half, sr=sampling_rate)\n",
    "    mel_spec_last = librosa.feature.melspectrogram(y=last_half, sr=sampling_rate)\n",
    "\n",
    "    mel_spec_first_db = librosa.power_to_db(mel_spec_first, ref=np.max)\n",
    "    mel_spec_last_db = librosa.power_to_db(mel_spec_last, ref=np.max)\n",
    "\n",
    "    item['mel_spec_first'] = mel_spec_first_db\n",
    "    item['mel_spec_last'] = mel_spec_last_db\n",
    "\n",
    "    del item['audio']\n",
    "\n",
    "print(\"All audios have been processed and Mel-Spectrograms created for both halves.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3383,
     "status": "ok",
     "timestamp": 1732529992402,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "iFrFqCksn15L",
    "outputId": "c78cdc3d-904b-4186-9c8a-daf8ba542e63"
   },
   "outputs": [],
   "source": [
    "# Function to convert a Mel-Spectrogram to a 3-channel RGB image\n",
    "def convert_to_rgb(mel_spec):\n",
    "    \"\"\"\n",
    "    Converts a Mel-Spectrogram to a 3-channel RGB image suitable for ViT input.\n",
    "    \"\"\"\n",
    "    resized_mel_spec = cv2.resize(mel_spec, (224, 224))\n",
    "\n",
    "    normalized_mel_spec = (resized_mel_spec - np.min(resized_mel_spec)) / (np.max(resized_mel_spec) - np.min(resized_mel_spec))\n",
    "\n",
    "    rgb_image = np.stack([normalized_mel_spec]*3, axis=-1)\n",
    "    return rgb_image\n",
    "\n",
    "# Convert all Mel-Spectrograms to RGB images\n",
    "print(\"Converting Mel-Spectrograms to RGB images...\")\n",
    "for item in newdata:\n",
    "    mel_spec_first = item['mel_spec_first']\n",
    "    rgb_image_first = convert_to_rgb(mel_spec_first)\n",
    "    item['image_first'] = rgb_image_first  # Save the RGB image of the first half\n",
    "\n",
    "    mel_spec_last = item['mel_spec_last']\n",
    "    rgb_image_last = convert_to_rgb(mel_spec_last)\n",
    "    item['image_last'] = rgb_image_last  # Save the RGB image of the last half\n",
    "\n",
    "    # Remove the Mel-Spectrograms to save memory\n",
    "    del item['mel_spec_first']\n",
    "    del item['mel_spec_last']\n",
    "\n",
    "print(\"Conversion to RGB images completed.\")\n",
    "\n",
    "\n",
    "def plot_random_mel_spectrograms(data, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plots random pairs of Mel-Spectrogram RGB images with their labels.\n",
    "    \"\"\"\n",
    "    random_samples = random.sample(data, num_samples)\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5 * num_samples))\n",
    "\n",
    "    for i, sample in enumerate(random_samples):\n",
    "        image_first = sample['image_first']\n",
    "        image_last = sample['image_last']\n",
    "        label = sample['label']\n",
    "\n",
    "        axes[i, 0].imshow(image_first)\n",
    "        axes[i, 0].set_title(f\"First Half - Label: {label}\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(image_last)\n",
    "        axes[i, 1].set_title(f\"Last Half - Label: {label}\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_random_mel_spectrograms(newdata, num_samples=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKDDrYZ8n86H"
   },
   "outputs": [],
   "source": [
    "# Define the custom Dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        Args:\n",
    "            data (list): List of data samples, each containing 'image_first', 'image_last', and 'label'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample and its label at the given index.\n",
    "        Args:\n",
    "            idx (int): Index of the sample.\n",
    "        Returns:\n",
    "            image_first (tensor): Transformed image tensor of the first half.\n",
    "            image_last (tensor): Transformed image tensor of the last half.\n",
    "            label (int): Corresponding label.\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        image_first = sample['image_first']\n",
    "        image_last = sample['image_last']\n",
    "        label = sample['label']\n",
    "\n",
    "        if 'updrs' in sample:\n",
    "            updrs_value = sample['updrs']\n",
    "        elif 'UPDRS' in sample:\n",
    "            updrs_value = sample['UPDRS']\n",
    "        else:\n",
    "            updrs_value = -1 \n",
    "\n",
    "        metadata = {'updrs': updrs_value}\n",
    "\n",
    "        if self.transform:\n",
    "            image_first = self.transform(image_first)\n",
    "            image_last = self.transform(image_last)\n",
    "\n",
    "        return image_first, image_last, label, metadata\n",
    "\n",
    "# Define data transformations (data augmentation and normalization)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),  # Normalize the tensor\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(10)  # Random rotation up to 10 degrees\n",
    "])\n",
    "\n",
    "grouped_by_id = defaultdict(list)\n",
    "for item in newdata:\n",
    "    grouped_by_id[item['id']].append(item)\n",
    "\n",
    "all_ids = list(grouped_by_id.keys())\n",
    "\n",
    "# Function to perform stratified group split based on subject IDs and labels\n",
    "def stratified_group_split(all_ids, grouped_by_id, label_key='label'):\n",
    "    \"\"\"\n",
    "    Splits the dataset into stratified groups while maintaining balance between classes.\n",
    "    Args:\n",
    "        all_ids (list): List of all subject IDs.\n",
    "        grouped_by_id (dict): Dictionary grouping data by subject ID.\n",
    "        label_key (str): Key to access the label in the data.\n",
    "    Returns:\n",
    "        folds (list): List of folds with balanced subject IDs.\n",
    "    \"\"\"\n",
    "    # Separate IDs based on labels\n",
    "    controls = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 0]\n",
    "    parkinsons = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 1]\n",
    "\n",
    "    # Shuffle the IDs to ensure random distribution\n",
    "    random.shuffle(controls)\n",
    "    random.shuffle(parkinsons)\n",
    "\n",
    "    # Define the number of folds for cross-validation\n",
    "    num_folds = 5\n",
    "\n",
    "    # Calculate the number of IDs per fold\n",
    "    split_controls = len(controls) // num_folds\n",
    "    split_parkinsons = len(parkinsons) // num_folds\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    for i in range(num_folds):\n",
    "        fold_controls = controls[i * split_controls:(i + 1) * split_controls]\n",
    "        fold_parkinsons = parkinsons[i * split_parkinsons:(i + 1) * split_parkinsons]\n",
    "        folds.append(fold_controls + fold_parkinsons)\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ba6pcP1W5Ijo"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate specificity based on confusion matrix.\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "    Returns:\n",
    "        Specificity (float): True Negative Rate.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG8ypusaRudX"
   },
   "outputs": [],
   "source": [
    "def analyze_updrs(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Analyze logits and probabilities by UPDRS levels for AST model with dual inputs.\n",
    "\n",
    "    Args:\n",
    "        val_loader: Validation data loader.\n",
    "        model: Trained DualInputASTModel.\n",
    "        device: Device (CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "        updrs_stats (dict): Dictionary with detailed metrics for each UPDRS level.\n",
    "    \"\"\"\n",
    "    updrs_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    control_stats = {'correct': 0, 'total': 0, 'control_prob': []}  # For label 0 (control)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs_first, inputs_last, labels, metadata in val_loader:\n",
    "            inputs_first = inputs_first.to(device)\n",
    "            inputs_last = inputs_last.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass to get logits\n",
    "            logits_first = model(inputs_first).logits  \n",
    "            logits_last = model(inputs_last).logits    \n",
    "            logits = (logits_first + logits_last) / 2  \n",
    "\n",
    "\n",
    "            # Compute probabilities for the Parkinsonian class\n",
    "            probabilities = torch.softmax(logits, dim=1)[:, 1]  \n",
    "            logits = logits[:, 1]  \n",
    "\n",
    "            # Iterate over each sample in the batch\n",
    "            for i, prob in enumerate(probabilities.cpu().numpy()):\n",
    "                logit = logits[i].item()\n",
    "\n",
    "                # Access UPDRS value from metadata if available\n",
    "                updrs_value = None\n",
    "                if 'updrs' in metadata:\n",
    "                    updrs_value = metadata['updrs'][i]\n",
    "                elif 'UPDRS' in metadata:\n",
    "                    updrs_value = metadata['UPDRS'][i]\n",
    "\n",
    "                # Convert UPDRS value to integer if it exists\n",
    "                if updrs_value is not None:\n",
    "                    if isinstance(updrs_value, torch.Tensor):\n",
    "                        updrs_value = updrs_value.item()\n",
    "                    else:\n",
    "                        updrs_value = int(updrs_value)\n",
    "\n",
    "                # Skip invalid UPDRS values\n",
    "                if updrs_value == -1 or updrs_value is None:\n",
    "                    continue\n",
    "\n",
    "                # Append results to UPDRS-specific stats\n",
    "                updrs_results[updrs_value].append((logit, prob, labels[i].item()))\n",
    "\n",
    "\n",
    "\n",
    "    return updrs_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JYfDlxdRvQZ"
   },
   "outputs": [],
   "source": [
    "def aggregate_updrs_results(fold_results):\n",
    "    \"\"\"\n",
    "    Aggregates UPDRS results across all folds.\n",
    "\n",
    "    Args:\n",
    "        fold_results (list): List of dictionaries, where each dictionary contains\n",
    "                             'updrs_results' for a fold.\n",
    "\n",
    "    Returns:\n",
    "        aggregated_results (dict): Dictionary with aggregated metrics for each UPDRS level.\n",
    "                                   Keys: {0, 1, 2, 3, 4}\n",
    "                                   Values: Dict with:\n",
    "                                       - 'total_count': Total samples with this UPDRS level.\n",
    "                                       - 'mean_probability': Mean probability for Parkinsonian classification.\n",
    "                                       - 'mean_logit': Mean logit value for Parkinsonian class.\n",
    "                                       - 'percentage_classified_as_parkinsonian': Percentage classified as Parkinsonian.\n",
    "        probabilities_by_updrs (dict): Dictionary containing all individual probabilities for each UPDRS level.\n",
    "    \"\"\"\n",
    "    aggregated_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    probabilities_by_updrs = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    for fold in fold_results:\n",
    "        updrs_results = fold['updrs_results']\n",
    "        for level, values in updrs_results.items():\n",
    "            aggregated_results[level].extend(values) \n",
    "            probabilities_by_updrs[level].extend([prob for _, prob, _ in values]) \n",
    "\n",
    "    metrics = {}\n",
    "    for level, results in aggregated_results.items():\n",
    "        if results:\n",
    "            logits, probs, true_labels = zip(*results)\n",
    "            mean_prob = np.mean(probs)  \n",
    "            mean_logit = np.mean(logits)  \n",
    "            total_count = len(results)  \n",
    "            classified_as_parkinsonian = sum(1 for prob, label in zip(probs, true_labels) if prob >= 0.5 and label == 1)\n",
    "            percentage_classified_as_parkinsonian = (classified_as_parkinsonian / total_count) * 100\n",
    "\n",
    "            metrics[level] = {\n",
    "                'total_count': total_count,\n",
    "                'mean_probability': mean_prob,\n",
    "                'mean_logit': mean_logit,\n",
    "                'percentage_classified_as_parkinsonian': percentage_classified_as_parkinsonian,\n",
    "            }\n",
    "        else:\n",
    "            metrics[level] = {\n",
    "                'total_count': 0,\n",
    "                'mean_probability': 0.0,\n",
    "                'mean_logit': 0.0,\n",
    "                'percentage_classified_as_parkinsonian': 0.0,\n",
    "            }\n",
    "\n",
    "    return metrics, probabilities_by_updrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhhhkGk1mgKw"
   },
   "outputs": [],
   "source": [
    "# Function to compute and print the confusion matrix and derived metrics\n",
    "def compute_confusion_matrix_metrics(labels, preds, fold_num):\n",
    "    \"\"\"\n",
    "    Computes and prints the confusion matrix, sensitivity, specificity, and balanced accuracy.\n",
    "\n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        preds (list): Predicted labels.\n",
    "        fold_num (int): Current fold number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Sensitivity, Specificity, Balanced Accuracy.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(labels, preds) \n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel() \n",
    "    else:\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0  \n",
    "        if len(cm) == 1:\n",
    "            if cm[0][0] == 0:\n",
    "                tn = 0\n",
    "                fp = 0\n",
    "                fn = cm[0][1]\n",
    "                tp = 0\n",
    "            else:\n",
    "                tn = cm[0][0]\n",
    "                fp = 0\n",
    "                fn = 0\n",
    "                tp = 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  \n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  \n",
    "    balanced_acc = (sensitivity + specificity) / 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22560343,
     "status": "ok",
     "timestamp": 1732555342521,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "X-SuCFxAUEH_",
    "outputId": "368a0c47-9cb2-43e0-a055-f95966068915"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "early_stopping_patience = 20\n",
    "learning_rate = 0.0001\n",
    "\n",
    "print(\"Starting K-Fold Cross Validation...\")\n",
    "folds = stratified_group_split(all_ids, grouped_by_id)\n",
    "\n",
    "fold_results = []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_precisions, val_precisions = [], []\n",
    "train_recalls, val_recalls = [], []\n",
    "train_f1s, val_f1s = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for fold, val_ids in enumerate(folds):\n",
    "    print(f'\\nFOLD {fold+1}')\n",
    "    train_ids = [id_ for id_ in all_ids if id_ not in val_ids]\n",
    "\n",
    "    train_samples = [item for id_ in train_ids for item in grouped_by_id[id_]]\n",
    "    val_samples = [item for id_ in val_ids for item in grouped_by_id[id_]]\n",
    "    train_labels = [item['label'] for item in train_samples]\n",
    "    val_labels = [item['label'] for item in val_samples]\n",
    "\n",
    "    print(f\"Training set: {len(train_samples)} samples\")\n",
    "    print(f\"  - Controls: {train_labels.count(0)} samples\")\n",
    "    print(f\"  - Parkinson's: {train_labels.count(1)} samples\")\n",
    "    print(f\"Validation set: {len(val_samples)} samples\")\n",
    "    print(f\"  - Controls: {val_labels.count(0)} samples\")\n",
    "    print(f\"  - Parkinson's: {val_labels.count(1)} samples\")\n",
    "\n",
    "    train_dataset = AudioDataset(train_samples, transform=data_transforms)\n",
    "    val_dataset = AudioDataset(val_samples, transform=data_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "    model.vit.encoder.layer[-1].output.dropout = nn.Dropout(p=0.15)\n",
    "    model.classifier.dropout = nn.Dropout(p=0.15)\n",
    "    model.vit.encoder.layer[-1].output.layernorm = nn.LayerNorm(model.config.hidden_size)\n",
    "    model.classifier.batchnorm = nn.BatchNorm1d(num_features=2)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.vit.encoder.layer[-1].parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "    epoch_train_accuracies, epoch_val_accuracies = [], []\n",
    "    epoch_train_precisions, epoch_val_precisions = [], []\n",
    "    epoch_train_recalls, epoch_val_recalls = [], []\n",
    "    epoch_train_f1s, epoch_val_f1s = [], []\n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    val_fold_preds, val_fold_true = [], []\n",
    "    train_preds_all, train_true_all = [], []\n",
    "    val_preds_all, val_true_all = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, correct_train = 0.0, 0\n",
    "        train_preds, train_true = [], []\n",
    "\n",
    "        for inputs_first, inputs_last, labels, metadata in train_loader:\n",
    "            inputs_first, inputs_last, labels = inputs_first.to(device), inputs_last.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs_combined = (model(inputs_first).logits + model(inputs_last).logits) / 2\n",
    "            loss = criterion(outputs_combined, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            preds = torch.argmax(outputs_combined, dim=1)\n",
    "            correct_train += torch.sum(preds == labels).item()\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_precision = precision_score(train_true, train_preds, average='binary', zero_division=0)\n",
    "        train_recall = recall_score(train_true, train_preds, average='binary', zero_division=0)\n",
    "        train_f1 = f1_score(train_true, train_preds, average='binary', zero_division=0)\n",
    "        train_specificity = calculate_specificity(train_true, train_preds)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct_val = 0.0, 0\n",
    "        val_preds, val_true = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs_first, inputs_last, labels, _ in val_loader:\n",
    "                inputs_first, inputs_last, labels = inputs_first.to(device), inputs_last.to(device), labels.to(device)\n",
    "                outputs_combined = (model(inputs_first).logits + model(inputs_last).logits) / 2\n",
    "                loss = criterion(outputs_combined, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                preds = torch.argmax(outputs_combined, dim=1)\n",
    "                correct_val += torch.sum(preds == labels).item()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        updrs_results = analyze_updrs(val_loader, model, device)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_precision = precision_score(val_true, val_preds, average='binary', zero_division=0)\n",
    "        val_recall = recall_score(val_true, val_preds, average='binary', zero_division=0)\n",
    "        val_f1 = f1_score(val_true, val_preds, average='binary', zero_division=0)\n",
    "        val_sensitivity = val_recall\n",
    "        val_specificity = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 0)) / \\\n",
    "                          np.sum(np.array(val_true) == 0)\n",
    "\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        epoch_train_precisions.append(train_precision)\n",
    "        epoch_val_precisions.append(val_precision)\n",
    "        epoch_train_recalls.append(train_recall)\n",
    "        epoch_val_recalls.append(val_recall)\n",
    "        epoch_train_f1s.append(train_f1)\n",
    "        epoch_val_f1s.append(val_f1)\n",
    "        epoch_train_losses.append(train_loss)\n",
    "        epoch_val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    fold_results.append({\n",
    "        'train_accuracy': epoch_train_accuracies,\n",
    "        'val_accuracy': epoch_val_accuracies,\n",
    "        'train_precision': epoch_train_precisions,\n",
    "        'val_precision': epoch_val_precisions,\n",
    "        'train_recall': epoch_train_recalls,\n",
    "        'val_recall': epoch_val_recalls,\n",
    "        'train_f1': epoch_train_f1s,\n",
    "        'val_f1': epoch_val_f1s,\n",
    "        'train_loss': epoch_train_losses,\n",
    "        'val_loss': epoch_val_losses,\n",
    "        'val_sensitivity': val_sensitivity,\n",
    "        'val_specificity': val_specificity,\n",
    "        'val_preds': val_fold_preds,\n",
    "        'val_true': val_fold_true,\n",
    "        'updrs_results': updrs_results\n",
    "    })\n",
    "\n",
    "# Final averages\n",
    "final_train_accuracies = [result['train_accuracy'][-1] for result in fold_results]\n",
    "final_val_accuracies = [result['val_accuracy'][-1] for result in fold_results]\n",
    "final_train_precisions = [result['train_precision'][-1] for result in fold_results]\n",
    "final_val_precisions = [result['val_precision'][-1] for result in fold_results]\n",
    "final_train_recalls = [result['train_recall'][-1] for result in fold_results]\n",
    "final_val_recalls = [result['val_recall'][-1] for result in fold_results]\n",
    "final_train_f1s = [result['train_f1'][-1] for result in fold_results]\n",
    "final_val_f1s = [result['val_f1'][-1] for result in fold_results]\n",
    "final_val_sensitivities = [result['val_sensitivity'] for result in fold_results]\n",
    "final_val_specificities = [result['val_specificity'] for result in fold_results]\n",
    "\n",
    "average_train_accuracy = np.mean(final_train_accuracies)\n",
    "average_val_accuracy = np.mean(final_val_accuracies)\n",
    "average_train_precision = np.mean(final_train_precisions)\n",
    "average_val_precision = np.mean(final_val_precisions)\n",
    "average_train_recall = np.mean(final_train_recalls)\n",
    "average_val_recall = np.mean(final_val_recalls)\n",
    "average_train_f1 = np.mean(final_train_f1s)\n",
    "average_val_f1 = np.mean(final_val_f1s)\n",
    "average_val_sensitivity = np.mean(final_val_sensitivities)\n",
    "average_val_specificity = np.mean(final_val_specificities)\n",
    "\n",
    "print(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\")\n",
    "print(f\"Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {average_train_precision:.4f}\")\n",
    "print(f\"Validation Precision: {average_val_precision:.4f}\")\n",
    "print(f\"Training Recall: {average_train_recall:.4f}\")\n",
    "print(f\"Validation Recall: {average_val_recall:.4f}\")\n",
    "print(f\"Training F1-Score: {average_train_f1:.4f}\")\n",
    "print(f\"Validation F1-Score: {average_val_f1:.4f}\")\n",
    "print(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\")\n",
    "print(f\"Validation Specificity: {average_val_specificity:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI-3S3diUQ21"
   },
   "outputs": [],
   "source": [
    "def calculate_average_metrics(fold_results):\n",
    "    \"\"\"\n",
    "    Calculates and prints the average metrics across all folds.\n",
    "    Args:\n",
    "        fold_results (list): List containing results for each fold.\n",
    "    \"\"\"\n",
    "    avg_train_accuracies = [np.mean(fold['train_accuracy']) for fold in fold_results]\n",
    "    avg_val_accuracies = [np.mean(fold['val_accuracy']) for fold in fold_results]\n",
    "    avg_train_precisions = [np.mean(fold['train_precision']) for fold in fold_results]\n",
    "    avg_val_precisions = [np.mean(fold['val_precision']) for fold in fold_results]\n",
    "    avg_train_recalls = [np.mean(fold['train_recall']) for fold in fold_results]\n",
    "    avg_val_recalls = [np.mean(fold['val_recall']) for fold in fold_results]\n",
    "    avg_train_f1s = [np.mean(fold['train_f1']) for fold in fold_results]\n",
    "    avg_val_f1s = [np.mean(fold['val_f1']) for fold in fold_results]\n",
    "\n",
    "    print(\"\\n===== Average Metrics Across Folds =====\")\n",
    "    print(f\"Average Training Accuracy: {np.mean(avg_train_accuracies):.4f}\")\n",
    "    print(f\"Average Validation Accuracy: {np.mean(avg_val_accuracies):.4f}\")\n",
    "    print(f\"Average Training Precision: {np.mean(avg_train_precisions):.4f}\")\n",
    "    print(f\"Average Validation Precision: {np.mean(avg_val_precisions):.4f}\")\n",
    "    print(f\"Average Training Recall: {np.mean(avg_train_recalls):.4f}\")\n",
    "    print(f\"Average Validation Recall: {np.mean(avg_val_recalls):.4f}\")\n",
    "    print(f\"Average Training F1-Score: {np.mean(avg_train_f1s):.4f}\")\n",
    "    print(f\"Average Validation F1-Score: {np.mean(avg_val_f1s):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1732555342521,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "xs46xyq6vNh6",
    "outputId": "0f52211a-58fe-44c0-b4ca-c96b04da03e5"
   },
   "outputs": [],
   "source": [
    "aggregated_updrs_metrics, probabilities_by_updrs = aggregate_updrs_results(fold_results)\n",
    "\n",
    "print(\"\\n===== Aggregated UPDRS Metrics Across Folds =====\")\n",
    "for level, metrics in aggregated_updrs_metrics.items():\n",
    "    print(f\"UPDRS Level {level}:\")\n",
    "    print(f\"  Total Count: {metrics['total_count']}\")\n",
    "    print(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\")\n",
    "    print(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1732555343538,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "3L7A4n3SvR1A",
    "outputId": "ebf3d2fb-4525-4a2c-9011-f743611ac32d"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs):\n",
    "    levels = list(aggregated_updrs_metrics.keys())\n",
    "    total_counts = [aggregated_updrs_metrics[level]['total_count'] for level in levels]\n",
    "    mean_probs = [aggregated_updrs_metrics[level]['mean_probability'] for level in levels]\n",
    "    mean_logits = [aggregated_updrs_metrics[level]['mean_logit'] for level in levels]\n",
    "    percentages_classified = [aggregated_updrs_metrics[level]['percentage_classified_as_parkinsonian'] for level in levels]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=mean_probs, palette='Blues_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Mean Probability')\n",
    "    plt.title('Mean Probability of Being Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data = [(level, prob) for level, probs in probabilities_by_updrs.items() for prob in probs]\n",
    "    df = pd.DataFrame(data, columns=['UPDRS Level', 'Probability'])\n",
    "    sns.boxplot(x='UPDRS Level', y='Probability', data=df, palette='Pastel1')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Distribution of Probabilities by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=percentages_classified, palette='Oranges_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Percentage Classified as Parkinsonian')\n",
    "    plt.title('Percentage Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=total_counts, palette='Greens_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Total Count')\n",
    "    plt.title('Total Data Count by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3fca2fd823fd4633a212bd5ff35bae41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_eb871e0a2cf246eb93f6489ed290db4d",
      "style": "IPY_MODEL_877f55be688144bda1c702fdc7b66c14",
      "value": true
     }
    },
    "6114f3834a384a17a9d61ceab7d892c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65e7482b4426451d99a65176fd3ea7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df10da2e305d4eeda5a15249ebb7d866",
      "placeholder": "​",
      "style": "IPY_MODEL_6114f3834a384a17a9d61ceab7d892c2",
      "value": "Connecting..."
     }
    },
    "6b89a1e004d049ecb56977799598e9d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da857d2ca0694f68aa05da1dc7f37784",
      "placeholder": "​",
      "style": "IPY_MODEL_7f09db369eb54075ab1d7b1cdf7c7cdf",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "6e7822e5de834110ad02abbf50d270a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_d05346a3b7eb4bc5b4155268b8ba553f"
     }
    },
    "7f09db369eb54075ab1d7b1cdf7c7cdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "877f55be688144bda1c702fdc7b66c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b7a38656bbb44ae911e16bf2d880946": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4f54d574afd4ac19f384222705c5917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6007a0a4f2d4fe18e82a5e86336f86f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0deb85faa9a4d1495428d602c3edc72",
      "placeholder": "​",
      "style": "IPY_MODEL_d679ebeafd784554907bae9ba0558711",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "a8c299f851fc44acb5b5975a1190eb85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "cbb2e75fe60347f8a9eec0b1ed499648": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_e0a85f128e8f4192ba8a16e68a714089",
      "placeholder": "​",
      "style": "IPY_MODEL_a4f54d574afd4ac19f384222705c5917",
      "value": ""
     }
    },
    "d05346a3b7eb4bc5b4155268b8ba553f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "d679ebeafd784554907bae9ba0558711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da857d2ca0694f68aa05da1dc7f37784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df10da2e305d4eeda5a15249ebb7d866": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0a85f128e8f4192ba8a16e68a714089": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0deb85faa9a4d1495428d602c3edc72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb871e0a2cf246eb93f6489ed290db4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f90a98419dbd4aa8900bec1c35887c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_9b7a38656bbb44ae911e16bf2d880946",
      "style": "IPY_MODEL_a8c299f851fc44acb5b5975a1190eb85",
      "tooltip": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
