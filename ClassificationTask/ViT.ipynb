{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "55bd4abb96054413abf41c8c398b34fd",
      "d81b6ae24249436c8ea25c0bb26c397c",
      "d28a9833c3384c6cb5fc99f8763b37dc",
      "113f3d569b3f48cb8bea1216fbec243f",
      "d85fa1ff95884f619d259efc55a4b762",
      "445d4f53ebc94b00ab5e63c0f144e47a",
      "bbcbccaf836348dc92980f7bb925d8f4",
      "49cd72e8195949f3b4dcd875deeab540",
      "ad2463147e294cf7a08dbdd73242ee50",
      "35cf7f3bb4a1431c98f535a2f955488a",
      "d6872028421244dcbee7aa8ef5e8771d",
      "204ea7de62e64cb0bd0bb14855c859bf",
      "cc00aba84af842c4897c952abc37de55",
      "a0d7c3cb91314136aec6309d75fd0662",
      "29849dbae7e74129ba145927db2a178f",
      "85c27e364204475989447a081cdd16af",
      "bfd8cc85333243b0aa9161d8cbdec11d"
     ]
    },
    "executionInfo": {
     "elapsed": 7740,
     "status": "ok",
     "timestamp": 1732563920824,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "Yu9klbCVHaoH",
    "outputId": "eed116ad-55e0-4b18-d1d7-e4d96ffc05d0"
   },
   "outputs": [],
   "source": [
    "# Section 1: Setup and Libraries\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "import os\n",
    "from google.colab import drive\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set the theme for seaborn\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n",
    "\n",
    "# HF Token (add your HF token here)\n",
    "from huggingface_hub import login  # Import the login function from Hugging Face Hub\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "hf_token = os.getenv(\"HF_TOKEN\")  # Retrieve the Hugging Face token from environment variables\n",
    "login(token=hf_token)  # Log in to Hugging Face using the token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3973,
     "status": "ok",
     "timestamp": 1732563924794,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "Kkx2BdHGHu6Z",
    "outputId": "9d8a7118-4be4-4d84-cd0e-ecf8298320dd"
   },
   "outputs": [],
   "source": [
    "# Section 2: Google Drive Setup and Data Loading\n",
    "\n",
    "# Mount Google Drive to access data\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set the path to the TESI directory in Google Drive\n",
    "tesi_path = '/content/drive/My Drive/TESI'\n",
    "os.chdir(tesi_path)  # Change the working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the Pickle file containing the dataset\n",
    "import pickle\n",
    "file_path = '/content/drive/MyDrive/TESI/newdata_updated.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    newdata = pickle.load(f)\n",
    "\n",
    "print(\"Pickle file loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKI0vqdxLJkT"
   },
   "outputs": [],
   "source": [
    "def print_updrs_distribution(data, label_key='label', updrs_keys=['updrs', 'UPDRS']):\n",
    "    \"\"\"\n",
    "    Prints the distribution of data based on UPDRS levels and labels.\n",
    "\n",
    "    Args:\n",
    "        data (list): Dataset containing 'label' and 'updrs' or 'UPDRS' information.\n",
    "        label_key (str): Key for the label (0 = control, 1 = Parkinsonian).\n",
    "        updrs_keys (list): Possible keys for the UPDRS value in the data.\n",
    "    \"\"\"\n",
    "    # Counters for labels and UPDRS\n",
    "    updrs_counts = defaultdict(int)\n",
    "    control_count, parkinsonian_count = 0, 0\n",
    "\n",
    "    for item in data:\n",
    "        # Check for the presence of the label key\n",
    "        if label_key in item:\n",
    "            label = item[label_key]\n",
    "            if label == 0:\n",
    "                control_count += 1\n",
    "            elif label == 1:\n",
    "                parkinsonian_count += 1\n",
    "\n",
    "        # Check for the presence of at least one UPDRS key\n",
    "        updrs_value = None\n",
    "        for key in updrs_keys:\n",
    "            if key in item:\n",
    "                updrs_value = item[key]\n",
    "                break\n",
    "\n",
    "        # Increment the count for the UPDRS level\n",
    "        if updrs_value is not None:\n",
    "            updrs_counts[updrs_value] += 1\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Number of controls: {control_count}\")\n",
    "    print(f\"Number of Parkinsonians: {parkinsonian_count}\")\n",
    "    print(\"UPDRS Distribution:\")\n",
    "    for updrs_value, count in sorted(updrs_counts.items()):\n",
    "        print(f\"  UPDRS {updrs_value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1732563925579,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "MMFdkJGKHwGr",
    "outputId": "8c29b3f2-64f3-4f81-b1b7-82925c79417e"
   },
   "outputs": [],
   "source": [
    "# Define the standard audio sampling rate\n",
    "sampling_rate = 44100  # 44.1 kHz\n",
    "\n",
    "# Calculate audio lengths in samples and convert to seconds\n",
    "audio_lengths = [len(item['audio']) for item in newdata]\n",
    "audio_lengths_sec = [length / sampling_rate for length in audio_lengths]\n",
    "\n",
    "# Plot the distribution of audio lengths before processing\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(audio_lengths_sec, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (Before Processing)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics about the audio lengths\n",
    "print(f\"Number of audios: {len(audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length: {min(audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length: {max(audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "# Remove outliers based on audio length using the Interquartile Range (IQR) method\n",
    "q1 = np.percentile(audio_lengths, 25)\n",
    "q3 = np.percentile(audio_lengths, 75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Define acceptable range for audio lengths\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filter audios within the acceptable range\n",
    "filtered_data = [item for item in newdata if lower_bound <= len(item['audio']) <= upper_bound]\n",
    "\n",
    "# Extract lengths after filtering\n",
    "filtered_audio_lengths = [len(item['audio']) for item in filtered_data]\n",
    "filtered_audio_lengths_sec = [length / sampling_rate for length in filtered_audio_lengths]\n",
    "\n",
    "# Plot the distribution after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_audio_lengths_sec, bins=50, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (After Removing Outliers)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics after filtering\n",
    "print(f\"Number of audios after removing outliers: {len(filtered_audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length after filtering: {min(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length after filtering: {max(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "# Find the shortest audio length (n) in samples\n",
    "min_length = min(filtered_audio_lengths)\n",
    "print(f\"The shortest audio length is: {min_length / sampling_rate:.2f} seconds ({min_length} samples)\")\n",
    "\n",
    "# Before removing outliers\n",
    "print(\"Distribution BEFORE outlier removal:\")\n",
    "print_updrs_distribution(newdata)\n",
    "\n",
    "# After removing outliers\n",
    "print(\"Distribution AFTER outlier removal:\")\n",
    "print_updrs_distribution(filtered_data)\n",
    "\n",
    "\n",
    "# Update 'newdata' to 'filtered_data' for further processing\n",
    "newdata = filtered_data\n",
    "# Preprocess the audios by trimming to the central part\n",
    "print(\"Preprocessing audios...\")\n",
    "min_length = min([len(item['audio']) for item in newdata])\n",
    "for item in newdata:\n",
    "    audio_trimmed = item['audio']\n",
    "    start = (len(audio_trimmed) - min_length) // 2\n",
    "    end = start + min_length\n",
    "    item['audio'] = audio_trimmed[start:end]  # Trim audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 14255,
     "status": "ok",
     "timestamp": 1732563939831,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "CuivIcOrHzfW",
    "outputId": "e4a0e218-5376-41fa-8261-dda3faba35b5"
   },
   "outputs": [],
   "source": [
    "# Section 4: Mel-Spectrogram Creation and RGB Conversion\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Mel-Spectrogram for each audio\n",
    "print(\"Creating Mel-Spectrograms...\")\n",
    "for item in newdata:\n",
    "    audio = np.array(item['audio'])\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=44100)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    item['audio'] = mel_spectrogram_db  # Replace with Mel-Spectrogram\n",
    "\n",
    "# Convert Mel-Spectrogram to RGB\n",
    "def convert_to_rgb(mel_spec):\n",
    "    resized_mel_spec = cv2.resize(mel_spec, (224, 224))  # Resize to 224x224\n",
    "    resized_mel_spec = (resized_mel_spec - np.min(resized_mel_spec)) / (np.max(resized_mel_spec) - np.min(resized_mel_spec))  # Normalize\n",
    "    return np.stack([resized_mel_spec] * 3, axis=-1)  # Convert to 3-channel RGB\n",
    "\n",
    "# Convert all Mel-Spectrograms to RGB\n",
    "for item in newdata:\n",
    "    item['audio'] = convert_to_rgb(item['audio'])  # Convert each Mel-Spectrogram to RGB\n",
    "\n",
    "# Function to plot 5 random Mel-Spectrograms with their labels\n",
    "def plot_random_mel_spectrograms(data, num_samples=5):\n",
    "    random_samples = random.sample(data, num_samples)  # Get 5 random samples\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))  # Create subplots\n",
    "\n",
    "    for i, sample in enumerate(random_samples):\n",
    "        mel_rgb = sample['audio']  # Get the Mel-Spectrogram in RGB\n",
    "        label = sample['label']  # Get the label\n",
    "\n",
    "        axes[i].imshow(mel_rgb)  # Plot the spectrogram\n",
    "        axes[i].set_title(f\"Label: {label}\")  # Set the title with the label\n",
    "        axes[i].axis('off')  # Hide axis for cleaner look\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot 5 random Mel-Spectrograms with their labels\n",
    "plot_random_mel_spectrograms(newdata, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1iGx646H7Qe"
   },
   "outputs": [],
   "source": [
    "# Section 5: Dataset and DataLoader Preparation\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Lista di campioni (dizionari) contenenti 'audio', 'label', e metadati come 'updrs'.\n",
    "            transform: Trasformazioni da applicare ai dati (es. normalizzazione, data augmentation).\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx: Indice del campione.\n",
    "        Returns:\n",
    "            image: Dati audio trasformati (es. Mel-spectrogram).\n",
    "            label: Etichetta corrispondente (0 o 1).\n",
    "            metadata: Dizionario contenente metadati, come UPDRS.\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        image = sample['audio']\n",
    "        label = sample['label']\n",
    "\n",
    "        # Controlla se esistono le chiavi 'updrs' o 'UPDRS'\n",
    "        if 'updrs' in sample:\n",
    "            updrs_value = sample['updrs']\n",
    "        elif 'UPDRS' in sample:\n",
    "            updrs_value = sample['UPDRS']\n",
    "        else:\n",
    "            updrs_value = -1  # Assegna -1 se nessuna chiave è presente\n",
    "\n",
    "        metadata = {'updrs': updrs_value}\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, metadata\n",
    "\n",
    "# Define data augmentation and normalization transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10)\n",
    "])\n",
    "\n",
    "# Group the data by subject ID and label (for balancing)\n",
    "grouped_by_id = defaultdict(list)\n",
    "for item in newdata:\n",
    "    grouped_by_id[item['id']].append(item)\n",
    "\n",
    "# List all subject IDs\n",
    "all_ids = list(grouped_by_id.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JKm9YaV5_po"
   },
   "outputs": [],
   "source": [
    "def analyze_updrs(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Analyze logits and probabilities by UPDRS levels.\n",
    "    Args:\n",
    "        val_loader: Validation data loader.\n",
    "        model: Trained model.\n",
    "        device: Device (CPU or GPU).\n",
    "    Returns:\n",
    "        updrs_results: Dictionary with logits, probabilities, and true labels grouped by UPDRS levels.\n",
    "    \"\"\"\n",
    "    updrs_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    # Validation phase: Calculate logits and probabilities for each UPDRS level\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, metadata in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "\n",
    "            # Calculate probabilities and logits\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of being Parkinsonian\n",
    "            logits = outputs[:, 1]  # Logit for Parkinsonian class\n",
    "\n",
    "            for i, prob in enumerate(probabilities.cpu().numpy()):\n",
    "                logit = logits[i].item()\n",
    "                updrs_value = metadata['updrs'][i]  # Access UPDRS metadata\n",
    "\n",
    "                if isinstance(updrs_value, torch.Tensor):\n",
    "                    updrs_value = updrs_value.item()\n",
    "                if updrs_value != -1:  # Skip invalid UPDRS values\n",
    "                    updrs_results[int(updrs_value)].append((logit, prob, labels[i].item()))\n",
    "\n",
    "    return updrs_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ8i_yN7whcg"
   },
   "outputs": [],
   "source": [
    "def aggregate_updrs_results(fold_results):\n",
    "    \"\"\"\n",
    "    Aggregates UPDRS results across all folds.\n",
    "\n",
    "    Args:\n",
    "        fold_results (list): List of dictionaries, where each dictionary contains\n",
    "                             'updrs_results' for a fold.\n",
    "\n",
    "    Returns:\n",
    "        aggregated_results (dict): Dictionary with aggregated metrics for each UPDRS level.\n",
    "                                   Keys: {0, 1, 2, 3, 4}\n",
    "                                   Values: Dict with:\n",
    "                                       - 'total_count': Total samples with this UPDRS level.\n",
    "                                       - 'mean_probability': Mean probability for Parkinsonian classification.\n",
    "                                       - 'mean_logit': Mean logit value for Parkinsonian class.\n",
    "                                       - 'percentage_classified_as_parkinsonian': Percentage classified as Parkinsonian.\n",
    "        probabilities_by_updrs (dict): Dictionary containing all individual probabilities for each UPDRS level.\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary for each UPDRS level\n",
    "    aggregated_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    probabilities_by_updrs = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    # Collect all results from all folds\n",
    "    for fold in fold_results:\n",
    "        updrs_results = fold['updrs_results']\n",
    "        for level, values in updrs_results.items():\n",
    "            aggregated_results[level].extend(values)  # Combine results across folds\n",
    "            probabilities_by_updrs[level].extend([prob for _, prob, _ in values])  # Collect probabilities\n",
    "\n",
    "    # Calculate aggregated metrics\n",
    "    metrics = {}\n",
    "    for level, results in aggregated_results.items():\n",
    "        if results:\n",
    "            # Extract logits, probabilities, and true labels\n",
    "            logits, probs, true_labels = zip(*results)\n",
    "            mean_prob = np.mean(probs)  # Mean probability\n",
    "            mean_logit = np.mean(logits)  # Mean logit value\n",
    "            total_count = len(results)  # Total count for this UPDRS level\n",
    "            classified_as_parkinsonian = sum(1 for prob, label in zip(probs, true_labels) if prob >= 0.5 and label == 1)\n",
    "            percentage_classified_as_parkinsonian = (classified_as_parkinsonian / total_count) * 100\n",
    "\n",
    "            # Store metrics\n",
    "            metrics[level] = {\n",
    "                'total_count': total_count,\n",
    "                'mean_probability': mean_prob,\n",
    "                'mean_logit': mean_logit,\n",
    "                'percentage_classified_as_parkinsonian': percentage_classified_as_parkinsonian,\n",
    "            }\n",
    "        else:\n",
    "            # Handle cases with no data for this UPDRS level\n",
    "            metrics[level] = {\n",
    "                'total_count': 0,\n",
    "                'mean_probability': 0.0,\n",
    "                'mean_logit': 0.0,\n",
    "                'percentage_classified_as_parkinsonian': 0.0,\n",
    "            }\n",
    "\n",
    "    return metrics, probabilities_by_updrs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUYsz8NGH_l0"
   },
   "outputs": [],
   "source": [
    "# Section 6: Balanced Data Splitting Function\n",
    "\n",
    "def stratified_group_split(all_ids, grouped_by_id, label_key='label'):\n",
    "    # Split into Parkinson's and control groups\n",
    "    controls = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 0]\n",
    "    parkinsons = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 1]\n",
    "\n",
    "    random.shuffle(controls)\n",
    "    random.shuffle(parkinsons)\n",
    "\n",
    "    split_controls = len(controls) // 5\n",
    "    split_parkinsons = len(parkinsons) // 5\n",
    "\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        fold_controls = controls[i * split_controls:(i + 1) * split_controls]\n",
    "        fold_parkinsons = parkinsons[i * split_parkinsons:(i + 1) * split_parkinsons]\n",
    "        folds.append(fold_controls + fold_parkinsons)\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 907251,
     "status": "ok",
     "timestamp": 1732574362581,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "uohcZvgSKotN",
    "outputId": "c4ac3e09-c780-44db-9a79-fe3abfee1656"
   },
   "outputs": [],
   "source": [
    "# Section 7: Model Configuration and Cross-Validation\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 300  # Number of epochs\n",
    "batch_size = 64   # Batch size\n",
    "early_stopping_patience = 30  # Patience for early stopping\n",
    "learning_rate = 0.001  # Initial learning rate\n",
    "\n",
    "# K-Fold Cross-Validation setup\n",
    "print(\"Starting K-Fold Cross Validation...\")\n",
    "folds = stratified_group_split(all_ids, grouped_by_id)  # Generate stratified folds\n",
    "\n",
    "# Lists to store metrics across folds\n",
    "fold_results = []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_precisions, val_precisions = [], []\n",
    "train_recalls, val_recalls = [], []\n",
    "train_f1s, val_f1s = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, val_ids in enumerate(folds):\n",
    "    print(f'\\nFOLD {fold + 1}')\n",
    "\n",
    "    # Prepare training and validation IDs\n",
    "    train_ids = [id_ for id_ in all_ids if id_ not in val_ids]\n",
    "    train_samples = [item for id_soggetto in train_ids for item in grouped_by_id[id_soggetto]]\n",
    "    val_samples = [item for id_soggetto in val_ids for item in grouped_by_id[id_soggetto]]\n",
    "\n",
    "    # Get labels for each set\n",
    "    train_labels = [item['label'] for item in train_samples]\n",
    "    val_labels = [item['label'] for item in val_samples]\n",
    "\n",
    "    # Print training and validation set statistics\n",
    "    print(f\"Training set: {len(train_samples)} samples - Controls: {train_labels.count(0)}, Parkinson's: {train_labels.count(1)}\")\n",
    "    print(f\"Validation set: {len(val_samples)} samples - Controls: {val_labels.count(0)}, Parkinson's: {val_labels.count(1)}\")\n",
    "\n",
    "    # Create datasets and data loaders\n",
    "    train_dataset = AudioDataset(train_samples, transform=data_transforms)\n",
    "    val_dataset = AudioDataset(val_samples, transform=data_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "      # Initialize and configure the model\n",
    "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "\n",
    "    # Freezing all layers except the classifier\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  # Freeze all layers initially\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True  # Unfreeze the classifier head\n",
    "\n",
    "    # Set up device, loss function, optimizer, and learning rate scheduler\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "\n",
    "    # Initialize training variables\n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "    epoch_train_accuracies, epoch_val_accuracies = [], []\n",
    "    epoch_train_precisions, epoch_val_precisions = [], []\n",
    "    epoch_train_recalls, epoch_val_recalls = [], []\n",
    "    epoch_train_f1s, epoch_val_f1s = [], []\n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    val_fold_preds, val_fold_true = [], []\n",
    "\n",
    "    # Training loop for the current fold\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct_train = 0.0, 0\n",
    "        train_preds, train_true = [], []\n",
    "\n",
    "        for inputs, labels, _ in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_train += torch.sum(preds == labels).item()\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and store training metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_precision = precision_score(train_true, train_preds, zero_division=0)\n",
    "        train_recall = recall_score(train_true, train_preds)\n",
    "        train_f1 = f1_score(train_true, train_preds)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct_val = 0.0, 0\n",
    "        val_preds, val_true = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct_val += torch.sum(preds == labels).item()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        updrs_results = analyze_updrs(val_loader, model, device)\n",
    "\n",
    "\n",
    "        # Calculate and store validation metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "          # Calculate metrics for validation\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_precision = precision_score(val_true, val_preds, zero_division=0)\n",
    "        val_recall = recall_score(val_true, val_preds)\n",
    "        val_f1 = f1_score(val_true, val_preds)\n",
    "        val_sensitivity = val_recall  # Sensitivity is the same as recall in binary classification\n",
    "\n",
    "        # Corrected specificity calculation\n",
    "        true_negatives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 0))\n",
    "        false_positives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 1))\n",
    "        val_specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "\n",
    "        # Append epoch metrics\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        epoch_train_precisions.append(train_precision)\n",
    "        epoch_val_precisions.append(val_precision)\n",
    "        epoch_train_recalls.append(train_recall)\n",
    "        epoch_val_recalls.append(val_recall)\n",
    "        epoch_train_f1s.append(train_f1)\n",
    "        epoch_val_f1s.append(val_f1)\n",
    "        epoch_train_losses.append(train_loss)\n",
    "        epoch_val_losses.append(val_loss)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # Learning rate adjustment\n",
    "        scheduler.step()\n",
    "\n",
    "    # Store results for this fold\n",
    "    fold_results.append({\n",
    "        'train_accuracy': epoch_train_accuracies,\n",
    "        'val_accuracy': epoch_val_accuracies,\n",
    "        'train_precision': epoch_train_precisions,\n",
    "        'val_precision': epoch_val_precisions,\n",
    "        'train_recall': epoch_train_recalls,\n",
    "        'val_recall': epoch_val_recalls,\n",
    "        'train_f1': epoch_train_f1s,\n",
    "        'val_f1': epoch_val_f1s,\n",
    "        'train_loss': epoch_train_losses,\n",
    "        'val_loss': epoch_val_losses,\n",
    "        'val_sensitivity': val_sensitivity,\n",
    "        'val_specificity': val_specificity,\n",
    "        'val_preds': val_fold_preds,\n",
    "        'val_true': val_fold_true,\n",
    "        'updrs_results': updrs_results  # Add UPDRS results here\n",
    "    })\n",
    "\n",
    "# Calculate and print final average metrics across all folds (only the last epoch of each fold)\n",
    "final_train_accuracies = [result['train_accuracy'][-1] for result in fold_results]\n",
    "final_val_accuracies = [result['val_accuracy'][-1] for result in fold_results]\n",
    "final_train_precisions = [result['train_precision'][-1] for result in fold_results]\n",
    "final_val_precisions = [result['val_precision'][-1] for result in fold_results]\n",
    "final_train_recalls = [result['train_recall'][-1] for result in fold_results]\n",
    "final_val_recalls = [result['val_recall'][-1] for result in fold_results]\n",
    "final_train_f1s = [result['train_f1'][-1] for result in fold_results]\n",
    "final_val_f1s = [result['val_f1'][-1] for result in fold_results]\n",
    "final_val_sensitivities = [result['val_sensitivity'] for result in fold_results]\n",
    "final_val_specificities = [result['val_specificity'] for result in fold_results]\n",
    "\n",
    "# Calculate averages across folds\n",
    "average_train_accuracy = np.mean(final_train_accuracies)\n",
    "average_val_accuracy = np.mean(final_val_accuracies)\n",
    "average_train_precision = np.mean(final_train_precisions)\n",
    "average_val_precision = np.mean(final_val_precisions)\n",
    "average_train_recall = np.mean(final_train_recalls)\n",
    "average_val_recall = np.mean(final_val_recalls)\n",
    "average_train_f1 = np.mean(final_train_f1s)\n",
    "average_val_f1 = np.mean(final_val_f1s)\n",
    "average_val_sensitivity = np.mean(final_val_sensitivities)\n",
    "average_val_specificity = np.mean(final_val_specificities)\n",
    "\n",
    "# Print final average metrics\n",
    "print(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\")\n",
    "print(f\"Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {average_train_precision:.4f}\")\n",
    "print(f\"Validation Precision: {average_val_precision:.4f}\")\n",
    "print(f\"Training Recall: {average_train_recall:.4f}\")\n",
    "print(f\"Validation Recall: {average_val_recall:.4f}\")\n",
    "print(f\"Training F1-Score: {average_train_f1:.4f}\")\n",
    "print(f\"Validation F1-Score: {average_val_f1:.4f}\")\n",
    "print(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\")\n",
    "print(f\"Validation Specificity: {average_val_specificity:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1732574362583,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "jAU1JambwoaS",
    "outputId": "7a2a9dcc-643b-44ba-eb1e-1e52ee86c3a6"
   },
   "outputs": [],
   "source": [
    "# Dopo il ciclo di cross-validation\n",
    "aggregated_updrs_metrics, probabilities_by_updrs = aggregate_updrs_results(fold_results)\n",
    "\n",
    "# Stampa dei risultati aggregati\n",
    "print(\"\\n===== Aggregated UPDRS Metrics Across Folds =====\")\n",
    "for level, metrics in aggregated_updrs_metrics.items():\n",
    "    print(f\"UPDRS Level {level}:\")\n",
    "    print(f\"  Total Count: {metrics['total_count']}\")\n",
    "    print(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\")\n",
    "    print(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "executionInfo": {
     "elapsed": 15757,
     "status": "ok",
     "timestamp": 1732574378334,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "XX26yfsjIFzg",
    "outputId": "37984136-7d21-45f5-bc86-21f31d68965f"
   },
   "outputs": [],
   "source": [
    "# Section 8: Results and Visualization\n",
    "\n",
    "# Plotting function for fold metrics\n",
    "def plot_fold_metrics(train_metrics, val_metrics, metric_name, fold_num, subplot_position):\n",
    "    plt.subplot(5, 5, subplot_position)\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, label=f'Training', alpha=0.6)\n",
    "    plt.plot(epochs, val_metrics, label=f'Validation', alpha=0.6, linestyle='dashed')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f'{metric_name} - Fold {fold_num}')\n",
    "\n",
    "# Plot accuracies and other metrics across all folds\n",
    "print(\"Plotting results...\")\n",
    "plt.figure(figsize=(25, 20))\n",
    "\n",
    "# Plotting Training and Validation Accuracy for each fold\n",
    "for fold_num, fold_result in enumerate(fold_results, 1):\n",
    "    plot_fold_metrics(fold_result['train_accuracy'], fold_result['val_accuracy'], 'Accuracy', fold_num, fold_num)\n",
    "\n",
    "# Plotting Training and Validation Precision for each fold\n",
    "for fold_num, fold_result in enumerate(fold_results, 1):\n",
    "    plot_fold_metrics(fold_result['train_precision'], fold_result['val_precision'], 'Precision', fold_num, fold_num + 5)\n",
    "\n",
    "# Plotting Training and Validation Recall for each fold\n",
    "for fold_num, fold_result in enumerate(fold_results, 1):\n",
    "    plot_fold_metrics(fold_result['train_recall'], fold_result['val_recall'], 'Recall', fold_num, fold_num + 10)\n",
    "\n",
    "# Plotting Training and Validation F1-Score for each fold\n",
    "for fold_num, fold_result in enumerate(fold_results, 1):\n",
    "    plot_fold_metrics(fold_result['train_f1'], fold_result['val_f1'], 'F1-Score', fold_num, fold_num + 15)\n",
    "\n",
    "# Plotting Training and Validation Loss for each fold\n",
    "for fold_num, fold_result in enumerate(fold_results, 1):\n",
    "    plot_fold_metrics(fold_result['train_loss'], fold_result['val_loss'], 'Loss', fold_num, fold_num + 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732574378335,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "ylgQ7QquTu8a",
    "outputId": "500651f6-7a86-4774-9602-4da3aba168fb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs):\n",
    "    # Prepare data for plotting\n",
    "    levels = list(aggregated_updrs_metrics.keys())\n",
    "    total_counts = [aggregated_updrs_metrics[level]['total_count'] for level in levels]\n",
    "    mean_probs = [aggregated_updrs_metrics[level]['mean_probability'] for level in levels]\n",
    "    mean_logits = [aggregated_updrs_metrics[level]['mean_logit'] for level in levels]\n",
    "    percentages_classified = [aggregated_updrs_metrics[level]['percentage_classified_as_parkinsonian'] for level in levels]\n",
    "\n",
    "    # Bar chart for mean probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=mean_probs, palette='Blues_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Mean Probability')\n",
    "    plt.title('Mean Probability of Being Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot for probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data = [(level, prob) for level, probs in probabilities_by_updrs.items() for prob in probs]\n",
    "    df = pd.DataFrame(data, columns=['UPDRS Level', 'Probability'])\n",
    "    sns.boxplot(x='UPDRS Level', y='Probability', data=df, palette='Pastel1')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Distribution of Probabilities by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for percentage classified as Parkinsonian\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=percentages_classified, palette='Oranges_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Percentage Classified as Parkinsonian')\n",
    "    plt.title('Percentage Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for total count\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=total_counts, palette='Greens_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Total Count')\n",
    "    plt.title('Total Data Count by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after calculating metrics\n",
    "plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732574378336,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "Op19B7LHhAAK",
    "outputId": "d2a140a6-f498-400a-fe51-e492a91eeaba"
   },
   "outputs": [],
   "source": [
    "# Nome del file per salvare tutti i risultati\n",
    "results_filename = \"results_ViT.txt\"\n",
    "\n",
    "# Scrivi tutti i risultati in un unico file\n",
    "with open(results_filename, mode=\"w\") as file:\n",
    "    # Scrivi i risultati UPDRS\n",
    "    file.write(\"===== Aggregated UPDRS Metrics Across Folds =====\\n\")\n",
    "    for level, metrics in aggregated_updrs_metrics.items():\n",
    "        file.write(f\"UPDRS Level {level}:\\n\")\n",
    "        file.write(f\"  Total Count: {metrics['total_count']}\\n\")\n",
    "        file.write(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\\n\")\n",
    "        file.write(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\\n\")\n",
    "        file.write(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "    # Scrivi le metriche medie sui fold\n",
    "    file.write(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\\n\")\n",
    "    file.write(f\"Training Accuracy: {average_train_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Validation Accuracy: {average_val_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Training Precision: {average_train_precision:.4f}\\n\")\n",
    "    file.write(f\"Validation Precision: {average_val_precision:.4f}\\n\")\n",
    "    file.write(f\"Training Recall: {average_train_recall:.4f}\\n\")\n",
    "    file.write(f\"Validation Recall: {average_val_recall:.4f}\\n\")\n",
    "    file.write(f\"Training F1-Score: {average_train_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation F1-Score: {average_val_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\\n\")\n",
    "    file.write(f\"Validation Specificity: {average_val_specificity:.4f}\\n\")\n",
    "\n",
    "print(f\"All results saved to {results_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "113f3d569b3f48cb8bea1216fbec243f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_204ea7de62e64cb0bd0bb14855c859bf",
      "style": "IPY_MODEL_cc00aba84af842c4897c952abc37de55",
      "value": true
     }
    },
    "204ea7de62e64cb0bd0bb14855c859bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29849dbae7e74129ba145927db2a178f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "35cf7f3bb4a1431c98f535a2f955488a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "445d4f53ebc94b00ab5e63c0f144e47a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c27e364204475989447a081cdd16af",
      "placeholder": "​",
      "style": "IPY_MODEL_bfd8cc85333243b0aa9161d8cbdec11d",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "49cd72e8195949f3b4dcd875deeab540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55bd4abb96054413abf41c8c398b34fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d81b6ae24249436c8ea25c0bb26c397c",
       "IPY_MODEL_d28a9833c3384c6cb5fc99f8763b37dc",
       "IPY_MODEL_113f3d569b3f48cb8bea1216fbec243f",
       "IPY_MODEL_d85fa1ff95884f619d259efc55a4b762",
       "IPY_MODEL_445d4f53ebc94b00ab5e63c0f144e47a"
      ],
      "layout": "IPY_MODEL_bbcbccaf836348dc92980f7bb925d8f4"
     }
    },
    "85c27e364204475989447a081cdd16af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0d7c3cb91314136aec6309d75fd0662": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad2463147e294cf7a08dbdd73242ee50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbcbccaf836348dc92980f7bb925d8f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "bfd8cc85333243b0aa9161d8cbdec11d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc00aba84af842c4897c952abc37de55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d28a9833c3384c6cb5fc99f8763b37dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_35cf7f3bb4a1431c98f535a2f955488a",
      "placeholder": "​",
      "style": "IPY_MODEL_d6872028421244dcbee7aa8ef5e8771d",
      "value": ""
     }
    },
    "d6872028421244dcbee7aa8ef5e8771d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d81b6ae24249436c8ea25c0bb26c397c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49cd72e8195949f3b4dcd875deeab540",
      "placeholder": "​",
      "style": "IPY_MODEL_ad2463147e294cf7a08dbdd73242ee50",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "d85fa1ff95884f619d259efc55a4b762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_a0d7c3cb91314136aec6309d75fd0662",
      "style": "IPY_MODEL_29849dbae7e74129ba145927db2a178f",
      "tooltip": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
