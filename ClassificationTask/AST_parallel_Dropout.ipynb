{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "16de2432d2e04344939d475fd653796f",
      "ba66b5a99da74886aec9f2f7bddf0b72",
      "bcf97694601547d780d87926691dce0b",
      "567b5d8a13c94e0fb635256c4a2a7f8d",
      "beaca8c8a0f146a4a12318f620cdf103",
      "65ee1f56657747769885fd987d3038d6",
      "42cbc13eee2a44fa9ce9050abb639bfa",
      "1aef132d8f7240a2bc71460844c44bdb",
      "3d4ba36bcde04e7f8ce14e396973f56b",
      "aaa7dd93795d4a72aec5c175e9037fa2",
      "422120d5c7074fdda00b10609a6bb31e"
     ]
    },
    "executionInfo": {
     "elapsed": 78631,
     "status": "ok",
     "timestamp": 1732727576047,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "Bhd-c6dLELcp",
    "outputId": "71fd0494-4b3c-4592-dc7d-345d256d177f"
   },
   "outputs": [],
   "source": [
    "# ==== SECTION 0: Import Libraries and Mount Google Drive ====\n",
    "\n",
    "# Import necessary standard libraries\n",
    "import os  # For operating system dependent functionality\n",
    "import pickle  # For serializing and de-serializing Python objects\n",
    "import random  # For generating random numbers\n",
    "import numpy as np  # For numerical operations on arrays\n",
    "import pandas as pd\n",
    "\n",
    "# Import PyTorch libraries for deep learning\n",
    "import torch  # Main PyTorch library\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "\n",
    "# Import utilities for data handling\n",
    "from torch.utils.data import Dataset, DataLoader  # For creating custom datasets and data loaders\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, balanced_accuracy_score, confusion_matrix\n",
    ")  # For evaluating model performance\n",
    "\n",
    "# Import transformers library for AST\n",
    "from transformers import ASTFeatureExtractor, ASTForAudioClassification  # AST models and feature extractor\n",
    "\n",
    "# Import defaultdict for grouping data\n",
    "from collections import defaultdict  # For creating dictionaries with default values\n",
    "\n",
    "# Import Google Colab drive for accessing Google Drive\n",
    "from google.colab import drive  # To mount Google Drive\n",
    "\n",
    "# Additional libraries for audio processing and image handling\n",
    "import librosa  # For audio processing\n",
    "import cv2  # For image processing\n",
    "from torchvision import transforms  # For data augmentation and transformations\n",
    "\n",
    "# ==== Mount Google Drive to access the dataset ====\n",
    "drive.mount('/content/drive')  # Mount Google Drive at the specified path\n",
    "\n",
    "# ==== SECTION 1: Data Loading and Preprocessing ====\n",
    "\n",
    "# Set the path to your thesis directory in Google Drive\n",
    "tesi_path = '/content/drive/My Drive/TESI'  # Define the path to the thesis directory\n",
    "os.chdir(tesi_path)  # Change the current working directory to the thesis directory\n",
    "print(\"Current working directory:\", os.getcwd())  # Print the current working directory\n",
    "\n",
    "# Define the path to the pickle file containing the dataset\n",
    "file_path = '/content/drive/MyDrive/TESI/newdata_updated.pkl'  # Path to the pickle file\n",
    "\n",
    "# Load the dataset from the pickle file\n",
    "with open(file_path, 'rb') as f:\n",
    "    newdata = pickle.load(f)  # Deserialize the pickle file into 'newdata'\n",
    "\n",
    "print(\"Pickle file loaded successfully.\")  # Confirm successful loading\n",
    "print(f\"Total samples in dataset: {len(newdata)}\")  # Print the number of samples in the dataset\n",
    "\n",
    "# Initialize the AST feature extractor with pretrained weights\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(\n",
    "    'MIT/ast-finetuned-audioset-10-10-0.4593',  # Pretrained AST model\n",
    "    sampling_rate=16000,  # Set the audio sampling rate to 16kHz\n",
    "    return_attention_mask=False  # Do not return attention masks\n",
    ")\n",
    "\n",
    "# Normalize the audio data to ensure it lies within the [-1, 1] range\n",
    "for item in newdata:\n",
    "    audio = np.array(item['audio'])  # Convert audio data to a NumPy array\n",
    "    audio = audio / np.max(np.abs(audio))  # Normalize audio to [-1, 1]\n",
    "    item['audio'] = audio  # Update the audio data in the dataset\n",
    "\n",
    "# Debugging: Print the shape of the first sample's audio\n",
    "print(f\"Example audio shape: {newdata[0]['audio'].shape}\")  # Shape of the first audio sample\n",
    "\n",
    "# ==== SECTION 2: Data Splitting and Outlier Removal ====\n",
    "\n",
    "def print_updrs_distribution(data, label_key='label', updrs_keys=['updrs', 'UPDRS']):\n",
    "    \"\"\"\n",
    "    Prints the distribution of data based on UPDRS levels and labels.\n",
    "\n",
    "    Args:\n",
    "        data (list): Dataset containing 'label' and 'updrs' or 'UPDRS' information.\n",
    "        label_key (str): Key for the label (0 = control, 1 = Parkinsonian).\n",
    "        updrs_keys (list): Possible keys for the UPDRS value in the data.\n",
    "    \"\"\"\n",
    "    # Counters for labels and UPDRS\n",
    "    updrs_counts = defaultdict(int)\n",
    "    control_count, parkinsonian_count = 0, 0\n",
    "\n",
    "    for item in data:\n",
    "        # Check for the presence of the label key\n",
    "        if label_key in item:\n",
    "            label = item[label_key]\n",
    "            if label == 0:\n",
    "                control_count += 1\n",
    "            elif label == 1:\n",
    "                parkinsonian_count += 1\n",
    "\n",
    "        # Check for the presence of at least one UPDRS key\n",
    "        updrs_value = None\n",
    "        for key in updrs_keys:\n",
    "            if key in item:\n",
    "                updrs_value = item[key]\n",
    "                break\n",
    "\n",
    "        # Increment the count for the UPDRS level\n",
    "        if updrs_value is not None:\n",
    "            updrs_counts[updrs_value] += 1\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Number of controls: {control_count}\")\n",
    "    print(f\"Number of Parkinsonians: {parkinsonian_count}\")\n",
    "    print(\"UPDRS Distribution:\")\n",
    "    for updrs_value, count in sorted(updrs_counts.items()):\n",
    "        print(f\"  UPDRS {updrs_value}: {count}\")\n",
    "\n",
    "\n",
    "# Define the standard audio sampling rate for processing\n",
    "sampling_rate = 44100  # Set sampling rate to 16kHz\n",
    "\n",
    "# Calculate audio lengths in samples and convert to seconds for analysis\n",
    "audio_lengths = [len(item['audio']) for item in newdata]  # List of audio lengths in samples\n",
    "audio_lengths_sec = [length / sampling_rate for length in audio_lengths]  # Convert lengths to seconds\n",
    "\n",
    "# Plot the distribution of audio lengths before processing\n",
    "plt.figure(figsize=(10, 6))  # Set figure size\n",
    "plt.hist(audio_lengths_sec, bins=50, color='blue', alpha=0.7)  # Create a histogram of audio lengths\n",
    "plt.title('Distribution of Audio Lengths (Before Processing)')  # Set plot title\n",
    "plt.xlabel('Audio Length (seconds)')  # Set x-axis label\n",
    "plt.ylabel('Count')  # Set y-axis label\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Print statistics about the audio lengths\n",
    "print(f\"Number of audios: {len(audio_lengths_sec)}\")  # Total number of audio samples\n",
    "print(f\"Minimum audio length: {min(audio_lengths_sec):.2f} seconds\")  # Minimum audio length\n",
    "print(f\"Maximum audio length: {max(audio_lengths_sec):.2f} seconds\")  # Maximum audio length\n",
    "\n",
    "# Remove outliers based on audio length using the Interquartile Range (IQR) method\n",
    "q1 = np.percentile(audio_lengths, 25)  # First quartile\n",
    "q3 = np.percentile(audio_lengths, 75)  # Third quartile\n",
    "iqr = q3 - q1  # Interquartile range\n",
    "\n",
    "# Define acceptable range for audio lengths\n",
    "lower_bound = q1 - 1.5 * iqr  # Lower bound for acceptable lengths\n",
    "upper_bound = q3 + 1.5 * iqr  # Upper bound for acceptable lengths\n",
    "\n",
    "# Filter audios within the acceptable range\n",
    "filtered_data = [item for item in newdata if lower_bound <= len(item['audio']) <= upper_bound]  # Remove outliers\n",
    "\n",
    "# Extract lengths after filtering\n",
    "filtered_audio_lengths = [len(item['audio']) for item in filtered_data]  # Lengths after filtering\n",
    "filtered_audio_lengths_sec = [length / sampling_rate for length in filtered_audio_lengths]  # Convert to seconds\n",
    "\n",
    "# Plot the distribution after filtering\n",
    "plt.figure(figsize=(10, 6))  # Set figure size\n",
    "plt.hist(filtered_audio_lengths_sec, bins=50, color='green', alpha=0.7)  # Create a histogram\n",
    "plt.title('Distribution of Audio Lengths (After Removing Outliers)')  # Set plot title\n",
    "plt.xlabel('Audio Length (seconds)')  # Set x-axis label\n",
    "plt.ylabel('Count')  # Set y-axis label\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Print statistics after filtering\n",
    "print(f\"Number of audios after removing outliers: {len(filtered_audio_lengths_sec)}\")  # Number after filtering\n",
    "print(f\"Minimum audio length after filtering: {min(filtered_audio_lengths_sec):.2f} seconds\")  # New minimum\n",
    "print(f\"Maximum audio length after filtering: {max(filtered_audio_lengths_sec):.2f} seconds\")  # New maximum\n",
    "\n",
    "# Find the shortest audio length (n) in samples\n",
    "min_length = min(filtered_audio_lengths)  # Minimum length in samples\n",
    "print(f\"The shortest audio length is: {min_length / sampling_rate:.2f} seconds ({min_length} samples)\")  # Print shortest length\n",
    "\n",
    "\n",
    "# Before removing outliers\n",
    "print(\"Distribution BEFORE outlier removal:\")\n",
    "print_updrs_distribution(newdata)\n",
    "\n",
    "# After removing outliers\n",
    "print(\"Distribution AFTER outlier removal:\")\n",
    "print_updrs_distribution(filtered_data)\n",
    "\n",
    "\n",
    "# Update 'newdata' to 'filtered_data' for further processing\n",
    "newdata = filtered_data  # Replace original data with filtered data\n",
    "\n",
    "# Function to extract the first and last halves of an audio signal\n",
    "def extract_first_last_halves(audio, min_length):\n",
    "    \"\"\"\n",
    "    Extracts the first and last halves of the audio signal, ensuring uniform length.\n",
    "    Pads with zeros if necessary.\n",
    "\n",
    "    Args:\n",
    "        audio (np.ndarray): The audio signal array.\n",
    "        min_length (int): The minimum length in samples to ensure uniformity.\n",
    "\n",
    "    Returns:\n",
    "        tuple: First half and last half of the audio signal.\n",
    "    \"\"\"\n",
    "    n_half = min_length // 2  # Calculate half the minimum length\n",
    "    if len(audio) >= min_length:\n",
    "        first_half = audio[:n_half]  # Extract the first half\n",
    "        last_half = audio[-n_half:]  # Extract the last half\n",
    "    else:\n",
    "        padding = min_length - len(audio)  # Calculate padding needed\n",
    "        audio_padded = np.pad(audio, (0, padding), 'constant')  # Pad audio with zeros\n",
    "        first_half = audio_padded[:n_half]  # Extract the first half\n",
    "        last_half = audio_padded[-n_half:]  # Extract the last half\n",
    "    return first_half, last_half  # Return both halves\n",
    "\n",
    "# Process each audio in the dataset to create first and last halves\n",
    "print(\"Processing audios and creating first and last halves...\")\n",
    "for item in newdata:\n",
    "    audio = np.array(item['audio'])  # Convert audio to NumPy array\n",
    "    first_half, last_half = extract_first_last_halves(audio, min_length)  # Extract halves\n",
    "\n",
    "    # Update the item with the two audio halves\n",
    "    item['audio_first'] = first_half  # Add first half\n",
    "    item['audio_last'] = last_half  # Add last half\n",
    "\n",
    "    # Remove the raw audio to save memory\n",
    "    del item['audio']  # Delete original audio data\n",
    "\n",
    "print(\"All audios have been processed and divided into first and last halves.\")\n",
    "\n",
    "# ==== SECTION 3: Dataset Class Definition ====\n",
    "\n",
    "# Adding dropout during feature extraction as well\n",
    "# Define the custom Dataset class with potential augmentation/dropout\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, extractor, augment=False):\n",
    "        self.data = data\n",
    "        self.extractor = extractor\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        audio_first = sample['audio_first']\n",
    "        audio_last = sample['audio_last']\n",
    "        label = sample['label']\n",
    "\n",
    "       # Controlla se esistono le chiavi 'updrs' o 'UPDRS'\n",
    "        if 'updrs' in sample:\n",
    "            updrs_value = sample['updrs']\n",
    "        elif 'UPDRS' in sample:\n",
    "            updrs_value = sample['UPDRS']\n",
    "        else:\n",
    "            updrs_value = -1  # Assegna -1 se nessuna chiave Ã¨ presente\n",
    "\n",
    "        metadata = {'updrs': updrs_value}\n",
    "\n",
    "        inputs_first = self.extractor(\n",
    "            audio_first,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "        input_values_first = inputs_first['input_values'].squeeze(0)\n",
    "\n",
    "        inputs_last = self.extractor(\n",
    "            audio_last,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "        input_values_last = inputs_last['input_values'].squeeze(0)\n",
    "\n",
    "        return input_values_first, input_values_last, label, metadata\n",
    "\n",
    "\n",
    "# ==== SECTION 4: Stratified Group Split for Cross-Validation ====\n",
    "\n",
    "# Function to perform stratified group splitting based on subject IDs and labels\n",
    "def stratified_group_split(all_ids, grouped_by_id, label_key='label'):\n",
    "    \"\"\"\n",
    "    Splits the dataset into stratified groups while maintaining balance between classes.\n",
    "\n",
    "    Args:\n",
    "        all_ids (list): List of all subject IDs.\n",
    "        grouped_by_id (dict): Dictionary grouping data by subject ID.\n",
    "        label_key (str): Key to access the label in the data.\n",
    "\n",
    "    Returns:\n",
    "        list: List of folds with balanced subject IDs.\n",
    "    \"\"\"\n",
    "    # Separate IDs based on their labels\n",
    "    controls = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 0]  # Control group IDs\n",
    "    parkinsons = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 1]  # Parkinson group IDs\n",
    "\n",
    "    # Shuffle the IDs to ensure random distribution\n",
    "    random.shuffle(controls)  # Shuffle control IDs\n",
    "    random.shuffle(parkinsons)  # Shuffle Parkinson IDs\n",
    "\n",
    "    num_folds = 5  # Define the number of cross-validation folds\n",
    "    split_controls = len(controls) // num_folds  # Number of control IDs per fold\n",
    "    split_parkinsons = len(parkinsons) // num_folds  # Number of Parkinson IDs per fold\n",
    "\n",
    "    folds = []  # Initialize list to store folds\n",
    "    for i in range(num_folds):\n",
    "        # Assign control and Parkinson IDs to the current fold\n",
    "        fold_controls = controls[i * split_controls:(i + 1) * split_controls]  # Controls for current fold\n",
    "        fold_parkinsons = parkinsons[i * split_parkinsons:(i + 1) * split_parkinsons]  # Parkinsons for current fold\n",
    "        folds.append(fold_controls + fold_parkinsons)  # Combine and add to folds\n",
    "\n",
    "    return folds  # Return the list of folds\n",
    "\n",
    "# ==== SECTION 5: Model Definition with Dropout ====\n",
    "\n",
    "class DualInputASTModel(nn.Module):  # Define the class for the Dual Input AST model\n",
    "    def __init__(self, pretrained_model_name='MIT/ast-finetuned-audioset-10-10-0.4593', num_labels=2):\n",
    "        super(DualInputASTModel, self).__init__()  # Initialize the base class nn.Module\n",
    "        self.ast = ASTForAudioClassification.from_pretrained(  # Load the pre-trained AST model\n",
    "            pretrained_model_name,  # Name of the pre-trained model\n",
    "            num_labels=num_labels,  # Number of classes (two: Parkinsonian and Control)\n",
    "            ignore_mismatched_sizes=True  # Ignore weight dimension mismatches\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(p=0.3)  # Add a dropout layer with probability 0.3 for the first input\n",
    "        self.dropout2 = nn.Dropout(p=0.3)  # Add a dropout layer with probability 0.3 for the second input\n",
    "\n",
    "        # Freeze most layers, fine-tuning last few layers and classifier\n",
    "        for param in self.ast.parameters():\n",
    "            param.requires_grad = False\n",
    "        for name, param in self.ast.named_parameters():\n",
    "            if 'encoder.layer.10' in name or 'encoder.layer.11' in name or 'classifier' in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_values_first, input_values_last):  # Define the forward method\n",
    "        # Forward pass for the first audio segment\n",
    "        outputs_first = self.ast(input_values_first).logits  # Compute logits for the first input\n",
    "        outputs_first = self.dropout1(outputs_first)  # Apply dropout to the first input\n",
    "\n",
    "        # Forward pass for the second audio segment\n",
    "        outputs_last = self.ast(input_values_last).logits  # Compute logits for the second input\n",
    "        outputs_last = self.dropout2(outputs_last)  # Apply dropout to the second input\n",
    "\n",
    "        # Average the logits to combine the results from the two audio segments\n",
    "        combined_logits = (outputs_first + outputs_last) / 2  # Combine logits by averaging the two inputs\n",
    "        return combined_logits  # Return the combined logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1732727576708,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "IPw9f6d11DoH"
   },
   "outputs": [],
   "source": [
    "def analyze_updrs(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Analyze logits and probabilities by UPDRS levels for AST model with dual inputs.\n",
    "\n",
    "    Args:\n",
    "        val_loader: Validation data loader.\n",
    "        model: Trained DualInputASTModel.\n",
    "        device: Device (CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "        updrs_stats (dict): Dictionary with detailed metrics for each UPDRS level.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries for results and statistics\n",
    "    updrs_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    control_stats = {'correct': 0, 'total': 0, 'control_prob': []}  # For label 0 (control)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for inputs_first, inputs_last, labels, metadata in val_loader:\n",
    "            # Move inputs and labels to the device\n",
    "            inputs_first, inputs_last, labels = (\n",
    "                inputs_first.to(device),\n",
    "                inputs_last.to(device),\n",
    "                labels.to(device)\n",
    "            )\n",
    "\n",
    "            # Forward pass to get logits\n",
    "            logits = model(inputs_first, inputs_last)\n",
    "\n",
    "            # Compute probabilities for the Parkinsonian class\n",
    "            probabilities = torch.softmax(logits, dim=1)[:, 1]  # Parkinsonian probabilities\n",
    "            logits = logits[:, 1]  # Parkinsonian logits\n",
    "\n",
    "            # Iterate over each sample in the batch\n",
    "            for i, prob in enumerate(probabilities.cpu().numpy()):\n",
    "                logit = logits[i].item()\n",
    "\n",
    "                # Access UPDRS value from metadata if available\n",
    "                updrs_value = None\n",
    "                if 'updrs' in metadata:\n",
    "                    updrs_value = metadata['updrs'][i]\n",
    "                elif 'UPDRS' in metadata:\n",
    "                    updrs_value = metadata['UPDRS'][i]\n",
    "\n",
    "                # Convert UPDRS value to integer if it exists\n",
    "                if updrs_value is not None:\n",
    "                    if isinstance(updrs_value, torch.Tensor):\n",
    "                        updrs_value = updrs_value.item()\n",
    "                    else:\n",
    "                        updrs_value = int(updrs_value)\n",
    "\n",
    "                # Skip invalid UPDRS values\n",
    "                if updrs_value == -1 or updrs_value is None:\n",
    "                    continue\n",
    "\n",
    "                # Append results to UPDRS-specific stats\n",
    "                updrs_results[updrs_value].append((logit, prob, labels[i].item()))\n",
    "\n",
    "\n",
    "\n",
    "    return updrs_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1732727576708,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "zEUfdHsFntN4"
   },
   "outputs": [],
   "source": [
    "def aggregate_updrs_results(fold_results):\n",
    "    \"\"\"\n",
    "    Aggregates UPDRS results across all folds.\n",
    "\n",
    "    Args:\n",
    "        fold_results (list): List of dictionaries, where each dictionary contains\n",
    "                             'updrs_results' for a fold.\n",
    "\n",
    "    Returns:\n",
    "        aggregated_results (dict): Dictionary with aggregated metrics for each UPDRS level.\n",
    "                                   Keys: {0, 1, 2, 3, 4}\n",
    "                                   Values: Dict with:\n",
    "                                       - 'total_count': Total samples with this UPDRS level.\n",
    "                                       - 'mean_probability': Mean probability for Parkinsonian classification.\n",
    "                                       - 'mean_logit': Mean logit value for Parkinsonian class.\n",
    "                                       - 'percentage_classified_as_parkinsonian': Percentage classified as Parkinsonian.\n",
    "        probabilities_by_updrs (dict): Dictionary containing all individual probabilities for each UPDRS level.\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary for each UPDRS level\n",
    "    aggregated_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    probabilities_by_updrs = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    # Collect all results from all folds\n",
    "    for fold in fold_results:\n",
    "        updrs_results = fold['updrs_results']\n",
    "        for level, values in updrs_results.items():\n",
    "            aggregated_results[level].extend(values)  # Combine results across folds\n",
    "            probabilities_by_updrs[level].extend([prob for _, prob, _ in values])  # Collect probabilities\n",
    "\n",
    "    # Calculate aggregated metrics\n",
    "    metrics = {}\n",
    "    for level, results in aggregated_results.items():\n",
    "        if results:\n",
    "            # Extract logits, probabilities, and true labels\n",
    "            logits, probs, true_labels = zip(*results)\n",
    "            mean_prob = np.mean(probs)  # Mean probability\n",
    "            mean_logit = np.mean(logits)  # Mean logit value\n",
    "            total_count = len(results)  # Total count for this UPDRS level\n",
    "            classified_as_parkinsonian = sum(1 for prob, label in zip(probs, true_labels) if prob >= 0.5 and label == 1)\n",
    "            percentage_classified_as_parkinsonian = (classified_as_parkinsonian / total_count) * 100\n",
    "\n",
    "            # Store metrics\n",
    "            metrics[level] = {\n",
    "                'total_count': total_count,\n",
    "                'mean_probability': mean_prob,\n",
    "                'mean_logit': mean_logit,\n",
    "                'percentage_classified_as_parkinsonian': percentage_classified_as_parkinsonian,\n",
    "            }\n",
    "        else:\n",
    "            # Handle cases with no data for this UPDRS level\n",
    "            metrics[level] = {\n",
    "                'total_count': 0,\n",
    "                'mean_probability': 0.0,\n",
    "                'mean_logit': 0.0,\n",
    "                'percentage_classified_as_parkinsonian': 0.0,\n",
    "            }\n",
    "\n",
    "    return metrics, probabilities_by_updrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "78a654f7e01f4aad960030cbc53b8a65",
      "ea011135cf31402fae9481482f91575b",
      "5db660e7dbd246bf9061667126f76e05",
      "5fb30b2b5b0f4cb1a1e49e9068591d80",
      "6c8d803810c74e09b1cad79ab0cbadb0",
      "affc2e44be054778b5ce3449a967c366",
      "09d3c21ddb9a4a7ca9f5dce85a40b224",
      "2f3cd61f701c4a30a7f4bb34261c9c39",
      "d62e56a716f8441384d23e43cf6459a4",
      "75cab32783264bcb93b2af189a365e45",
      "811117e4ce704487969ae9d5a0d11a5d",
      "602f912e5df749eba17173fe15870c03",
      "a47aee5d6a82408599e8dedea612c817",
      "13f3aa9799ed408aa976073c02d695a5",
      "7692c3a367074124a12b9e043d4845c1",
      "05514db00de4458abf3d972192374f1d",
      "1674e47cbaa3420bb75164e6b5e4a786",
      "4d369af205ed4448ab34ea84c9f7ffe9",
      "71c07d51eab14d1ca76c23160c0354d6",
      "1d8548d410da4fca8f07f2ee19effc6d",
      "87471e360ba14a06aaa7e305e451d206",
      "19eedcc7abe54200a2821ff4cb87eafe"
     ]
    },
    "executionInfo": {
     "elapsed": 12329772,
     "status": "ok",
     "timestamp": 1732767355451,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "y_N7TU1jZnRO",
    "outputId": "e3faa546-c681-437e-8f41-f59fb018b0d6"
   },
   "outputs": [],
   "source": [
    " # ==== SECTION 6: Training and Evaluation Configuration ====\n",
    "\n",
    "# Set training hyperparameters\n",
    "num_epochs = 100  # Maximum number of training epochs\n",
    "#num_epochs = 2\n",
    "early_stopping_patience = 10 # Patience for early stopping\n",
    "learning_rate = 1e-4  # Learning rate for the optimizer\n",
    "dropout_rate = 0.3  # Tune this between 0.2-0.4 for different results\n",
    "\n",
    "gamma = 0.995  # Exponential decay factor for the learning rate scheduler\n",
    "\n",
    "# Lists to store metrics across folds\n",
    "fold_results = []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_precisions, val_precisions = [], []\n",
    "train_recalls, val_recalls = [], []\n",
    "train_f1s, val_f1s = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Define the loss function as Cross Entropy Loss for classification\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "\n",
    "# Function to compute and print the confusion matrix and derived metrics\n",
    "def compute_confusion_matrix_metrics(labels, preds, fold_num):\n",
    "    \"\"\"\n",
    "    Computes and prints the confusion matrix, sensitivity, specificity, and balanced accuracy.\n",
    "\n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        preds (list): Predicted labels.\n",
    "        fold_num (int): Current fold number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Sensitivity, Specificity, Balanced Accuracy.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(labels, preds)  # Compute confusion matrix\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()  # Unpack confusion matrix\n",
    "    else:\n",
    "        # Handle cases where one class is missing in predictions\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0  # Initialize values\n",
    "        if len(cm) == 1:\n",
    "            if cm[0][0] == 0:\n",
    "                tn = 0\n",
    "                fp = 0\n",
    "                fn = cm[0][1]\n",
    "                tp = 0\n",
    "            else:\n",
    "                tn = cm[0][0]\n",
    "                fp = 0\n",
    "                fn = 0\n",
    "                tp = 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Calculate sensitivity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Calculate specificity\n",
    "    balanced_acc = (sensitivity + specificity) / 2  # Calculate balanced accuracy\n",
    "\n",
    "    # Print the confusion matrix and derived metrics\n",
    "    print(f\"\\nConfusion Matrix for Fold {fold_num}:\")\n",
    "    print(cm)\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "\n",
    "    return sensitivity, specificity, balanced_acc  # Return the metrics\n",
    "\n",
    "# ==== SECTION 7: Cross-Validation Loop ====\n",
    "\n",
    "# Group data by subject ID for splitting\n",
    "grouped_by_id = defaultdict(list)  # Initialize defaultdict\n",
    "for item in newdata:\n",
    "    grouped_by_id[item['id']].append(item)  # Group items by 'id'\n",
    "\n",
    "all_ids = list(grouped_by_id.keys())  # List of all unique subject IDs\n",
    "\n",
    "# Perform stratified group split to ensure balanced folds\n",
    "folds = stratified_group_split(all_ids, grouped_by_id)  # Split IDs into folds\n",
    "\n",
    "# ==== SECTION 7: Cross-Validation Loop with Metrics and UPDRS Analysis ====\n",
    "\n",
    "\n",
    "# Loop over each fold for cross-validation\n",
    "for fold in range(5):\n",
    "    print(f\"\\nProcessing Fold {fold+1}/5...\")  # Indicate current fold\n",
    "\n",
    "    # Define training and validation IDs\n",
    "    train_ids = [id_ for id_ in all_ids if id_ not in folds[fold]]  # IDs for training\n",
    "    val_ids = folds[fold]  # IDs for validation\n",
    "\n",
    "    # Extract training and validation samples based on IDs\n",
    "    train_samples = [item for id_soggetto in train_ids for item in grouped_by_id[id_soggetto]]  # Training samples\n",
    "    val_samples = [item for id_soggetto in val_ids for item in grouped_by_id[id_soggetto]]  # Validation samples\n",
    "\n",
    "    print(f\"Training set size: {len(train_samples)} samples\")  # Print training set size\n",
    "    print(f\"Validation set size: {len(val_samples)} samples\")  # Print validation set size\n",
    "\n",
    "    # Create Dataset objects for training and validation\n",
    "    train_dataset = AudioDataset(train_samples, feature_extractor)  # Training dataset\n",
    "    val_dataset = AudioDataset(val_samples, feature_extractor)  # Validation dataset\n",
    "\n",
    "    # Create DataLoader objects for batching\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Training DataLoader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)  # Validation DataLoader\n",
    "\n",
    "    # Initialize the custom DualInputASTModel\n",
    "    model = DualInputASTModel()  # Instantiate the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Select device\n",
    "    model.to(device)  # Move model to the selected device\n",
    "\n",
    "    # Define the optimizer with weight decay\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),  # Only optimize parameters that require gradients\n",
    "        lr=learning_rate,  # Set learning rate\n",
    "        weight_decay=0.05  # Set weight decay for regularization\n",
    "    )\n",
    "\n",
    "    # Define the learning rate scheduler with exponential decay\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)  # Scheduler for learning rate decay\n",
    "\n",
    "    best_val_accuracy = 0  # Initialize best validation accuracy\n",
    "    patience_counter = 0  # Initialize patience counter for early stopping\n",
    "    epoch_train_accuracies, epoch_val_accuracies = [], []\n",
    "    epoch_train_precisions, epoch_val_precisions = [], []\n",
    "    epoch_train_recalls, epoch_val_recalls = [], []\n",
    "    epoch_train_f1s, epoch_val_f1s = [], []\n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    val_fold_preds, val_fold_true = [], []\n",
    "\n",
    "    # Loop over each epoch for training\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} for Fold {fold+1}\")  # Indicate current epoch and fold\n",
    "\n",
    "        # ==== Training Phase ====\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss, correct_train = 0.0, 0\n",
    "        train_preds, train_true = [], []\n",
    "\n",
    "        # Iterate over training batches\n",
    "        for inputs_first, inputs_last, labels, _ in train_loader:\n",
    "            inputs_first = inputs_first.to(device)  # Move first input to device\n",
    "            inputs_last = inputs_last.to(device)  # Move last input to device\n",
    "            labels = labels.to(device)  # Move labels to device\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs_first, inputs_last)  # Forward pass with both inputs\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)  # Accumulate training loss\n",
    "            preds = torch.argmax(outputs, dim=1)  # Get predicted classes\n",
    "            correct_train += torch.sum(preds == labels).item()\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_precision = precision_score(train_true, train_preds, zero_division=0)\n",
    "        train_recall = recall_score(train_true, train_preds)\n",
    "        train_f1 = f1_score(train_true, train_preds)\n",
    "\n",
    "        # ==== Validation Phase ====\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss, correct_val = 0.0, 0\n",
    "        val_preds, val_true = [], []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            # Iterate over validation batches\n",
    "            for inputs_first, inputs_last, labels, _ in val_loader:\n",
    "                inputs_first = inputs_first.to(device)  # Move first input to device\n",
    "                inputs_last = inputs_last.to(device)  # Move last input to device\n",
    "                labels = labels.to(device)  # Move labels to device\n",
    "\n",
    "                outputs = model(inputs_first, inputs_last)  # Forward pass with both inputs\n",
    "                loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "                val_loss += loss.item() * labels.size(0)  # Accumulate validation loss\n",
    "                preds = torch.argmax(outputs, dim=1)  # Get predicted classes\n",
    "                correct_val += torch.sum(preds == labels).item()\n",
    "                val_preds.extend(preds.cpu().numpy())  # Store predictions\n",
    "                val_true.extend(labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "        updrs_results = analyze_updrs(val_loader, model, device)\n",
    "\n",
    "\n",
    "        # Calculate and store validation metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "          # Calculate metrics for validation\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_precision = precision_score(val_true, val_preds, zero_division=0)\n",
    "        val_recall = recall_score(val_true, val_preds)\n",
    "        val_f1 = f1_score(val_true, val_preds)\n",
    "        val_sensitivity = val_recall  # Sensitivity is the same as recall in binary classification\n",
    "\n",
    "        # Corrected specificity calculation\n",
    "        true_negatives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 0))\n",
    "        false_positives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 1))\n",
    "        val_specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "\n",
    "        # Append epoch metrics\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        epoch_train_precisions.append(train_precision)\n",
    "        epoch_val_precisions.append(val_precision)\n",
    "        epoch_train_recalls.append(train_recall)\n",
    "        epoch_val_recalls.append(val_recall)\n",
    "        epoch_train_f1s.append(train_f1)\n",
    "        epoch_val_f1s.append(val_f1)\n",
    "        epoch_train_losses.append(train_loss)\n",
    "        epoch_val_losses.append(val_loss)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "        # ==== Early Stopping Logic ====\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy  # Update best validation accuracy\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            # Save the best model for the current fold\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold+1}.pt')  # Save model state\n",
    "        else:\n",
    "            patience_counter += 1  # Increment patience counter\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")  # Indicate early stopping\n",
    "                break  # Exit the epoch loop\n",
    "\n",
    "        # Update the learning rate scheduler\n",
    "        scheduler.step()  # Step the scheduler\n",
    "\n",
    "            # Store results for this fold\n",
    "    fold_results.append({\n",
    "        'train_accuracy': epoch_train_accuracies,\n",
    "        'val_accuracy': epoch_val_accuracies,\n",
    "        'train_precision': epoch_train_precisions,\n",
    "        'val_precision': epoch_val_precisions,\n",
    "        'train_recall': epoch_train_recalls,\n",
    "        'val_recall': epoch_val_recalls,\n",
    "        'train_f1': epoch_train_f1s,\n",
    "        'val_f1': epoch_val_f1s,\n",
    "        'train_loss': epoch_train_losses,\n",
    "        'val_loss': epoch_val_losses,\n",
    "        'val_sensitivity': val_sensitivity,\n",
    "        'val_specificity': val_specificity,\n",
    "        'val_preds': val_fold_preds,\n",
    "        'val_true': val_fold_true,\n",
    "        'updrs_results': updrs_results  # Add UPDRS results here\n",
    "    })\n",
    "\n",
    "# Calculate and print final average metrics across all folds (only the last epoch of each fold)\n",
    "final_train_accuracies = [result['train_accuracy'][-1] for result in fold_results]\n",
    "final_val_accuracies = [result['val_accuracy'][-1] for result in fold_results]\n",
    "final_train_precisions = [result['train_precision'][-1] for result in fold_results]\n",
    "final_val_precisions = [result['val_precision'][-1] for result in fold_results]\n",
    "final_train_recalls = [result['train_recall'][-1] for result in fold_results]\n",
    "final_val_recalls = [result['val_recall'][-1] for result in fold_results]\n",
    "final_train_f1s = [result['train_f1'][-1] for result in fold_results]\n",
    "final_val_f1s = [result['val_f1'][-1] for result in fold_results]\n",
    "final_val_sensitivities = [result['val_sensitivity'] for result in fold_results]\n",
    "final_val_specificities = [result['val_specificity'] for result in fold_results]\n",
    "\n",
    "# Calculate averages across folds\n",
    "average_train_accuracy = np.mean(final_train_accuracies)\n",
    "average_val_accuracy = np.mean(final_val_accuracies)\n",
    "average_train_precision = np.mean(final_train_precisions)\n",
    "average_val_precision = np.mean(final_val_precisions)\n",
    "average_train_recall = np.mean(final_train_recalls)\n",
    "average_val_recall = np.mean(final_val_recalls)\n",
    "average_train_f1 = np.mean(final_train_f1s)\n",
    "average_val_f1 = np.mean(final_val_f1s)\n",
    "average_val_sensitivity = np.mean(final_val_sensitivities)\n",
    "average_val_specificity = np.mean(final_val_specificities)\n",
    "\n",
    "# Print final average metrics\n",
    "print(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\")\n",
    "print(f\"Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {average_train_precision:.4f}\")\n",
    "print(f\"Validation Precision: {average_val_precision:.4f}\")\n",
    "print(f\"Training Recall: {average_train_recall:.4f}\")\n",
    "print(f\"Validation Recall: {average_val_recall:.4f}\")\n",
    "print(f\"Training F1-Score: {average_train_f1:.4f}\")\n",
    "print(f\"Validation F1-Score: {average_val_f1:.4f}\")\n",
    "print(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\")\n",
    "print(f\"Validation Specificity: {average_val_specificity:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732767355451,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "6rEdyK2WT4vv",
    "outputId": "7535b923-a85e-41c4-e3ba-7290877ef9a5"
   },
   "outputs": [],
   "source": [
    "# Dopo il ciclo di cross-validation\n",
    "aggregated_updrs_metrics, probabilities_by_updrs = aggregate_updrs_results(fold_results)\n",
    "\n",
    "# Stampa dei risultati aggregati\n",
    "print(\"\\n===== Aggregated UPDRS Metrics Across Folds =====\")\n",
    "for level, metrics in aggregated_updrs_metrics.items():\n",
    "    print(f\"UPDRS Level {level}:\")\n",
    "    print(f\"  Total Count: {metrics['total_count']}\")\n",
    "    print(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\")\n",
    "    print(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2582,
     "status": "ok",
     "timestamp": 1732767358032,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "khGghT9ET5XW",
    "outputId": "ccf850f9-1459-4911-be63-00fe6272f058"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs):\n",
    "    # Prepare data for plotting\n",
    "    levels = list(aggregated_updrs_metrics.keys())\n",
    "    total_counts = [aggregated_updrs_metrics[level]['total_count'] for level in levels]\n",
    "    mean_probs = [aggregated_updrs_metrics[level]['mean_probability'] for level in levels]\n",
    "    mean_logits = [aggregated_updrs_metrics[level]['mean_logit'] for level in levels]\n",
    "    percentages_classified = [aggregated_updrs_metrics[level]['percentage_classified_as_parkinsonian'] for level in levels]\n",
    "\n",
    "    # Bar chart for mean probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=mean_probs, palette='Blues_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Mean Probability')\n",
    "    plt.title('Mean Probability of Being Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot for probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data = [(level, prob) for level, probs in probabilities_by_updrs.items() for prob in probs]\n",
    "    df = pd.DataFrame(data, columns=['UPDRS Level', 'Probability'])\n",
    "    sns.boxplot(x='UPDRS Level', y='Probability', data=df, palette='Pastel1')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Distribution of Probabilities by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for percentage classified as Parkinsonian\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=percentages_classified, palette='Oranges_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Percentage Classified as Parkinsonian')\n",
    "    plt.title('Percentage Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for total count\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=total_counts, palette='Greens_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Total Count')\n",
    "    plt.title('Total Data Count by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after calculating metrics\n",
    "plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1732767358033,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "jArM-UREUCR0",
    "outputId": "089e93b7-1230-4716-f9a1-71f656264a57"
   },
   "outputs": [],
   "source": [
    "# Nome del file per salvare tutti i risultati\n",
    "results_filename = \"results_AST_parallel2.txt\"\n",
    "\n",
    "# Scrivi tutti i risultati in un unico file\n",
    "with open(results_filename, mode=\"w\") as file:\n",
    "    # Scrivi i risultati UPDRS\n",
    "    file.write(\"===== Aggregated UPDRS Metrics Across Folds =====\\n\")\n",
    "    for level, metrics in aggregated_updrs_metrics.items():\n",
    "        file.write(f\"UPDRS Level {level}:\\n\")\n",
    "        file.write(f\"  Total Count: {metrics['total_count']}\\n\")\n",
    "        file.write(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\\n\")\n",
    "        file.write(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\\n\")\n",
    "        file.write(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "    # Scrivi le metriche medie sui fold\n",
    "    file.write(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\\n\")\n",
    "    file.write(f\"Training Accuracy: {average_train_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Validation Accuracy: {average_val_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Training Precision: {average_train_precision:.4f}\\n\")\n",
    "    file.write(f\"Validation Precision: {average_val_precision:.4f}\\n\")\n",
    "    file.write(f\"Training Recall: {average_train_recall:.4f}\\n\")\n",
    "    file.write(f\"Validation Recall: {average_val_recall:.4f}\\n\")\n",
    "    file.write(f\"Training F1-Score: {average_train_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation F1-Score: {average_val_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\\n\")\n",
    "    file.write(f\"Validation Specificity: {average_val_specificity:.4f}\\n\")\n",
    "\n",
    "print(f\"All results saved to {results_filename}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05514db00de4458abf3d972192374f1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d3c21ddb9a4a7ca9f5dce85a40b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13f3aa9799ed408aa976073c02d695a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71c07d51eab14d1ca76c23160c0354d6",
      "max": 346404948,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d8548d410da4fca8f07f2ee19effc6d",
      "value": 346404948
     }
    },
    "1674e47cbaa3420bb75164e6b5e4a786": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16de2432d2e04344939d475fd653796f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba66b5a99da74886aec9f2f7bddf0b72",
       "IPY_MODEL_bcf97694601547d780d87926691dce0b",
       "IPY_MODEL_567b5d8a13c94e0fb635256c4a2a7f8d"
      ],
      "layout": "IPY_MODEL_beaca8c8a0f146a4a12318f620cdf103"
     }
    },
    "19eedcc7abe54200a2821ff4cb87eafe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1aef132d8f7240a2bc71460844c44bdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d8548d410da4fca8f07f2ee19effc6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f3cd61f701c4a30a7f4bb34261c9c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d4ba36bcde04e7f8ce14e396973f56b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "422120d5c7074fdda00b10609a6bb31e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42cbc13eee2a44fa9ce9050abb639bfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d369af205ed4448ab34ea84c9f7ffe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "567b5d8a13c94e0fb635256c4a2a7f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaa7dd93795d4a72aec5c175e9037fa2",
      "placeholder": "â",
      "style": "IPY_MODEL_422120d5c7074fdda00b10609a6bb31e",
      "value": "â297/297â[00:00&lt;00:00,â26.7kB/s]"
     }
    },
    "5db660e7dbd246bf9061667126f76e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f3cd61f701c4a30a7f4bb34261c9c39",
      "max": 26763,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d62e56a716f8441384d23e43cf6459a4",
      "value": 26763
     }
    },
    "5fb30b2b5b0f4cb1a1e49e9068591d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75cab32783264bcb93b2af189a365e45",
      "placeholder": "â",
      "style": "IPY_MODEL_811117e4ce704487969ae9d5a0d11a5d",
      "value": "â26.8k/26.8kâ[00:00&lt;00:00,â1.68MB/s]"
     }
    },
    "602f912e5df749eba17173fe15870c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a47aee5d6a82408599e8dedea612c817",
       "IPY_MODEL_13f3aa9799ed408aa976073c02d695a5",
       "IPY_MODEL_7692c3a367074124a12b9e043d4845c1"
      ],
      "layout": "IPY_MODEL_05514db00de4458abf3d972192374f1d"
     }
    },
    "65ee1f56657747769885fd987d3038d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c8d803810c74e09b1cad79ab0cbadb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71c07d51eab14d1ca76c23160c0354d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75cab32783264bcb93b2af189a365e45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7692c3a367074124a12b9e043d4845c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87471e360ba14a06aaa7e305e451d206",
      "placeholder": "â",
      "style": "IPY_MODEL_19eedcc7abe54200a2821ff4cb87eafe",
      "value": "â346M/346Mâ[00:01&lt;00:00,â244MB/s]"
     }
    },
    "78a654f7e01f4aad960030cbc53b8a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea011135cf31402fae9481482f91575b",
       "IPY_MODEL_5db660e7dbd246bf9061667126f76e05",
       "IPY_MODEL_5fb30b2b5b0f4cb1a1e49e9068591d80"
      ],
      "layout": "IPY_MODEL_6c8d803810c74e09b1cad79ab0cbadb0"
     }
    },
    "811117e4ce704487969ae9d5a0d11a5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87471e360ba14a06aaa7e305e451d206": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47aee5d6a82408599e8dedea612c817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1674e47cbaa3420bb75164e6b5e4a786",
      "placeholder": "â",
      "style": "IPY_MODEL_4d369af205ed4448ab34ea84c9f7ffe9",
      "value": "model.safetensors:â100%"
     }
    },
    "aaa7dd93795d4a72aec5c175e9037fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affc2e44be054778b5ce3449a967c366": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba66b5a99da74886aec9f2f7bddf0b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65ee1f56657747769885fd987d3038d6",
      "placeholder": "â",
      "style": "IPY_MODEL_42cbc13eee2a44fa9ce9050abb639bfa",
      "value": "preprocessor_config.json:â100%"
     }
    },
    "bcf97694601547d780d87926691dce0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1aef132d8f7240a2bc71460844c44bdb",
      "max": 297,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d4ba36bcde04e7f8ce14e396973f56b",
      "value": 297
     }
    },
    "beaca8c8a0f146a4a12318f620cdf103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d62e56a716f8441384d23e43cf6459a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ea011135cf31402fae9481482f91575b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affc2e44be054778b5ce3449a967c366",
      "placeholder": "â",
      "style": "IPY_MODEL_09d3c21ddb9a4a7ca9f5dce85a40b224",
      "value": "config.json:â100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
