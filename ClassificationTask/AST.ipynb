{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 10233,
     "status": "ok",
     "timestamp": 1732705351167,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "R-i5JMXpNsoR",
    "outputId": "5c3135fc-8b12-4694-cc44-4421a86510ae"
   },
   "outputs": [],
   "source": [
    "# ==== SECTION 0: Import Libraries and Mount Google Drive ====\n",
    "\n",
    "# Importing necessary libraries\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix\n",
    "from transformers import ASTFeatureExtractor, ASTForAudioClassification\n",
    "from collections import defaultdict\n",
    "from google.colab import drive  # Import Google Drive\n",
    "\n",
    "# Mount Google Drive to access the dataset\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ==== SECTION 1: Data Loading and Preprocessing ====\n",
    "\n",
    "# Set the path to your data and change the working directory\n",
    "tesi_path = '/content/drive/My Drive/TESI'\n",
    "os.chdir(tesi_path)  # Change to the thesis directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the dataset from a pickle file\n",
    "file_path = '/content/drive/MyDrive/TESI/newdata_updated.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    newdata = pickle.load(f)\n",
    "\n",
    "print(\"Pickle file loaded successfully.\")\n",
    "print(f\"Total samples in dataset: {len(newdata)}\")\n",
    "\n",
    "# Define the standard audio sampling rate\n",
    "sampling_rate = 44100  # 44.1 kHz\n",
    "\n",
    "# Calculate audio lengths in samples and convert to seconds\n",
    "audio_lengths = [len(item['audio']) for item in newdata]\n",
    "audio_lengths_sec = [length / sampling_rate for length in audio_lengths]\n",
    "\n",
    "# Plot the distribution of audio lengths before processing\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(audio_lengths_sec, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (Before Processing)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics about the audio lengths\n",
    "print(f\"Number of audios: {len(audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length: {min(audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length: {max(audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "def print_updrs_distribution(data, label_key='label', updrs_keys=['updrs', 'UPDRS']):\n",
    "    \"\"\"\n",
    "    Prints the distribution of data based on UPDRS levels and labels.\n",
    "\n",
    "    Args:\n",
    "        data (list): Dataset containing 'label' and 'updrs' or 'UPDRS' information.\n",
    "        label_key (str): Key for the label (0 = control, 1 = Parkinsonian).\n",
    "        updrs_keys (list): Possible keys for the UPDRS value in the data.\n",
    "    \"\"\"\n",
    "    # Counters for labels and UPDRS\n",
    "    updrs_counts = defaultdict(int)\n",
    "    control_count, parkinsonian_count = 0, 0\n",
    "\n",
    "    for item in data:\n",
    "        # Check for the presence of the label key\n",
    "        if label_key in item:\n",
    "            label = item[label_key]\n",
    "            if label == 0:\n",
    "                control_count += 1\n",
    "            elif label == 1:\n",
    "                parkinsonian_count += 1\n",
    "\n",
    "        # Check for the presence of at least one UPDRS key\n",
    "        updrs_value = None\n",
    "        for key in updrs_keys:\n",
    "            if key in item:\n",
    "                updrs_value = item[key]\n",
    "                break\n",
    "\n",
    "        # Increment the count for the UPDRS level\n",
    "        if updrs_value is not None:\n",
    "            updrs_counts[updrs_value] += 1\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Number of controls: {control_count}\")\n",
    "    print(f\"Number of Parkinsonians: {parkinsonian_count}\")\n",
    "    print(\"UPDRS Distribution:\")\n",
    "    for updrs_value, count in sorted(updrs_counts.items()):\n",
    "        print(f\"  UPDRS {updrs_value}: {count}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1732705351874,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "b0fQJqUn1a9J",
    "outputId": "97b6193f-d2c9-4f91-a208-d3fdf1135ea1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove outliers based on audio length using the Interquartile Range (IQR) method\n",
    "q1 = np.percentile(audio_lengths, 25)\n",
    "q3 = np.percentile(audio_lengths, 75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Define acceptable range for audio lengths\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filter audios within the acceptable range\n",
    "filtered_data = [item for item in newdata if lower_bound <= len(item['audio']) <= upper_bound]\n",
    "\n",
    "# Extract lengths after filtering\n",
    "filtered_audio_lengths = [len(item['audio']) for item in filtered_data]\n",
    "filtered_audio_lengths_sec = [length / sampling_rate for length in filtered_audio_lengths]\n",
    "\n",
    "# Plot the distribution after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_audio_lengths_sec, bins=50, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Audio Lengths (After Removing Outliers)')\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics after filtering\n",
    "print(f\"Number of audios after removing outliers: {len(filtered_audio_lengths_sec)}\")\n",
    "print(f\"Minimum audio length after filtering: {min(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "print(f\"Maximum audio length after filtering: {max(filtered_audio_lengths_sec):.2f} seconds\")\n",
    "\n",
    "# Find the shortest audio length (n) in samples\n",
    "min_length = min(filtered_audio_lengths)\n",
    "print(f\"The shortest audio length is: {min_length / sampling_rate:.2f} seconds ({min_length} samples)\")\n",
    "\n",
    "# Before removing outliers\n",
    "print(\"Distribution BEFORE outlier removal:\")\n",
    "print_updrs_distribution(newdata)\n",
    "\n",
    "# After removing outliers\n",
    "print(\"Distribution AFTER outlier removal:\")\n",
    "print_updrs_distribution(filtered_data)\n",
    "\n",
    "# Update 'newdata' to 'filtered_data' for further processing\n",
    "newdata = filtered_data\n",
    "# Preprocess the audios by trimming to the central part\n",
    "print(\"Preprocessing audios...\")\n",
    "min_length = min([len(item['audio']) for item in newdata])\n",
    "for item in newdata:\n",
    "    audio_trimmed = item['audio']\n",
    "    start = (len(audio_trimmed) - min_length) // 2\n",
    "    end = start + min_length\n",
    "    item['audio'] = audio_trimmed[start:end]  # Trim audio\n",
    "\n",
    "# Normalize the audio data to ensure it lies within [-1, 1] range\n",
    "for item in newdata:\n",
    "    audio = np.array(item['audio'])\n",
    "    audio = audio / np.max(np.abs(audio))  # Normalize audio\n",
    "    item['audio'] = audio\n",
    "\n",
    "# Debugging: Print shape of a sample audio\n",
    "print(f\"Example audio shape: {newdata[0]['audio'].shape}\")\n",
    "\n",
    "# Initialize the AST feature extractor for processing audio\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(\n",
    "    'MIT/ast-finetuned-audioset-10-10-0.4593',\n",
    "    sampling_rate=16000,  # Set the audio sampling rate to 16kHz\n",
    "    return_attention_mask=False  # Don't use attention masks for this task\n",
    ")\n",
    "\n",
    "# ==== SECTION 2: Dataset Class Definition ====\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Custom dataset class for loading audio and labels\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, extractor, dropout_rate=0.15):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list): List of samples with 'audio' and 'label' keys.\n",
    "            extractor (callable): Feature extractor function.\n",
    "            dropout_rate (float): Dropout probability to apply on features.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.extractor = extractor\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # Initialize dropout with specified rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Return the total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        audio = sample['audio']\n",
    "        label = sample['label']\n",
    "\n",
    "        # Check for 'updrs' or 'UPDRS' key\n",
    "        if 'updrs' in sample:\n",
    "            updrs_value = sample['updrs']\n",
    "        elif 'UPDRS' in sample:\n",
    "            updrs_value = sample['UPDRS']\n",
    "        else:\n",
    "            updrs_value = -1  # Assign -1 if no key is present\n",
    "\n",
    "        metadata = {'updrs': updrs_value}\n",
    "\n",
    "        # Extract features from the raw audio using ASTFeatureExtractor\n",
    "        inputs = self.extractor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        input_values = inputs['input_values'].squeeze(0)  # Remove batch dimension\n",
    "\n",
    "        # Apply dropout to the input values\n",
    "        input_values = self.dropout(input_values)\n",
    "\n",
    "        return input_values, label, metadata\n",
    "\n",
    "# ==== SECTION 3: Stratified Group Split ====\n",
    "\n",
    "# Function to ensure balanced stratified split between control and Parkinson subjects\n",
    "def stratified_group_split(all_ids, grouped_by_id, label_key='label'):\n",
    "    controls = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 0]  # Control group\n",
    "    parkinsons = [id_ for id_ in all_ids if grouped_by_id[id_][0][label_key] == 1]  # Parkinson group\n",
    "\n",
    "    random.shuffle(controls)  # Shuffle to randomize\n",
    "    random.shuffle(parkinsons)\n",
    "\n",
    "    split_controls = len(controls) // 5  # Split into 5 folds\n",
    "    split_parkinsons = len(parkinsons) // 5\n",
    "\n",
    "    # Create balanced folds\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        fold_controls = controls[i * split_controls:(i + 1) * split_controls]\n",
    "        fold_parkinsons = parkinsons[i * split_parkinsons:(i + 1) * split_parkinsons]\n",
    "        folds.append(fold_controls + fold_parkinsons)\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732705351874,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "YTXioM3T1l3W"
   },
   "outputs": [],
   "source": [
    "def analyze_updrs(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Analyze logits and probabilities by UPDRS levels.\n",
    "    Args:\n",
    "        val_loader: Validation data loader.\n",
    "        model: Trained model.\n",
    "        device: Device (CPU or GPU).\n",
    "    Returns:\n",
    "        updrs_results: Dictionary with logits, probabilities, and true labels grouped by UPDRS levels.\n",
    "    \"\"\"\n",
    "    updrs_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    # Validation phase: Calculate logits and probabilities for each UPDRS level\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, metadata in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "\n",
    "            # Calculate probabilities and logits\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of being Parkinsonian\n",
    "            logits = outputs[:, 1]  # Logit for Parkinsonian class\n",
    "\n",
    "            # Iterate over each sample in the batch\n",
    "            for i, prob in enumerate(probabilities.cpu().numpy()):\n",
    "                logit = logits[i].item()\n",
    "\n",
    "                # Access UPDRS value from metadata if available\n",
    "                updrs_value = None\n",
    "                if 'updrs' in metadata:\n",
    "                    updrs_value = metadata['updrs'][i]\n",
    "                elif 'UPDRS' in metadata:\n",
    "                    updrs_value = metadata['UPDRS'][i]\n",
    "\n",
    "                # Convert UPDRS value to integer if it exists\n",
    "                if updrs_value is not None:\n",
    "                    if isinstance(updrs_value, torch.Tensor):\n",
    "                        updrs_value = updrs_value.item()\n",
    "                    else:\n",
    "                        updrs_value = int(updrs_value)\n",
    "\n",
    "                # Skip invalid UPDRS values\n",
    "                if updrs_value == -1 or updrs_value is None:\n",
    "                    continue\n",
    "\n",
    "                # Append results to UPDRS-specific stats\n",
    "                updrs_results[updrs_value].append((logit, prob, labels[i].item()))\n",
    "\n",
    "\n",
    "    return updrs_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732705351874,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "Xio48hBW0D40"
   },
   "outputs": [],
   "source": [
    "def aggregate_updrs_results(fold_results):\n",
    "    \"\"\"\n",
    "    Aggregates UPDRS results across all folds.\n",
    "\n",
    "    Args:\n",
    "        fold_results (list): List of dictionaries, where each dictionary contains\n",
    "                             'updrs_results' for a fold.\n",
    "\n",
    "    Returns:\n",
    "        aggregated_results (dict): Dictionary with aggregated metrics for each UPDRS level.\n",
    "                                   Keys: {0, 1, 2, 3, 4}\n",
    "                                   Values: Dict with:\n",
    "                                       - 'total_count': Total samples with this UPDRS level.\n",
    "                                       - 'mean_probability': Mean probability for Parkinsonian classification.\n",
    "                                       - 'mean_logit': Mean logit value for Parkinsonian class.\n",
    "                                       - 'percentage_classified_as_parkinsonian': Percentage classified as Parkinsonian.\n",
    "        probabilities_by_updrs (dict): Dictionary containing all individual probabilities for each UPDRS level.\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary for each UPDRS level\n",
    "    aggregated_results = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    probabilities_by_updrs = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "    # Collect all results from all folds\n",
    "    for fold in fold_results:\n",
    "        updrs_results = fold['updrs_results']\n",
    "        for level, values in updrs_results.items():\n",
    "            aggregated_results[level].extend(values)  # Combine results across folds\n",
    "            probabilities_by_updrs[level].extend([prob for _, prob, _ in values])  # Collect probabilities\n",
    "\n",
    "    # Calculate aggregated metrics\n",
    "    metrics = {}\n",
    "    for level, results in aggregated_results.items():\n",
    "        if results:\n",
    "            # Extract logits, probabilities, and true labels\n",
    "            logits, probs, true_labels = zip(*results)\n",
    "            mean_prob = np.mean(probs)  # Mean probability\n",
    "            mean_logit = np.mean(logits)  # Mean logit value\n",
    "            total_count = len(results)  # Total count for this UPDRS level\n",
    "            classified_as_parkinsonian = sum(1 for prob, label in zip(probs, true_labels) if prob >= 0.5 and label == 1)\n",
    "            percentage_classified_as_parkinsonian = (classified_as_parkinsonian / total_count) * 100\n",
    "\n",
    "            # Store metrics\n",
    "            metrics[level] = {\n",
    "                'total_count': total_count,\n",
    "                'mean_probability': mean_prob,\n",
    "                'mean_logit': mean_logit,\n",
    "                'percentage_classified_as_parkinsonian': percentage_classified_as_parkinsonian,\n",
    "            }\n",
    "        else:\n",
    "            # Handle cases with no data for this UPDRS level\n",
    "            metrics[level] = {\n",
    "                'total_count': 0,\n",
    "                'mean_probability': 0.0,\n",
    "                'mean_logit': 0.0,\n",
    "                'percentage_classified_as_parkinsonian': 0.0,\n",
    "            }\n",
    "\n",
    "    return metrics, probabilities_by_updrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732705352187,
     "user": {
      "displayName": "Benedetta Perrone",
      "userId": "00214980196106492209"
     },
     "user_tz": -60
    },
    "id": "_3WJpyfPK5KW"
   },
   "outputs": [],
   "source": [
    "# ==== SECTION 6: Confusion Matrix and Metric Calculation ====\n",
    "\n",
    "# Function to compute and print the confusion matrix and derived metrics\n",
    "def compute_confusion_matrix_metrics(labels, preds, fold_num):\n",
    "    cm = confusion_matrix(labels, preds)  # Compute confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()  # Extract values from the confusion matrix\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity (Recall for positive class)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity\n",
    "    balanced_acc = (sensitivity + specificity) / 2  # Balanced accuracy\n",
    "\n",
    "    # Print confusion matrix and derived metrics\n",
    "    print(f\"\\nConfusion Matrix for Fold {fold_num}:\")\n",
    "    print(cm)\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "\n",
    "    return sensitivity, specificity, balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlJAELEkN1J8",
    "outputId": "4d4ff676-700f-437c-b28a-18b583afa94c"
   },
   "outputs": [],
   "source": [
    "# ==== SECTION 7: Training Loop Over 5 Folds ====\n",
    "\n",
    "# Set training parameters\n",
    "num_epochs = 50  # Lower the number of epochs for faster training\n",
    "early_stopping_patience = 5  # More aggressive early stopping\n",
    "learning_rate = 1e-3  # Slightly increase learning rate for faster convergence\n",
    "gamma = 0.995  # Exponential decay factor for learning rate scheduler\n",
    "\n",
    "# Lists to store metrics across folds\n",
    "fold_results = []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_precisions, val_precisions = [], []\n",
    "train_recalls, val_recalls = [], []\n",
    "train_f1s, val_f1s = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Group data by subject ID for splitting\n",
    "grouped_by_id = defaultdict(list)\n",
    "for item in newdata:\n",
    "    grouped_by_id[item['id']].append(item)\n",
    "\n",
    "all_ids = list(grouped_by_id.keys())\n",
    "\n",
    "# Perform stratified split to ensure balance\n",
    "folds = stratified_group_split(all_ids, grouped_by_id)\n",
    "\n",
    "\n",
    "\n",
    "# Loop over 5 folds to train and validate the model\n",
    "for fold in range(5):\n",
    "    print(f\"Processing Fold {fold+1}/5...\")  # Debug: indicate the current fold\n",
    "\n",
    "    # Define training and validation IDs\n",
    "    train_ids = [id_ for id_ in all_ids if id_ not in folds[fold]]  # IDs for training\n",
    "    val_ids = folds[fold]  # IDs for validation\n",
    "\n",
    "    # Extract training and validation samples based on IDs\n",
    "    train_samples = [item for id_soggetto in train_ids for item in grouped_by_id[id_soggetto]]  # Training samples\n",
    "    val_samples = [item for id_soggetto in val_ids for item in grouped_by_id[id_soggetto]]  # Validation samples\n",
    "\n",
    "    print(f\"Training set size: {len(train_samples)} samples\")  # Print training set size\n",
    "    print(f\"Validation set size: {len(val_samples)} samples\")  # Print validation set size\n",
    "\n",
    "    # Create Dataset objects for training and validation\n",
    "    train_dataset = AudioDataset(train_samples, feature_extractor)  # Training dataset\n",
    "    val_dataset = AudioDataset(val_samples, feature_extractor)  # Validation dataset\n",
    "\n",
    "    # Create DataLoader objects for batching\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Training DataLoader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # Validation DataLoader\n",
    "\n",
    "    # Reinitialize the AST model at the start of each fold\n",
    "    model = ASTForAudioClassification.from_pretrained(\n",
    "        'MIT/ast-finetuned-audioset-10-10-0.4593',  # Load the AST model\n",
    "        num_labels=2,  # Set the number of output classes to 2 (Control, Parkinson)\n",
    "        ignore_mismatched_sizes=True  # Ignore size mismatch in classifier layer\n",
    "    )\n",
    "\n",
    "        # Define optimizer and scheduler\n",
    "    optimizer = optim.AdamW(model.classifier.parameters(), lr=learning_rate, weight_decay=0.01)  # AdamW optimizer with weight decay\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)  # Exponential decay for learning rate\n",
    "\n",
    "    # Freeze layers except classifier and last transformer layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  # Freeze all layers\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder.layer.11' in name or 'encoder.layer.10' in name or 'classifier' in name:\n",
    "            param.requires_grad = True  # Unfreeze last 2 layers\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "    model.to(device)  # Move model to the appropriate device (GPU/CPU)\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize training variables\n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "    best_val_loss = 0\n",
    "    epoch_train_accuracies, epoch_val_accuracies = [], []\n",
    "    epoch_train_precisions, epoch_val_precisions = [], []\n",
    "    epoch_train_recalls, epoch_val_recalls = [], []\n",
    "    epoch_train_f1s, epoch_val_f1s = [], []\n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    val_fold_preds, val_fold_true = [], []\n",
    "\n",
    "\n",
    "    # Training loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} for Fold {fold+1}\")  # Debug: print current epoch number\n",
    "\n",
    "        # TRAINING PHASE\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss, correct_train = 0.0, 0\n",
    "        train_preds, train_true = [], []\n",
    "\n",
    "        for inputs, labels, metadata in train_loader:  # Iterate over training batches\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs).logits  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)  # Accumulate training loss\n",
    "            preds = torch.argmax(outputs, dim=1)  # Get predicted classes\n",
    "            correct_train += torch.sum(preds == labels).item()\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = correct_train / len(train_loader.dataset)\n",
    "        train_precision = precision_score(train_true, train_preds, zero_division=0)\n",
    "        train_recall = recall_score(train_true, train_preds)\n",
    "        train_f1 = f1_score(train_true, train_preds)\n",
    "\n",
    "\n",
    "        # VALIDATION PHASE\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss, correct_val = 0, 0  # Initialize validation loss and correct prediction counter\n",
    "        val_preds, val_true = [], []  # Store all predictions and labels for the validation set\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation during validation\n",
    "            for inputs, labels, metadata in val_loader:  # Iterate over validation batches\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "                outputs = model(inputs).logits  # Forward pass\n",
    "\n",
    "                loss = criterion(outputs, labels)  # Calculate validation loss\n",
    "\n",
    "                val_loss += loss.item() * labels.size(0)  # Accumulate validation loss\n",
    "                preds = torch.argmax(outputs, dim=1)  # Get predicted classes\n",
    "                correct_val += torch.sum(preds == labels).item()\n",
    "                val_preds.extend(preds.cpu().numpy())  # Store predictions\n",
    "                val_true.extend(labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "        updrs_results = analyze_updrs(val_loader, model, device)\n",
    "\n",
    "        # Calculate and store validation metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "          # Calculate metrics for validation\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_precision = precision_score(val_true, val_preds, zero_division=0)\n",
    "        val_recall = recall_score(val_true, val_preds)\n",
    "        val_f1 = f1_score(val_true, val_preds)\n",
    "        val_sensitivity = val_recall  # Sensitivity is the same as recall in binary classification\n",
    "\n",
    "            # Corrected specificity calculation\n",
    "        true_negatives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 0))\n",
    "        false_positives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 1))\n",
    "        val_specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "\n",
    "        # Calculate and store validation metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "          # Calculate metrics for validation\n",
    "        val_accuracy = correct_val / len(val_loader.dataset)\n",
    "        val_precision = precision_score(val_true, val_preds, zero_division=0)\n",
    "        val_recall = recall_score(val_true, val_preds)\n",
    "        val_f1 = f1_score(val_true, val_preds)\n",
    "        val_sensitivity = val_recall  # Sensitivity is the same as recall in binary classification\n",
    "\n",
    "        # Corrected specificity calculation\n",
    "        true_negatives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 0))\n",
    "        false_positives = np.sum((np.array(val_true) == 0) & (np.array(val_preds) == 1))\n",
    "        val_specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "\n",
    "        # Append epoch metrics\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        epoch_train_precisions.append(train_precision)\n",
    "        epoch_val_precisions.append(val_precision)\n",
    "        epoch_train_recalls.append(train_recall)\n",
    "        epoch_val_recalls.append(val_recall)\n",
    "        epoch_train_f1s.append(train_f1)\n",
    "        epoch_val_f1s.append(val_f1)\n",
    "        epoch_train_losses.append(train_loss)\n",
    "        epoch_val_losses.append(val_loss)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "                # ==== Early Stopping Logic ====\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold+1}.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")  # Indicate early stopping\n",
    "                break  # Exit the epoch loop\n",
    "\n",
    "        # Update the learning rate scheduler\n",
    "        scheduler.step()  # Step the scheduler\n",
    "\n",
    "            # Store results for this fold\n",
    "    fold_results.append({\n",
    "        'train_accuracy': epoch_train_accuracies,\n",
    "        'val_accuracy': epoch_val_accuracies,\n",
    "        'train_precision': epoch_train_precisions,\n",
    "        'val_precision': epoch_val_precisions,\n",
    "        'train_recall': epoch_train_recalls,\n",
    "        'val_recall': epoch_val_recalls,\n",
    "        'train_f1': epoch_train_f1s,\n",
    "        'val_f1': epoch_val_f1s,\n",
    "        'train_loss': epoch_train_losses,\n",
    "        'val_loss': epoch_val_losses,\n",
    "        'val_sensitivity': val_sensitivity,\n",
    "        'val_specificity': val_specificity,\n",
    "        'val_preds': val_fold_preds,\n",
    "        'val_true': val_fold_true,\n",
    "        'updrs_results': updrs_results  # Add UPDRS results here\n",
    "    })\n",
    "\n",
    "# Calculate and print final average metrics across all folds (only the last epoch of each fold)\n",
    "final_train_accuracies = [result['train_accuracy'][-1] for result in fold_results]\n",
    "final_val_accuracies = [result['val_accuracy'][-1] for result in fold_results]\n",
    "final_train_precisions = [result['train_precision'][-1] for result in fold_results]\n",
    "final_val_precisions = [result['val_precision'][-1] for result in fold_results]\n",
    "final_train_recalls = [result['train_recall'][-1] for result in fold_results]\n",
    "final_val_recalls = [result['val_recall'][-1] for result in fold_results]\n",
    "final_train_f1s = [result['train_f1'][-1] for result in fold_results]\n",
    "final_val_f1s = [result['val_f1'][-1] for result in fold_results]\n",
    "final_val_sensitivities = [result['val_sensitivity'] for result in fold_results]\n",
    "final_val_specificities = [result['val_specificity'] for result in fold_results]\n",
    "\n",
    "# Calculate averages across folds\n",
    "average_train_accuracy = np.mean(final_train_accuracies)\n",
    "average_val_accuracy = np.mean(final_val_accuracies)\n",
    "average_train_precision = np.mean(final_train_precisions)\n",
    "average_val_precision = np.mean(final_val_precisions)\n",
    "average_train_recall = np.mean(final_train_recalls)\n",
    "average_val_recall = np.mean(final_val_recalls)\n",
    "average_train_f1 = np.mean(final_train_f1s)\n",
    "average_val_f1 = np.mean(final_val_f1s)\n",
    "average_val_sensitivity = np.mean(final_val_sensitivities)\n",
    "average_val_specificity = np.mean(final_val_specificities)\n",
    "\n",
    "# Print final average metrics\n",
    "print(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\")\n",
    "print(f\"Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {average_train_precision:.4f}\")\n",
    "print(f\"Validation Precision: {average_val_precision:.4f}\")\n",
    "print(f\"Training Recall: {average_train_recall:.4f}\")\n",
    "print(f\"Validation Recall: {average_val_recall:.4f}\")\n",
    "print(f\"Training F1-Score: {average_train_f1:.4f}\")\n",
    "print(f\"Validation F1-Score: {average_val_f1:.4f}\")\n",
    "print(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\")\n",
    "print(f\"Validation Specificity: {average_val_specificity:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eRzCK23JaZY"
   },
   "outputs": [],
   "source": [
    "# Dopo il ciclo di cross-validation\n",
    "aggregated_updrs_metrics, probabilities_by_updrs = aggregate_updrs_results(fold_results)\n",
    "\n",
    "# Stampa dei risultati aggregati\n",
    "print(\"\\n===== Aggregated UPDRS Metrics Across Folds =====\")\n",
    "for level, metrics in aggregated_updrs_metrics.items():\n",
    "    print(f\"UPDRS Level {level}:\")\n",
    "    print(f\"  Total Count: {metrics['total_count']}\")\n",
    "    print(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\")\n",
    "    print(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwRqfs1lJppP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs):\n",
    "    # Prepare data for plotting\n",
    "    levels = list(aggregated_updrs_metrics.keys())\n",
    "    total_counts = [aggregated_updrs_metrics[level]['total_count'] for level in levels]\n",
    "    mean_probs = [aggregated_updrs_metrics[level]['mean_probability'] for level in levels]\n",
    "    mean_logits = [aggregated_updrs_metrics[level]['mean_logit'] for level in levels]\n",
    "    percentages_classified = [aggregated_updrs_metrics[level]['percentage_classified_as_parkinsonian'] for level in levels]\n",
    "\n",
    "    # Bar chart for mean probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=mean_probs, palette='Blues_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Mean Probability')\n",
    "    plt.title('Mean Probability of Being Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot for probabilities\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data = [(level, prob) for level, probs in probabilities_by_updrs.items() for prob in probs]\n",
    "    df = pd.DataFrame(data, columns=['UPDRS Level', 'Probability'])\n",
    "    sns.boxplot(x='UPDRS Level', y='Probability', data=df, palette='Pastel1')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Distribution of Probabilities by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for percentage classified as Parkinsonian\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=percentages_classified, palette='Oranges_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Percentage Classified as Parkinsonian')\n",
    "    plt.title('Percentage Classified as Parkinsonian by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "    # Bar chart for total count\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=levels, y=total_counts, palette='Greens_d')\n",
    "    plt.xlabel('UPDRS Level')\n",
    "    plt.ylabel('Total Count')\n",
    "    plt.title('Total Data Count by UPDRS Level')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after calculating metrics\n",
    "plot_updrs_metrics(aggregated_updrs_metrics, probabilities_by_updrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlFnp4ZeM5P-"
   },
   "outputs": [],
   "source": [
    "# Nome del file per salvare tutti i risultati\n",
    "results_filename = \"results_AST2.txt\"\n",
    "\n",
    "# Scrivi tutti i risultati in un unico file\n",
    "with open(results_filename, mode=\"w\") as file:\n",
    "    # Scrivi i risultati UPDRS\n",
    "    file.write(\"===== Aggregated UPDRS Metrics Across Folds =====\\n\")\n",
    "    for level, metrics in aggregated_updrs_metrics.items():\n",
    "        file.write(f\"UPDRS Level {level}:\\n\")\n",
    "        file.write(f\"  Total Count: {metrics['total_count']}\\n\")\n",
    "        file.write(f\"  Mean Probability (Parkinsonian): {metrics['mean_probability']:.4f}\\n\")\n",
    "        file.write(f\"  Percentage Classified as Parkinsonian: {metrics['percentage_classified_as_parkinsonian']:.2f}%\\n\")\n",
    "        file.write(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "    # Scrivi le metriche medie sui fold\n",
    "    file.write(\"\\n===== Average Metrics Across Folds (Last Epoch Only) =====\\n\")\n",
    "    file.write(f\"Training Accuracy: {average_train_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Validation Accuracy: {average_val_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Training Precision: {average_train_precision:.4f}\\n\")\n",
    "    file.write(f\"Validation Precision: {average_val_precision:.4f}\\n\")\n",
    "    file.write(f\"Training Recall: {average_train_recall:.4f}\\n\")\n",
    "    file.write(f\"Validation Recall: {average_val_recall:.4f}\\n\")\n",
    "    file.write(f\"Training F1-Score: {average_train_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation F1-Score: {average_val_f1:.4f}\\n\")\n",
    "    file.write(f\"Validation Sensitivity: {average_val_sensitivity:.4f}\\n\")\n",
    "    file.write(f\"Validation Specificity: {average_val_specificity:.4f}\\n\")\n",
    "\n",
    "print(f\"All results saved to {results_filename}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
